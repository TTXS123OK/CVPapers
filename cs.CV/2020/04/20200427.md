# Arxiv Papers in cs.CV on 2020-04-27
### Printing and Scanning Attack for Image Counter Forensics
- **Arxiv ID**: http://arxiv.org/abs/2005.02160v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2005.02160v2)
- **Published**: 2020-04-27 00:32:15+00:00
- **Updated**: 2020-06-24 17:01:59+00:00
- **Authors**: Hailey Joren, Otkrist Gupta, Dan Raviv
- **Comment**: 10 pages, 5 figures, 7 tables
- **Journal**: None
- **Summary**: Examining the authenticity of images has become increasingly important as manipulation tools become more accessible and advanced. Recent work has shown that while CNN-based image manipulation detectors can successfully identify manipulations, they are also vulnerable to adversarial attacks, ranging from simple double JPEG compression to advanced pixel-based perturbation. In this paper we explore another method of highly plausible attack: printing and scanning. We demonstrate the vulnerability of two state-of-the-art models to this type of attack. We also propose a new machine learning model that performs comparably to these state-of-the-art models when trained and validated on printed and scanned images. Of the three models, our proposed model outperforms the others when trained and validated on images from a single printer. To facilitate this exploration, we create a dataset of over 6,000 printed and scanned image blocks. Further analysis suggests that variation between images produced from different printers is significant, large enough that good validation accuracy on images from one printer does not imply similar validation accuracy on identical images from a different printer.



### Fully Embedding Fast Convolutional Networks on Pixel Processor Arrays
- **Arxiv ID**: http://arxiv.org/abs/2004.12525v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2004.12525v1)
- **Published**: 2020-04-27 01:00:35+00:00
- **Updated**: 2020-04-27 01:00:35+00:00
- **Authors**: Laurie Bose, Jianing Chen, Stephen J. Carey, Piotr Dudek, Walterio Mayol-Cuevas
- **Comment**: None
- **Journal**: None
- **Summary**: We present a novel method of CNN inference for pixel processor array (PPA) vision sensors, designed to take advantage of their massive parallelism and analog compute capabilities. PPA sensors consist of an array of processing elements (PEs), with each PE capable of light capture, data storage and computation, allowing various computer vision processing to be executed directly upon the sensor device. The key idea behind our approach is storing network weights "in-pixel" within the PEs of the PPA sensor itself to allow various computations, such as multiple different image convolutions, to be carried out in parallel. Our approach can perform convolutional layers, max pooling, ReLu, and a final fully connected layer entirely upon the PPA sensor, while leaving no untapped computational resources. This is in contrast to previous works that only use a sensor-level processing to sequentially compute image convolutions, and must transfer data to an external digital processor to complete the computation. We demonstrate our approach on the SCAMP-5 vision system, performing inference of a MNIST digit classification network at over 3000 frames per second and over 93% classification accuracy. This is the first work demonstrating CNN inference conducted entirely upon the processor array of a PPA vision sensor device, requiring no external processing.



### Towards Accurate and Robust Domain Adaptation under Noisy Environments
- **Arxiv ID**: http://arxiv.org/abs/2004.12529v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2004.12529v2)
- **Published**: 2020-04-27 01:07:19+00:00
- **Updated**: 2020-05-05 01:18:01+00:00
- **Authors**: Zhongyi Han, Xian-Jin Gui, Chaoran Cui, Yilong Yin
- **Comment**: To appear in Proceedings of IJCAI 2020
- **Journal**: None
- **Summary**: In non-stationary environments, learning machines usually confront the domain adaptation scenario where the data distribution does change over time. Previous domain adaptation works have achieved great success in theory and practice. However, they always lose robustness in noisy environments where the labels and features of examples from the source domain become corrupted. In this paper, we report our attempt towards achieving accurate noise-robust domain adaptation. We first give a theoretical analysis that reveals how harmful noises influence unsupervised domain adaptation. To eliminate the effect of label noise, we propose an offline curriculum learning for minimizing a newly-defined empirical source risk. To reduce the impact of feature noise, we propose a proxy distribution based margin discrepancy. We seamlessly transform our methods into an adversarial network that performs efficient joint optimization for them, successfully mitigating the negative influence from both data corruption and distribution shift. A series of empirical studies show that our algorithm remarkably outperforms state of the art, over 10% accuracy improvements in some domain adaptation tasks under noisy environments.



### Difficulty Translation in Histopathology Images
- **Arxiv ID**: http://arxiv.org/abs/2004.12535v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2004.12535v2)
- **Published**: 2020-04-27 01:27:15+00:00
- **Updated**: 2020-07-10 23:37:20+00:00
- **Authors**: Jerry Wei, Arief Suriawinata, Xiaoying Liu, Bing Ren, Mustafa Nasir-Moin, Naofumi Tomita, Jason Wei, Saeed Hassanpour
- **Comment**: Accepted to 2020 Artificial Intelligence in Medicine (AIME)
  conference. Invited for long oral presentation
- **Journal**: None
- **Summary**: The unique nature of histopathology images opens the door to domain-specific formulations of image translation models. We propose a difficulty translation model that modifies colorectal histopathology images to be more challenging to classify. Our model comprises a scorer, which provides an output confidence to measure the difficulty of images, and an image translator, which learns to translate images from easy-to-classify to hard-to-classify using a training set defined by the scorer. We present three findings. First, generated images were indeed harder to classify for both human pathologists and machine learning classifiers than their corresponding source images. Second, image classifiers trained with generated images as augmented data performed better on both easy and hard images from an independent test set. Finally, human annotator agreement and our model's measure of difficulty correlated strongly, implying that for future work requiring human annotator agreement, the confidence score of a machine learning classifier could be used as a proxy.



### Towards Data-Efficient Learning: A Benchmark for COVID-19 CT Lung and Infection Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2004.12537v2
- **DOI**: 10.1002/mp.14676
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2004.12537v2)
- **Published**: 2020-04-27 01:31:48+00:00
- **Updated**: 2020-12-03 11:21:07+00:00
- **Authors**: Jun Ma, Yixin Wang, Xingle An, Cheng Ge, Ziqi Yu, Jianan Chen, Qiongjie Zhu, Guoqiang Dong, Jian He, Zhiqiang He, Yuntao Zhu, Ziwei Nie, Xiaoping Yang
- **Comment**: accepted for publication in Medical Physics
- **Journal**: None
- **Summary**: Purpose: Accurate segmentation of lung and infection in COVID-19 CT scans plays an important role in the quantitative management of patients. Most of the existing studies are based on large and private annotated datasets that are impractical to obtain from a single institution, especially when radiologists are busy fighting the coronavirus disease. Furthermore, it is hard to compare current COVID-19 CT segmentation methods as they are developed on different datasets, trained in different settings, and evaluated with different metrics. Methods: To promote the development of data-efficient deep learning methods, in this paper, we built three benchmarks for lung and infection segmentation based on 70 annotated COVID-19 cases, which contain current active research areas, e.g., few-shot learning, domain generalization, and knowledge transfer. For a fair comparison among different segmentation methods, we also provide standard training, validation and testing splits, evaluation metrics and, the corresponding code. Results: Based on the state-of-the-art network, we provide more than 40 pre-trained baseline models, which not only serve as out-of-the-box segmentation tools but also save computational time for researchers who are interested in COVID-19 lung and infection segmentation. We achieve average Dice Similarity Coefficient (DSC) scores of 97.3\%, 97.7\%, and 67.3\% and average Normalized Surface Dice (NSD) scores of 90.6\%, 91.4\%, and 70.0\% for left lung, right lung, and infection, respectively. Conclusions: To the best of our knowledge, this work presents the first data-efficient learning benchmark for medical image segmentation and the largest number of pre-trained models up to now. All these resources are publicly available, and our work lays the foundation for promoting the development of deep learning methods for efficient COVID-19 CT segmentation with limited data.



### VTGNet: A Vision-based Trajectory Generation Network for Autonomous Vehicles in Urban Environments
- **Arxiv ID**: http://arxiv.org/abs/2004.12591v3
- **DOI**: 10.1109/TIV.2020.3033878
- **Categories**: **cs.CV**, cs.LG, cs.RO, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2004.12591v3)
- **Published**: 2020-04-27 06:17:55+00:00
- **Updated**: 2020-10-23 08:46:58+00:00
- **Authors**: Peide Cai, Yuxiang Sun, Hengli Wang, Ming Liu
- **Comment**: 11 pages, 14 figures, and 4 tables. The paper is accepted by IEEE
  Transactions on Intelligent Vehicles (T-IV), 2020
- **Journal**: None
- **Summary**: Traditional methods for autonomous driving are implemented with many building blocks from perception, planning and control, making them difficult to generalize to varied scenarios due to complex assumptions and interdependencies. Recently, the end-to-end driving method has emerged, which performs well and generalizes to new environments by directly learning from export-provided data. However, many existing methods on this topic neglect to check the confidence of the driving actions and the ability to recover from driving mistakes. In this paper, we develop an uncertainty-aware end-to-end trajectory generation method based on imitation learning. It can extract spatiotemporal features from the front-view camera images for scene understanding, and then generate collision-free trajectories several seconds into the future. The experimental results suggest that under various weather and lighting conditions, our network can reliably generate trajectories in different urban environments, such as turning at intersections and slowing down for collision avoidance. Furthermore, closed-loop driving tests suggest that the proposed method achieves better cross-scene/platform driving results than the state-of-the-art (SOTA) end-to-end control method, where our model can recover from off-center and off-orientation errors and capture 80% of dangerous cases with high uncertainty estimations.



### Robust Screening of COVID-19 from Chest X-ray via Discriminative Cost-Sensitive Learning
- **Arxiv ID**: http://arxiv.org/abs/2004.12592v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2004.12592v2)
- **Published**: 2020-04-27 06:17:56+00:00
- **Updated**: 2020-05-21 14:37:04+00:00
- **Authors**: Tianyang Li, Zhongyi Han, Benzheng Wei, Yuanjie Zheng, Yanfei Hong, Jinyu Cong
- **Comment**: Under review
- **Journal**: None
- **Summary**: This paper addresses the new problem of automated screening of coronavirus disease 2019 (COVID-19) based on chest X-rays, which is urgently demanded toward fast stopping the pandemic. However, robust and accurate screening of COVID-19 from chest X-rays is still a globally recognized challenge because of two bottlenecks: 1) imaging features of COVID-19 share some similarities with other pneumonia on chest X-rays, and 2) the misdiagnosis rate of COVID-19 is very high, and the misdiagnosis cost is expensive. While a few pioneering works have made much progress, they underestimate both crucial bottlenecks. In this paper, we report our solution, discriminative cost-sensitive learning (DCSL), which should be the choice if the clinical needs the assisted screening of COVID-19 from chest X-rays. DCSL combines both advantages from fine-grained classification and cost-sensitive learning. Firstly, DCSL develops a conditional center loss that learns deep discriminative representation. Secondly, DCSL establishes score-level cost-sensitive learning that can adaptively enlarge the cost of misclassifying COVID-19 examples into other classes. DCSL is so flexible that it can apply in any deep neural network. We collected a large-scale multi-class dataset comprised of 2,239 chest X-ray examples: 239 examples from confirmed COVID-19 cases, 1,000 examples with confirmed bacterial or viral pneumonia cases, and 1,000 examples of healthy people. Extensive experiments on the three-class classification show that our algorithm remarkably outperforms state-of-the-art algorithms. It achieves an accuracy of 97.01%, a precision of 97%, a sensitivity of 97.09%, and an F1-score of 96.98%. These results endow our algorithm as an efficient tool for the fast large-scale screening of COVID-19.



### Deploying Image Deblurring across Mobile Devices: A Perspective of Quality and Latency
- **Arxiv ID**: http://arxiv.org/abs/2004.12599v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2004.12599v1)
- **Published**: 2020-04-27 06:32:53+00:00
- **Updated**: 2020-04-27 06:32:53+00:00
- **Authors**: Cheng-Ming Chiang, Yu Tseng, Yu-Syuan Xu, Hsien-Kai Kuo, Yi-Min Tsai, Guan-Yu Chen, Koan-Sin Tan, Wei-Ting Wang, Yu-Chieh Lin, Shou-Yao Roy Tseng, Wei-Shiang Lin, Chia-Lin Yu, BY Shen, Kloze Kao, Chia-Ming Cheng, Hung-Jen Chen
- **Comment**: CVPR 2020 Workshop on New Trends in Image Restoration and Enhancement
  (NTIRE)
- **Journal**: None
- **Summary**: Recently, image enhancement and restoration have become important applications on mobile devices, such as super-resolution and image deblurring. However, most state-of-the-art networks present extremely high computational complexity. This makes them difficult to be deployed on mobile devices with acceptable latency. Moreover, when deploying to different mobile devices, there is a large latency variation due to the difference and limitation of deep learning accelerators on mobile devices. In this paper, we conduct a search of portable network architectures for better quality-latency trade-off across mobile devices. We further present the effectiveness of widely used network optimizations for image deblurring task. This paper provides comprehensive experiments and comparisons to uncover the in-depth analysis for both latency and image quality. Through all the above works, we demonstrate the successful deployment of image deblurring application on mobile devices with the acceleration of deep learning accelerators. To the best of our knowledge, this is the first paper that addresses all the deployment issues of image deblurring task across mobile devices. This paper provides practical deployment-guidelines, and is adopted by the championship-winning team in NTIRE 2020 Image Deblurring Challenge on Smartphone Track.



### Improving Endoscopic Decision Support Systems by Translating Between Imaging Modalities
- **Arxiv ID**: http://arxiv.org/abs/2004.12604v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2004.12604v1)
- **Published**: 2020-04-27 06:55:56+00:00
- **Updated**: 2020-04-27 06:55:56+00:00
- **Authors**: Georg Wimmer, Michael Gadermayr, Andreas VÃ©csei, Andreas Uhl
- **Comment**: Submitted to MICCAI 2020
- **Journal**: None
- **Summary**: Novel imaging technologies raise many questions concerning the adaptation of computer-aided decision support systems. Classification models either need to be adapted or even newly trained from scratch to exploit the full potential of enhanced techniques. Both options typically require the acquisition of new labeled training data. In this work we investigate the applicability of image-to-image translation to endoscopic images showing different imaging modalities, namely conventional white-light and narrow-band imaging. In a study on computer-aided celiac disease diagnosis, we explore whether image-to-image translation is capable of effectively performing the translation between the domains. We investigate if models can be trained on virtual (or a mixture of virtual and real) samples to improve overall accuracy in a setting with limited labeled training data. Finally, we also ask whether a translation of testing images to another domain is capable of improving accuracy by exploiting the enhanced imaging characteristics.



### Continuous hand-eye calibration using 3D points
- **Arxiv ID**: http://arxiv.org/abs/2004.12611v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2004.12611v1)
- **Published**: 2020-04-27 07:13:33+00:00
- **Updated**: 2020-04-27 07:13:33+00:00
- **Authors**: Bjarne Grossmann, Volker Krueger
- **Comment**: None
- **Journal**: None
- **Summary**: The recent development of calibration algorithms has been driven into two major directions: (1) an increasing accuracy of mathematical approaches and (2) an increasing flexibility in usage by reducing the dependency on calibration objects. These two trends, however, seem to be contradictory since the overall accuracy is directly related to the accuracy of the pose estimation of the calibration object and therefore demanding large objects, while an increased flexibility leads to smaller objects or noisier estimation methods.   The method presented in this paper aims to resolves this problem in two steps: First, we derive a simple closed-form solution with a shifted focus towards the equation of translation that only solves for the necessary hand-eye transformation. We show that it is superior in accuracy and robustness compared to traditional approaches. Second, we decrease the dependency on the calibration object to a single 3D-point by using a similar formulation based on the equation of translation which is much less affected by the estimation error of the calibration object's orientation. Moreover, it makes the estimation of the orientation obsolete while taking advantage of the higher accuracy and robustness from the first solution, resulting in a versatile method for continuous hand-eye calibration.



### Maximum Density Divergence for Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/2004.12615v1
- **DOI**: 10.1109/TPAMI.2020.2991050
- **Categories**: **cs.CV**, cs.LG, cs.MM, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2004.12615v1)
- **Published**: 2020-04-27 07:35:06+00:00
- **Updated**: 2020-04-27 07:35:06+00:00
- **Authors**: Li Jingjing, Chen Erpeng, Ding Zhengming, Zhu Lei, Lu Ke, Shen Heng Tao
- **Comment**: Published on IEEE Transactions on Pattern Analysis and Machine
  Intelligence (TPAMI)
- **Journal**: None
- **Summary**: Unsupervised domain adaptation addresses the problem of transferring knowledge from a well-labeled source domain to an unlabeled target domain where the two domains have distinctive data distributions. Thus, the essence of domain adaptation is to mitigate the distribution divergence between the two domains. The state-of-the-art methods practice this very idea by either conducting adversarial training or minimizing a metric which defines the distribution gaps. In this paper, we propose a new domain adaptation method named Adversarial Tight Match (ATM) which enjoys the benefits of both adversarial training and metric learning. Specifically, at first, we propose a novel distance loss, named Maximum Density Divergence (MDD), to quantify the distribution divergence. MDD minimizes the inter-domain divergence ("match" in ATM) and maximizes the intra-class density ("tight" in ATM). Then, to address the equilibrium challenge issue in adversarial domain adaptation, we consider leveraging the proposed MDD into adversarial domain adaptation framework. At last, we tailor the proposed MDD as a practical learning loss and report our ATM. Both empirical evaluation and theoretical analysis are reported to verify the effectiveness of the proposed method. The experimental results on four benchmarks, both classical and large-scale, show that our method is able to achieve new state-of-the-art performance on most evaluations. Codes and datasets used in this paper are available at {\it github.com/lijin118/ATM}.



### Localizing Grouped Instances for Efficient Detection in Low-Resource Scenarios
- **Arxiv ID**: http://arxiv.org/abs/2004.12623v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2004.12623v1)
- **Published**: 2020-04-27 07:56:53+00:00
- **Updated**: 2020-04-27 07:56:53+00:00
- **Authors**: Amelie Royer, Christoph H. Lampert
- **Comment**: WACV 2020
- **Journal**: None
- **Summary**: State-of-the-art detection systems are generally evaluated on their ability to exhaustively retrieve objects densely distributed in the image, across a wide variety of appearances and semantic categories. Orthogonal to this, many real-life object detection applications, for example in remote sensing, instead require dealing with large images that contain only a few small objects of a single class, scattered heterogeneously across the space. In addition, they are often subject to strict computational constraints, such as limited battery capacity and computing power. To tackle these more practical scenarios, we propose a novel flexible detection scheme that efficiently adapts to variable object sizes and densities: We rely on a sequence of detection stages, each of which has the ability to predict groups of objects as well as individuals. Similar to a detection cascade, this multi-stage architecture spares computational effort by discarding large irrelevant regions of the image early during the detection process. The ability to group objects provides further computational and memory savings, as it allows working with lower image resolutions in early stages, where groups are more easily detected than individuals, as they are more salient. We report experimental results on two aerial image datasets, and show that the proposed method is as accurate yet computationally more efficient than standard single-shot detectors, consistently across three different backbone architectures.



### Preliminary Forensics Analysis of DeepFake Images
- **Arxiv ID**: http://arxiv.org/abs/2004.12626v5
- **DOI**: 10.23919/AEIT50178.2020.9241108
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2004.12626v5)
- **Published**: 2020-04-27 08:09:06+00:00
- **Updated**: 2020-08-04 09:27:14+00:00
- **Authors**: Luca Guarnera, Oliver Giudice, Cristina Nastasi, Sebastiano Battiato
- **Comment**: Accepted at IEEE AEIT International Annual Conference 2020
- **Journal**: 2020 AEIT International Annual Conference (AEIT)
- **Summary**: One of the most terrifying phenomenon nowadays is the DeepFake: the possibility to automatically replace a person's face in images and videos by exploiting algorithms based on deep learning. This paper will present a brief overview of technologies able to produce DeepFake images of faces. A forensics analysis of those images with standard methods will be presented: not surprisingly state of the art techniques are not completely able to detect the fakeness. To solve this, a preliminary idea on how to fight DeepFake images of faces will be presented by analysing anomalies in the frequency domain.



### CascadeTabNet: An approach for end to end table detection and structure recognition from image-based documents
- **Arxiv ID**: http://arxiv.org/abs/2004.12629v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2004.12629v2)
- **Published**: 2020-04-27 08:12:48+00:00
- **Updated**: 2020-05-28 08:02:43+00:00
- **Authors**: Devashish Prasad, Ayan Gadpal, Kshitij Kapadni, Manish Visave, Kavita Sultanpure
- **Comment**: Paper has been accepted at CVPR Workshop 2020 (CVPR2020 Workshop on
  Text and Documents in the Deep Learning Era)
- **Journal**: None
- **Summary**: An automatic table recognition method for interpretation of tabular data in document images majorly involves solving two problems of table detection and table structure recognition. The prior work involved solving both problems independently using two separate approaches. More recent works signify the use of deep learning-based solutions while also attempting to design an end to end solution. In this paper, we present an improved deep learning-based end to end approach for solving both problems of table detection and structure recognition using a single Convolution Neural Network (CNN) model. We propose CascadeTabNet: a Cascade mask Region-based CNN High-Resolution Network (Cascade mask R-CNN HRNet) based model that detects the regions of tables and recognizes the structural body cells from the detected tables at the same time. We evaluate our results on ICDAR 2013, ICDAR 2019 and TableBank public datasets. We achieved 3rd rank in ICDAR 2019 post-competition results for table detection while attaining the best accuracy results for the ICDAR 2013 and TableBank dataset. We also attain the highest accuracy results on the ICDAR 2019 table structure recognition dataset. Additionally, we demonstrate effective transfer learning and image augmentation techniques that enable CNNs to achieve very accurate table detection results. Code and dataset has been made available at: https://github.com/DevashishPrasad/CascadeTabNet



### JointsGait:A model-based Gait Recognition Method based on Gait Graph Convolutional Networks and Joints Relationship Pyramid Mapping
- **Arxiv ID**: http://arxiv.org/abs/2005.08625v2
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV, 68T01, I.2.10; I.5.1; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/2005.08625v2)
- **Published**: 2020-04-27 08:30:37+00:00
- **Updated**: 2020-12-09 09:12:03+00:00
- **Authors**: Na Li, Xinbo Zhao, Chong Ma
- **Comment**: The paper format was changed and experiments on other databases were
  added. The format and page layout were changed greatly
- **Journal**: None
- **Summary**: Gait, as one of unique biometric features, has the advantage of being recognized from a long distance away, can be widely used in public security. Considering 3D pose estimation is more challenging than 2D pose estimation in practice , we research on using 2D joints to recognize gait in this paper, and a new model-based gait recognition method JointsGait is put forward to extract gait information from 2D human body joints. Appearance-based gait recognition algorithms are prevalent before. However, appearance features suffer from external factors which can cause drastic appearance variations, e.g. clothing. Unlike previous approaches, JointsGait firstly extracted spatio-temporal features from 2D joints using gait graph convolutional networks, which are less interfered by external factors. Secondly, Joints Relationship Pyramid Mapping (JRPM) are proposed to map spatio-temporal gait features into a discriminative feature space with biological advantages according to the relationship of human joints when people are walking at various scales. Finally, we design a fusion loss strategy to help the joints features to be insensitive to cross-view. Our method is evaluated on two large datasets, Kinect Gait Biometry Dataset and CASIA-B. On Kinect Gait Biometry Dataset database, JointsGait only uses corresponding 2D coordinates of joints, but achieves satisfactory recognition accuracy compared with those model-based algorithms using 3D joints. On CASIA-B database, the proposed method greatly outperforms advanced model-based methods in all walking conditions, even performs superior to state-of-art appearance-based methods when clothing seriously affect people's appearance. The experimental results demonstrate that JointsGait achieves the state-of-art performance despite the low dimensional feature (2D body joints) and is less affected by the view variations and clothing variation.



### 3D-CVF: Generating Joint Camera and LiDAR Features Using Cross-View Spatial Feature Fusion for 3D Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2004.12636v2
- **DOI**: 10.1007/978-3-030-58583-9_43
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2004.12636v2)
- **Published**: 2020-04-27 08:34:46+00:00
- **Updated**: 2020-07-21 03:00:03+00:00
- **Authors**: Jin Hyeok Yoo, Yecheol Kim, Jisong Kim, Jun Won Choi
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we propose a new deep architecture for fusing camera and LiDAR sensors for 3D object detection. Because the camera and LiDAR sensor signals have different characteristics and distributions, fusing these two modalities is expected to improve both the accuracy and robustness of 3D object detection. One of the challenges presented by the fusion of cameras and LiDAR is that the spatial feature maps obtained from each modality are represented by significantly different views in the camera and world coordinates; hence, it is not an easy task to combine two heterogeneous feature maps without loss of information. To address this problem, we propose a method called 3D-CVF that combines the camera and LiDAR features using the cross-view spatial feature fusion strategy. First, the method employs auto-calibrated projection, to transform the 2D camera features to a smooth spatial feature map with the highest correspondence to the LiDAR features in the bird's eye view (BEV) domain. Then, a gated feature fusion network is applied to use the spatial attention maps to mix the camera and LiDAR features appropriately according to the region. Next, camera-LiDAR feature fusion is also achieved in the subsequent proposal refinement stage. The camera feature is used from the 2D camera-view domain via 3D RoI grid pooling and fused with the BEV feature for proposal refinement. Our evaluations, conducted on the KITTI and nuScenes 3D object detection datasets demonstrate that the camera-LiDAR fusion offers significant performance gain over single modality and that the proposed 3D-CVF achieves state-of-the-art performance in the KITTI benchmark.



### Self-supervised Keypoint Correspondences for Multi-Person Pose Estimation and Tracking in Videos
- **Arxiv ID**: http://arxiv.org/abs/2004.12652v3
- **DOI**: 10.1007/978-3-030-58565-5_3
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2004.12652v3)
- **Published**: 2020-04-27 09:02:24+00:00
- **Updated**: 2021-03-15 11:48:44+00:00
- **Authors**: Umer Rafi, Andreas Doering, Bastian Leibe, Juergen Gall
- **Comment**: Accepted to ECCV 2020
- **Journal**: None
- **Summary**: Video annotation is expensive and time consuming. Consequently, datasets for multi-person pose estimation and tracking are less diverse and have more sparse annotations compared to large scale image datasets for human pose estimation. This makes it challenging to learn deep learning based models for associating keypoints across frames that are robust to nuisance factors such as motion blur and occlusions for the task of multi-person pose tracking. To address this issue, we propose an approach that relies on keypoint correspondences for associating persons in videos. Instead of training the network for estimating keypoint correspondences on video data, it is trained on a large scale image datasets for human pose estimation using self-supervision. Combined with a top-down framework for human pose estimation, we use keypoints correspondences to (i) recover missed pose detections (ii) associate pose detections across video frames. Our approach achieves state-of-the-art results for multi-frame pose estimation and multi-person pose tracking on the PosTrack $2017$ and PoseTrack $2018$ data sets.



### OR-UNet: an Optimized Robust Residual U-Net for Instrument Segmentation in Endoscopic Images
- **Arxiv ID**: http://arxiv.org/abs/2004.12668v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2004.12668v1)
- **Published**: 2020-04-27 09:34:05+00:00
- **Updated**: 2020-04-27 09:34:05+00:00
- **Authors**: Fabian Isensee, Klaus H. Maier-Hein
- **Comment**: None
- **Journal**: None
- **Summary**: Segmentation of endoscopic images is an essential processing step for computer and robotics-assisted interventions. The Robust-MIS challenge provides the largest dataset of annotated endoscopic images to date, with 5983 manually annotated images. Here we describe OR-UNet, our optimized robust residual 2D U-Net for endoscopic image segmentation. As the name implies, the network makes use of residual connections in the encoder. It is trained with the sum of Dice and cross-entropy loss and deep supervision. During training, extensive data augmentation is used to increase the robustness. In an 8-fold cross-validation on the training images, our model achieved a mean (median) Dice score of 87.41 (94.35). We use the eight models from the cross-validation as an ensemble on the test set.



### Distance Guided Channel Weighting for Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2004.12679v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2004.12679v4)
- **Published**: 2020-04-27 09:57:12+00:00
- **Updated**: 2022-05-13 08:55:09+00:00
- **Authors**: Xuanyi Liu, Lanyun Zhu, Shiping Zhu, Li Luo
- **Comment**: None
- **Journal**: None
- **Summary**: Recent works have achieved great success in improving the performance of multiple computer vision tasks by capturing features with a high channel number utilizing deep neural networks. However, many channels of extracted features are not discriminative and contain a lot of redundant information. In this paper, we address above issue by introducing the Distance Guided Channel Weighting (DGCW) Module. The DGCW module is constructed in a pixel-wise context extraction manner, which enhances the discriminativeness of features by weighting different channels of each pixel's feature vector when modeling its relationship with other pixels. It can make full use of the high-discriminative information while ignore the low-discriminative information containing in feature maps, as well as capture the long-range dependencies. Furthermore, by incorporating the DGCW module with a baseline segmentation network, we propose the Distance Guided Channel Weighting Network (DGCWNet). We conduct extensive experiments to demonstrate the effectiveness of DGCWNet. In particular, it achieves 81.6% mIoU on Cityscapes with only fine annotated data for training, and also gains satisfactory performance on another two semantic segmentation datasets, i.e. Pascal Context and ADE20K. Code will be available soon at https://github.com/LanyunZhu/DGCWNet.



### Remote Photoplethysmography: Rarely Considered Factors
- **Arxiv ID**: http://arxiv.org/abs/2004.12695v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.SP
- **Links**: [PDF](http://arxiv.org/pdf/2004.12695v1)
- **Published**: 2020-04-27 10:38:45+00:00
- **Updated**: 2020-04-27 10:38:45+00:00
- **Authors**: Yuriy Mironenko, Konstantin Kalinin, Mikhail Kopeliovich, Mikhail Petrushan
- **Comment**: None
- **Journal**: None
- **Summary**: Remote Photoplethysmography (rPPG) is a fast-growing technique of vital sign estimation by analyzing video of a person. Several major phenomena affecting rPPG signals have been studied (e.g. video compression, distance from person to camera, skin tone, head motions). However, to develop a highly accurate rPPG method, new, minor, factors should be investigated. First considered factor is irregular frame rate of video recordings. Despite of PPG signal transformation by frame rate irregularity, no significant distortion of PPG signal spectra was found in the experiments. Second factor is rolling shutter effect which generates tiny phase shift of the same PPG signal in different parts of the frame caused by progressive scanning. In particular conditions effect of this artifact could be of the same order of magnitude as physiologically caused phase shifts. Third factor is a size of temporal windows, which could significantly influence the estimated error of vital sign evaluation. It follows that one should account difference in size of processing windows when comparing rPPG methods. Short series of experiments were conducted to estimate importance of these phenomena and to determine necessity of their further comprehensive study.



### Reconstructing normal section profiles of 3D revolving structures via pose-unconstrained multi-line structured-light vision
- **Arxiv ID**: http://arxiv.org/abs/2004.12697v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2004.12697v1)
- **Published**: 2020-04-27 10:39:38+00:00
- **Updated**: 2020-04-27 10:39:38+00:00
- **Authors**: Junhua Sun, Zhou Zhang, Jie Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: The wheel of the train is a 3D revolving geometrical structure. Reconstructing the normal section profile is an effective approach to determine the critical geometric parameter and wear of the wheel in the community of railway safety. The existing reconstruction methods typically require a sensor working in a constrained position and pose, suffering poor flexibility and limited viewangle. This paper proposes a pose-unconstrained normal section profile reconstruction framework for 3D revolving structures via multiple 3D general section profiles acquired by a multi-line structured light vision sensor. First, we establish a model to estimate the axis of 3D revolving geometrical structure and the normal section profile using corresponding points. Then, we embed the model into an iterative algorithm to optimize the corresponding points and finally reconstruct the accurate normal section profile. We conducted real experiment on reconstructing the normal section profile of a 3D wheel. The results demonstrate that our algorithm reaches the mean precision of 0.068mm and good repeatability with the STD of 0.007mm. It is also robust to varying pose variations of the sensor. Our proposed framework and models are generalized to any 3D wheeltype revolving components.



### In-Vehicle Object Detection in the Wild for Driverless Vehicles
- **Arxiv ID**: http://arxiv.org/abs/2004.12700v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2004.12700v1)
- **Published**: 2020-04-27 10:43:00+00:00
- **Updated**: 2020-04-27 10:43:00+00:00
- **Authors**: Ranjith Dinakaran, Li Zhang, Richard Jiang
- **Comment**: the 14th International FLINS Conference on Robotics and Artificial
  Intelligence
- **Journal**: FLINS 2020
- **Summary**: In-vehicle human object identification plays an important role in vision-based automated vehicle driving systems while objects such as pedestrians and vehicles on roads or streets are the primary targets to protect from driverless vehicles. A challenge is the difficulty to detect objects in moving under the wild conditions, while illumination and image quality could drastically vary. In this work, to address this challenge, we exploit Deep Convolutional Generative Adversarial Networks (DCGANs) with Single Shot Detector (SSD) to handle with the wild conditions. In our work, a GAN was trained with low-quality images to handle with the challenges arising from the wild conditions in smart cities, while a cascaded SSD is employed as the object detector to perform with the GAN. We used tested our approach under wild conditions using taxi driver videos on London street in both daylight and night times, and the tests from in-vehicle videos demonstrate that this strategy can drastically achieve a better detection rate under the wild conditions.



### On indirect assessment of heart rate in video
- **Arxiv ID**: http://arxiv.org/abs/2004.12703v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2004.12703v1)
- **Published**: 2020-04-27 10:51:11+00:00
- **Updated**: 2020-04-27 10:51:11+00:00
- **Authors**: Mikhail Kopeliovich, Konstantin Kalinin, Yuriy Mironenko, Mikhail Petrushan
- **Comment**: None
- **Journal**: None
- **Summary**: Problem of indirect assessment of heart rate in video is addressed. Several methods of indirect evaluations (adaptive baselines) were examined on Remote Physiological Signal Sensing challenge. Particularly, regression models of dependency of heart rate on estimated age and motion intensity were obtained on challenge's train set. Accounting both motion and age in regression model led to top-quarter position in the leaderboard. Practical value of such adaptive baseline approaches is discussed. Although such approaches are considered as non-applicable in medicine, they are valuable as baseline for the photoplethysmography problem.



### GraftNet: An Engineering Implementation of CNN for Fine-grained Multi-label Task
- **Arxiv ID**: http://arxiv.org/abs/2004.12709v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2004.12709v1)
- **Published**: 2020-04-27 11:08:28+00:00
- **Updated**: 2020-04-27 11:08:28+00:00
- **Authors**: Chunhua Jia, Lei Zhang, Hui Huang, Weiwei Cai, Hao Hu, Rohan Adivarekar
- **Comment**: 8 Pages, 5 figures, 3 tables
- **Journal**: None
- **Summary**: Multi-label networks with branches are proved to perform well in both accuracy and speed, but lacks flexibility in providing dynamic extension onto new labels due to the low efficiency of re-work on annotating and training. For multi-label classification task, to cover new labels we need to annotate not only newly collected images, but also the previous whole dataset to check presence of these new labels. Also training on whole re-annotated dataset costs much time. In order to recognize new labels more effectively and accurately, we propose GraftNet, which is a customizable tree-like network with its trunk pretrained with a dynamic graph for generic feature extraction, and branches separately trained on sub-datasets with single label to improve accuracy. GraftNet could reduce cost, increase flexibility, and incrementally handle new labels. Experimental results show that it has good performance on our human attributes recognition task, which is fine-grained multi-label classification.



### Unsupervised Domain Adaptation with Multiple Domain Discriminators and Adaptive Self-Training
- **Arxiv ID**: http://arxiv.org/abs/2004.12724v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2004.12724v1)
- **Published**: 2020-04-27 11:48:03+00:00
- **Updated**: 2020-04-27 11:48:03+00:00
- **Authors**: Teo Spadotto, Marco Toldo, Umberto Michieli, Pietro Zanuttigh
- **Comment**: 8 pages, 3 figures, 2 tables
- **Journal**: None
- **Summary**: Unsupervised Domain Adaptation (UDA) aims at improving the generalization capability of a model trained on a source domain to perform well on a target domain for which no labeled data is available. In this paper, we consider the semantic segmentation of urban scenes and we propose an approach to adapt a deep neural network trained on synthetic data to real scenes addressing the domain shift between the two different data distributions. We introduce a novel UDA framework where a standard supervised loss on labeled synthetic data is supported by an adversarial module and a self-training strategy aiming at aligning the two domain distributions. The adversarial module is driven by a couple of fully convolutional discriminators dealing with different domains: the first discriminates between ground truth and generated maps, while the second between segmentation maps coming from synthetic or real world data. The self-training module exploits the confidence estimated by the discriminators on unlabeled data to select the regions used to reinforce the learning process. Furthermore, the confidence is thresholded with an adaptive mechanism based on the per-class overall confidence. Experimental results prove the effectiveness of the proposed strategy in adapting a segmentation network trained on synthetic datasets like GTA5 and SYNTHIA, to real world datasets like Cityscapes and Mapillary.



### Semantic Neighborhood-Aware Deep Facial Expression Recognition
- **Arxiv ID**: http://arxiv.org/abs/2004.12725v1
- **DOI**: 10.1109/TIP.2020.2991510
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2004.12725v1)
- **Published**: 2020-04-27 11:48:17+00:00
- **Updated**: 2020-04-27 11:48:17+00:00
- **Authors**: Yongjian Fu, Xintian Wu, Xi Li, Zhijie Pan, Daxin Luo
- **Comment**: None
- **Journal**: None
- **Summary**: Different from many other attributes, facial expression can change in a continuous way, and therefore, a slight semantic change of input should also lead to the output fluctuation limited in a small scale. This consistency is important. However, current Facial Expression Recognition (FER) datasets may have the extreme imbalance problem, as well as the lack of data and the excessive amounts of noise, hindering this consistency and leading to a performance decreasing when testing. In this paper, we not only consider the prediction accuracy on sample points, but also take the neighborhood smoothness of them into consideration, focusing on the stability of the output with respect to slight semantic perturbations of the input. A novel method is proposed to formulate semantic perturbation and select unreliable samples during training, reducing the bad effect of them. Experiments show the effectiveness of the proposed method and state-of-the-art results are reported, getting closer to an upper limit than the state-of-the-art methods by a factor of 30\% in AffectNet, the largest in-the-wild FER database by now.



### Single Shot 6D Object Pose Estimation
- **Arxiv ID**: http://arxiv.org/abs/2004.12729v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2004.12729v1)
- **Published**: 2020-04-27 11:59:11+00:00
- **Updated**: 2020-04-27 11:59:11+00:00
- **Authors**: Kilian Kleeberger, Marco F. Huber
- **Comment**: Accepted at 2020 IEEE International Conference on Robotics and
  Automation (ICRA 2020)
- **Journal**: None
- **Summary**: In this paper, we introduce a novel single shot approach for 6D object pose estimation of rigid objects based on depth images. For this purpose, a fully convolutional neural network is employed, where the 3D input data is spatially discretized and pose estimation is considered as a regression task that is solved locally on the resulting volume elements. With 65 fps on a GPU, our Object Pose Network (OP-Net) is extremely fast, is optimized end-to-end, and estimates the 6D pose of multiple objects in the image simultaneously. Our approach does not require manually 6D pose-annotated real-world datasets and transfers to the real world, although being entirely trained on synthetic data. The proposed method is evaluated on public benchmark datasets, where we can demonstrate that state-of-the-art methods are significantly outperformed.



### EAO-SLAM: Monocular Semi-Dense Object SLAM Based on Ensemble Data Association
- **Arxiv ID**: http://arxiv.org/abs/2004.12730v2
- **DOI**: 10.1109/IROS45743.2020.9341757
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2004.12730v2)
- **Published**: 2020-04-27 11:59:28+00:00
- **Updated**: 2020-07-29 07:36:13+00:00
- **Authors**: Yanmin Wu, Yunzhou Zhang, Delong Zhu, Yonghui Feng, Sonya Coleman, Dermot Kerr
- **Comment**: Accepted to IROS 2020. Project Page:
  https://yanmin-wu.github.io/project/eaoslam/; Code:
  https://github.com/yanmin-wu/EAO-SLAM
- **Journal**: 2020 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS), Las Vegas, NV, USA, 2020, pp. 4966-4973
- **Summary**: Object-level data association and pose estimation play a fundamental role in semantic SLAM, which remain unsolved due to the lack of robust and accurate algorithms. In this work, we propose an ensemble data associate strategy for integrating the parametric and nonparametric statistic tests. By exploiting the nature of different statistics, our method can effectively aggregate the information of different measurements, and thus significantly improve the robustness and accuracy of data association. We then present an accurate object pose estimation framework, in which an outliers-robust centroid and scale estimation algorithm and an object pose initialization algorithm are developed to help improve the optimality of pose estimation results. Furthermore, we build a SLAM system that can generate semi-dense or lightweight object-oriented maps with a monocular camera. Extensive experiments are conducted on three publicly available datasets and a real scenario. The results show that our approach significantly outperforms state-of-the-art techniques in accuracy and robustness. The source code is available on: https://github.com/yanmin-wu/EAO-SLAM.



### A Skip-connected Multi-column Network for Isolated Handwritten Bangla Character and Digit recognition
- **Arxiv ID**: http://arxiv.org/abs/2004.12769v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2004.12769v1)
- **Published**: 2020-04-27 13:18:58+00:00
- **Updated**: 2020-04-27 13:18:58+00:00
- **Authors**: Animesh Singh, Ritesh Sarkhel, Nibaran Das, Mahantapas Kundu, Mita Nasipuri
- **Comment**: None
- **Journal**: None
- **Summary**: Finding local invariant patterns in handwrit-ten characters and/or digits for optical character recognition is a difficult task. Variations in writing styles from one person to another make this task challenging. We have proposed a non-explicit feature extraction method using a multi-scale multi-column skip convolutional neural network in this work. Local and global features extracted from different layers of the proposed architecture are combined to derive the final feature descriptor encoding a character or digit image. Our method is evaluated on four publicly available datasets of isolated handwritten Bangla characters and digits. Exhaustive comparative analysis against contemporary methods establishes the efficacy of our proposed approach.



### Adversarial Fooling Beyond "Flipping the Label"
- **Arxiv ID**: http://arxiv.org/abs/2004.12771v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2004.12771v1)
- **Published**: 2020-04-27 13:21:03+00:00
- **Updated**: 2020-04-27 13:21:03+00:00
- **Authors**: Konda Reddy Mopuri, Vaisakh Shaj, R. Venkatesh Babu
- **Comment**: CVPR-AMLCV-2020
- **Journal**: None
- **Summary**: Recent advancements in CNNs have shown remarkable achievements in various CV/AI applications. Though CNNs show near human or better than human performance in many critical tasks, they are quite vulnerable to adversarial attacks. These attacks are potentially dangerous in real-life deployments. Though there have been many adversarial attacks proposed in recent years, there is no proper way of quantifying the effectiveness of these attacks. As of today, mere fooling rate is used for measuring the susceptibility of the models, or the effectiveness of adversarial attacks. Fooling rate just considers label flipping and does not consider the cost of such flipping, for instance, in some deployments, flipping between two species of dogs may not be as severe as confusing a dog category with that of a vehicle. Therefore, the metric to quantify the vulnerability of the models should capture the severity of the flipping as well. In this work we first bring out the drawbacks of the existing evaluation and propose novel metrics to capture various aspects of the fooling. Further, for the first time, we present a comprehensive analysis of several important adversarial attacks over a set of distinct CNN architectures. We believe that the presented analysis brings valuable insights about the current adversarial attacks and the CNN models.



### Unsupervised Real Image Super-Resolution via Generative Variational AutoEncoder
- **Arxiv ID**: http://arxiv.org/abs/2004.12811v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2004.12811v1)
- **Published**: 2020-04-27 13:49:36+00:00
- **Updated**: 2020-04-27 13:49:36+00:00
- **Authors**: Zhi-Song Liu, Wan-Chi Siu, Li-Wen Wang, Chu-Tak Li, Marie-Paule Cani, Yui-Lam Chan
- **Comment**: 9 pages, 7 figures, CVPR2020 NTIRE2020 Real Image Super-Resolution
  Challenge
- **Journal**: 2020 IEEE conference on Computer Vision and Pattern Recognition
  Workshop
- **Summary**: Benefited from the deep learning, image Super-Resolution has been one of the most developing research fields in computer vision. Depending upon whether using a discriminator or not, a deep convolutional neural network can provide an image with high fidelity or better perceptual quality. Due to the lack of ground truth images in real life, people prefer a photo-realistic image with low fidelity to a blurry image with high fidelity. In this paper, we revisit the classic example based image super-resolution approaches and come up with a novel generative model for perceptual image super-resolution. Given that real images contain various noise and artifacts, we propose a joint image denoising and super-resolution model via Variational AutoEncoder. We come up with a conditional variational autoencoder to encode the reference for dense feature vector which can then be transferred to the decoder for target image denoising. With the aid of the discriminator, an additional overhead of super-resolution subnetwork is attached to super-resolve the denoised image with photo-realistic visual quality. We participated the NTIRE2020 Real Image Super-Resolution Challenge. Experimental results show that by using the proposed approach, we can obtain enlarged images with clean and pleasant features compared to other supervised methods. We also compared our approach with state-of-the-art methods on various datasets to demonstrate the efficiency of our proposed unsupervised super-resolution model.



### A Critic Evaluation of Methods for COVID-19 Automatic Detection from X-Ray Images
- **Arxiv ID**: http://arxiv.org/abs/2004.12823v4
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2004.12823v4)
- **Published**: 2020-04-27 14:05:36+00:00
- **Updated**: 2020-09-20 00:36:28+00:00
- **Authors**: Gianluca Maguolo, Loris Nanni
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we compare and evaluate different testing protocols used for automatic COVID-19 diagnosis from X-Ray images in the recent literature. We show that similar results can be obtained using X-Ray images that do not contain most of the lungs. We are able to remove the lungs from the images by turning to black the center of the X-Ray scan and training our classifiers only on the outer part of the images. Hence, we deduce that several testing protocols for the recognition are not fair and that the neural networks are learning patterns in the dataset that are not correlated to the presence of COVID-19. Finally, we show that creating a fair testing protocol is a challenging task, and we provide a method to measure how fair a specific testing protocol is. In the future research we suggest to check the fairness of a testing protocol using our tools and we encourage researchers to look for better techniques than the ones that we propose.



### A Deep Attentive Convolutional Neural Network for Automatic Cortical Plate Segmentation in Fetal MRI
- **Arxiv ID**: http://arxiv.org/abs/2004.12847v3
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV, q-bio.QM
- **Links**: [PDF](http://arxiv.org/pdf/2004.12847v3)
- **Published**: 2020-04-27 14:55:22+00:00
- **Updated**: 2021-04-02 13:28:34+00:00
- **Authors**: Haoran Dou, Davood Karimi, Caitlin K. Rollins, Cynthia M. Ortinau, Lana Vasung, Clemente Velasco-Annis, Abdelhakim Ouaalam, Xin Yang, Dong Ni, Ali Gholipour
- **Comment**: Accepted by IEEE Transactions on Medical Imaging
- **Journal**: None
- **Summary**: Fetal cortical plate segmentation is essential in quantitative analysis of fetal brain maturation and cortical folding. Manual segmentation of the cortical plate, or manual refinement of automatic segmentations is tedious and time-consuming. Automatic segmentation of the cortical plate, on the other hand, is challenged by the relatively low resolution of the reconstructed fetal brain MRI scans compared to the thin structure of the cortical plate, partial voluming, and the wide range of variations in the morphology of the cortical plate as the brain matures during gestation. To reduce the burden of manual refinement of segmentations, we have developed a new and powerful deep learning segmentation method. Our method exploits new deep attentive modules with mixed kernel convolutions within a fully convolutional neural network architecture that utilizes deep supervision and residual connections. We evaluated our method quantitatively based on several performance measures and expert evaluations. Results show that our method outperforms several state-of-the-art deep models for segmentation, as well as a state-of-the-art multi-atlas segmentation technique. We achieved average Dice similarity coefficient of 0.87, average Hausdorff distance of 0.96 mm, and average symmetric surface difference of 0.28 mm on reconstructed fetal brain MRI scans of fetuses scanned in the gestational age range of 16 to 39 weeks. With a computation time of less than 1 minute per fetal brain, our method can facilitate and accelerate large-scale studies on normal and altered fetal brain cortical maturation and folding.



### Improvement in Land Cover and Crop Classification based on Temporal Features Learning from Sentinel-2 Data Using Recurrent-Convolutional Neural Network (R-CNN)
- **Arxiv ID**: http://arxiv.org/abs/2004.12880v2
- **DOI**: 10.3390/app10010238
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2004.12880v2)
- **Published**: 2020-04-27 15:39:50+00:00
- **Updated**: 2020-05-05 10:28:07+00:00
- **Authors**: Vittorio Mazzia, Aleem Khaliq, Marcello Chiaberge
- **Comment**: None
- **Journal**: Appl. Sci. 2020, 10(1), 238
- **Summary**: The increasing spatial and temporal resolution of globally available satellite images, such as provided by Sentinel-2, creates new possibilities for researchers to use freely available multi-spectral optical images, with decametric spatial resolution and more frequent revisits for remote sensing applications such as land cover and crop classification (LC&CC), agricultural monitoring and management, environment monitoring. Existing solutions dedicated to cropland mapping can be categorized based on per-pixel based and object-based. However, it is still challenging when more classes of agricultural crops are considered at a massive scale. In this paper, a novel and optimal deep learning model for pixel-based LC&CC is developed and implemented based on Recurrent Neural Networks (RNN) in combination with Convolutional Neural Networks (CNN) using multi-temporal sentinel-2 imagery of central north part of Italy, which has diverse agricultural system dominated by economic crop types. The proposed methodology is capable of automated feature extraction by learning time correlation of multiple images, which reduces manual feature engineering and modeling crop phenological stages. Fifteen classes, including major agricultural crops, were considered in this study. We also tested other widely used traditional machine learning algorithms for comparison such as support vector machine SVM, random forest (RF), Kernal SVM, and gradient boosting machine, also called XGBoost. The overall accuracy achieved by our proposed Pixel R-CNN was 96.5%, which showed considerable improvements in comparison with existing mainstream methods. This study showed that Pixel R-CNN based model offers a highly accurate way to assess and employ time-series data for multi-temporal classification tasks.



### Control Design of Autonomous Drone Using Deep Learning Based Image Understanding Techniques
- **Arxiv ID**: http://arxiv.org/abs/2004.12886v3
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/2004.12886v3)
- **Published**: 2020-04-27 15:50:04+00:00
- **Updated**: 2020-09-16 01:23:04+00:00
- **Authors**: Seid Miad Zandavi, Vera Chung, Ali Anaissi
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents a new framework to use images as the inputs for the controller to have autonomous flight, considering the noisy indoor environment and uncertainties. A new Proportional-Integral-Derivative-Accelerated (PIDA) control with a derivative filter is proposed to improves drone/quadcopter flight stability within a noisy environment and enables autonomous flight using object and depth detection techniques. The mathematical model is derived from an accurate model with a high level of fidelity by addressing the problems of non-linearity, uncertainties, and coupling. The proposed PIDA controller is tuned by Stochastic Dual Simplex Algorithm (SDSA) to support autonomous flight. The simulation results show that adapting the deep learning-based image understanding techniques (RetinaNet ant colony detection and PSMNet) to the proposed controller can enable the generation and tracking of the desired point in the presence of environmental disturbances.



### Towards causal generative scene models via competition of experts
- **Arxiv ID**: http://arxiv.org/abs/2004.12906v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2004.12906v1)
- **Published**: 2020-04-27 16:10:04+00:00
- **Updated**: 2020-04-27 16:10:04+00:00
- **Authors**: Julius von KÃ¼gelgen, Ivan Ustyuzhaninov, Peter Gehler, Matthias Bethge, Bernhard SchÃ¶lkopf
- **Comment**: Presented at the ICLR 2020 workshop "Causal learning for decision
  making"
- **Journal**: None
- **Summary**: Learning how to model complex scenes in a modular way with recombinable components is a pre-requisite for higher-order reasoning and acting in the physical world. However, current generative models lack the ability to capture the inherently compositional and layered nature of visual scenes. While recent work has made progress towards unsupervised learning of object-based scene representations, most models still maintain a global representation space (i.e., objects are not explicitly separated), and cannot generate scenes with novel object arrangement and depth ordering. Here, we present an alternative approach which uses an inductive bias encouraging modularity by training an ensemble of generative models (experts). During training, experts compete for explaining parts of a scene, and thus specialise on different object classes, with objects being identified as parts that re-occur across multiple scenes. Our model allows for controllable sampling of individual objects and recombination of experts in physically plausible ways. In contrast to other methods, depth layering and occlusion are handled correctly, moving this approach closer to a causal generative scene model. Experiments on simple toy data qualitatively demonstrate the conceptual advantages of the proposed approach.



### Audio-Visual Instance Discrimination with Cross-Modal Agreement
- **Arxiv ID**: http://arxiv.org/abs/2004.12943v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2004.12943v3)
- **Published**: 2020-04-27 16:59:49+00:00
- **Updated**: 2021-03-29 20:14:23+00:00
- **Authors**: Pedro Morgado, Nuno Vasconcelos, Ishan Misra
- **Comment**: None
- **Journal**: None
- **Summary**: We present a self-supervised learning approach to learn audio-visual representations from video and audio. Our method uses contrastive learning for cross-modal discrimination of video from audio and vice-versa. We show that optimizing for cross-modal discrimination, rather than within-modal discrimination, is important to learn good representations from video and audio. With this simple but powerful insight, our method achieves highly competitive performance when finetuned on action recognition tasks. Furthermore, while recent work in contrastive learning defines positive and negative samples as individual instances, we generalize this definition by exploring cross-modal agreement. We group together multiple instances as positives by measuring their similarity in both the video and audio feature spaces. Cross-modal agreement creates better positive and negative sets, which allows us to calibrate visual similarities by seeking within-modal discrimination of positive instances, and achieve significant gains on downstream tasks.



### CoReNet: Coherent 3D scene reconstruction from a single RGB image
- **Arxiv ID**: http://arxiv.org/abs/2004.12989v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2004.12989v2)
- **Published**: 2020-04-27 17:53:07+00:00
- **Updated**: 2020-08-05 15:59:48+00:00
- **Authors**: Stefan Popov, Pablo Bauszat, Vittorio Ferrari
- **Comment**: ECCV 2020, camera ready, oral
- **Journal**: None
- **Summary**: Advances in deep learning techniques have allowed recent work to reconstruct the shape of a single object given only one RBG image as input. Building on common encoder-decoder architectures for this task, we propose three extensions: (1) ray-traced skip connections that propagate local 2D information to the output 3D volume in a physically correct manner; (2) a hybrid 3D volume representation that enables building translation equivariant models, while at the same time encoding fine object details without an excessive memory footprint; (3) a reconstruction loss tailored to capture overall object geometry. Furthermore, we adapt our model to address the harder task of reconstructing multiple objects from a single image. We reconstruct all objects jointly in one pass, producing a coherent reconstruction, where all objects live in a single consistent 3D coordinate frame relative to the camera and they do not intersect in 3D space. We also handle occlusions and resolve them by hallucinating the missing object parts in the 3D volume. We validate the impact of our contributions experimentally both on synthetic data from ShapeNet as well as real images from Pix3D. Our method improves over the state-of-the-art single-object methods on both datasets. Finally, we evaluate performance quantitatively on multiple object reconstruction with synthetic scenes assembled from ShapeNet objects.



### MakeItTalk: Speaker-Aware Talking-Head Animation
- **Arxiv ID**: http://arxiv.org/abs/2004.12992v3
- **DOI**: 10.1145/3414685.3417774
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/2004.12992v3)
- **Published**: 2020-04-27 17:56:15+00:00
- **Updated**: 2021-02-25 17:57:03+00:00
- **Authors**: Yang Zhou, Xintong Han, Eli Shechtman, Jose Echevarria, Evangelos Kalogerakis, Dingzeyu Li
- **Comment**: SIGGRAPH Asia 2020, 15 pages, 13 figures
- **Journal**: None
- **Summary**: We present a method that generates expressive talking heads from a single facial image with audio as the only input. In contrast to previous approaches that attempt to learn direct mappings from audio to raw pixels or points for creating talking faces, our method first disentangles the content and speaker information in the input audio signal. The audio content robustly controls the motion of lips and nearby facial regions, while the speaker information determines the specifics of facial expressions and the rest of the talking head dynamics. Another key component of our method is the prediction of facial landmarks reflecting speaker-aware dynamics. Based on this intermediate representation, our method is able to synthesize photorealistic videos of entire talking heads with full range of motion and also animate artistic paintings, sketches, 2D cartoon characters, Japanese mangas, stylized caricatures in a single unified framework. We present extensive quantitative and qualitative evaluation of our method, in addition to user studies, demonstrating generated talking heads of significantly higher quality compared to prior state-of-the-art.



### GIMP-ML: Python Plugins for using Computer Vision Models in GIMP
- **Arxiv ID**: http://arxiv.org/abs/2004.13060v3
- **DOI**: None
- **Categories**: **cs.CV**, 65D19
- **Links**: [PDF](http://arxiv.org/pdf/2004.13060v3)
- **Published**: 2020-04-27 18:00:37+00:00
- **Updated**: 2020-10-26 16:19:38+00:00
- **Authors**: Kritik Soman
- **Comment**: 7 pages, 13 figures
- **Journal**: None
- **Summary**: This paper introduces GIMP-ML v1.1, a set of Python plugins for the widely popular GNU Image Manipulation Program (GIMP). It enables the use of recent advances in computer vision to the conventional image editing pipeline. Applications from deep learning such as monocular depth estimation, semantic segmentation, mask generative adversarial networks, image super-resolution, de-noising, de-hazing, matting, enlightening and coloring have been incorporated with GIMP through Python-based plugins. Additionally, operations on images such as k-means based color clustering have also been added. GIMP-ML relies on standard Python packages such as numpy, pytorch, open-cv, scipy. Apart from these, several image manipulation techniques using these plugins have been compiled and demonstrated in the YouTube channel (https://youtube.com/user/kritiksoman) with the objective of demonstrating the use-cases for machine learning based image modification. In addition, GIMP-ML also aims to bring the benefits of using deep learning networks used for computer vision tasks to routine image processing workflows. The code and installation procedure for configuring these plugins is available at https://github.com/kritiksoman/GIMP-ML.



### A Novel Attention-based Aggregation Function to Combine Vision and Language
- **Arxiv ID**: http://arxiv.org/abs/2004.13073v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2004.13073v2)
- **Published**: 2020-04-27 18:09:46+00:00
- **Updated**: 2020-07-13 12:22:38+00:00
- **Authors**: Matteo Stefanini, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara
- **Comment**: ICPR 2020
- **Journal**: None
- **Summary**: The joint understanding of vision and language has been recently gaining a lot of attention in both the Computer Vision and Natural Language Processing communities, with the emergence of tasks such as image captioning, image-text matching, and visual question answering. As both images and text can be encoded as sets or sequences of elements -- like regions and words -- proper reduction functions are needed to transform a set of encoded elements into a single response, like a classification or similarity score. In this paper, we propose a novel fully-attentive reduction method for vision and language. Specifically, our approach computes a set of scores for each element of each modality employing a novel variant of cross-attention, and performs a learnable and cross-modal reduction, which can be used for both classification and ranking. We test our approach on image-text matching and visual question answering, building fair comparisons with other reduction choices, on both COCO and VQA 2.0 datasets. Experimentally, we demonstrate that our approach leads to a performance increase on both tasks. Further, we conduct ablation studies to validate the role of each component of the approach.



### A scalable and efficient convolutional neural network accelerator using HLS for a System on Chip design
- **Arxiv ID**: http://arxiv.org/abs/2004.13075v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AR
- **Links**: [PDF](http://arxiv.org/pdf/2004.13075v2)
- **Published**: 2020-04-27 18:12:22+00:00
- **Updated**: 2020-10-07 06:58:55+00:00
- **Authors**: Kim Bjerge, Jonathan Horsted Schougaard, Daniel Ejnar Larsen
- **Comment**: 18 pages, 12 figures
- **Journal**: None
- **Summary**: This paper presents a configurable Convolutional Neural Network Accelerator (CNNA) for a System on Chip design (SoC). The goal was to accelerate inference of different deep learning networks on an embedded SoC platform. The presented CNNA has a scalable architecture which uses High Level Synthesis (HLS) and SystemC for the hardware accelerator. It is able to accelerate any Convolutional Neural Network (CNN) exported from Python and supports a combination of convolutional, max-pooling, and fully connected layers. A training method with fixed-point quantized weights is proposed and presented in the paper. The CNNA is template-based, enabling it to scale for different targets of the Xilinx Zynq platform. This approach enables design space exploration, which makes it possible to explore several configurations of the CNNA during C- and RTL-simulation, fitting it to the desired platform and model. The CNN VGG16 was used to test the solution on a Xilinx Ultra96 board using PYNQ. The result gave a high level of accuracy in training with an auto-scaled fixed-point Q2.14 format compared to a similar floating-point model. It was able to perform inference in 2.0 seconds, while having an average power consumption of 2.63 W, which corresponds to a power efficiency of 6.0 GOPS/W.



### The Problem of Fragmented Occlusion in Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2004.13076v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2004.13076v1)
- **Published**: 2020-04-27 18:16:01+00:00
- **Updated**: 2020-04-27 18:16:01+00:00
- **Authors**: Julian Pegoraro, Roman Pflugfelder
- **Comment**: accepted by the Austrian Joint Computer Vision and Robotics Workshop
  2020 (https://acvrw20.ist.tugraz.at)
- **Journal**: None
- **Summary**: Object detection in natural environments is still a very challenging task, even though deep learning has brought a tremendous improvement in performance over the last years. A fundamental problem of object detection based on deep learning is that neither the training data nor the suggested models are intended for the challenge of fragmented occlusion. Fragmented occlusion is much more challenging than ordinary partial occlusion and occurs frequently in natural environments such as forests. A motivating example of fragmented occlusion is object detection through foliage which is an essential requirement in green border surveillance. This paper presents an analysis of state-of-the-art detectors with imagery of green borders and proposes to train Mask R-CNN on new training data which captures explicitly the problem of fragmented occlusion. The results show clear improvements of Mask R-CNN with this new training strategy (also against other detectors) for data showing slight fragmented occlusion.



### Self-Supervised Attention Learning for Depth and Ego-motion Estimation
- **Arxiv ID**: http://arxiv.org/abs/2004.13077v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2004.13077v2)
- **Published**: 2020-04-27 18:19:22+00:00
- **Updated**: 2022-12-05 19:51:01+00:00
- **Authors**: Assem Sadek, Boris Chidlovskii
- **Comment**: None
- **Journal**: None
- **Summary**: We address the problem of depth and ego-motion estimation from image sequences. Recent advances in the domain propose to train a deep learning model for both tasks using image reconstruction in a self-supervised manner. We revise the assumptions and the limitations of the current approaches and propose two improvements to boost the performance of the depth and ego-motion estimation. We first use Lie group properties to enforce the geometric consistency between images in the sequence and their reconstructions. We then propose a mechanism to pay an attention to image regions where the image reconstruction get corrupted. We show how to integrate the attention mechanism in the form of attention gates in the pipeline and use attention coefficients as a mask. We evaluate the new architecture on the KITTI datasets and compare it to the previous techniques. We show that our approach improves the state-of-the-art results for ego-motion estimation and achieve comparable results for depth estimation.



### Compact retail shelf segmentation for mobile deployment
- **Arxiv ID**: http://arxiv.org/abs/2004.13094v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2004.13094v1)
- **Published**: 2020-04-27 18:54:36+00:00
- **Updated**: 2020-04-27 18:54:36+00:00
- **Authors**: Pratyush Kumar, Muktabh Mayank Srivastava
- **Comment**: 10 pages
- **Journal**: None
- **Summary**: The recent surge of automation in the retail industries has rapidly increased demand for applying deep learning models on mobile devices. To make the deep learning models real-time on-device, a compact efficient network becomes inevitable. In this paper, we work on one such common problem in the retail industries - Shelf segmentation. Shelf segmentation can be interpreted as a pixel-wise classification problem, i.e., each pixel is classified as to whether they belong to visible shelf edges or not. The aim is not just to segment shelf edges, but also to deploy the model on mobile devices. As there is no standard solution for such dense classification problem on mobile devices, we look at semantic segmentation architectures which can be deployed on edge. We modify low-footprint semantic segmentation architectures to perform shelf segmentation. In addressing this issue, we modified the famous U-net architecture in certain aspects to make it fit for on-devices without impacting significant drop in accuracy and also with 15X fewer parameters. In this paper, we proposed Light Weight Segmentation Network (LWSNet), a small compact model able to run fast on devices with limited memory and can train with less amount (~ 100 images) of labeled data.



### Can We Learn Heuristics For Graphical Model Inference Using Reinforcement Learning?
- **Arxiv ID**: http://arxiv.org/abs/2005.01508v2
- **DOI**: None
- **Categories**: **cs.CV**, I.4.6, I.2.6
- **Links**: [PDF](http://arxiv.org/pdf/2005.01508v2)
- **Published**: 2020-04-27 19:24:04+00:00
- **Updated**: 2020-05-05 02:20:13+00:00
- **Authors**: Safa Messaoud, Maghav Kumar, Alexander G. Schwing
- **Comment**: CVPR 2020 (Oral)
- **Journal**: None
- **Summary**: Combinatorial optimization is frequently used in computer vision. For instance, in applications like semantic segmentation, human pose estimation and action recognition, programs are formulated for solving inference in Conditional Random Fields (CRFs) to produce a structured output that is consistent with visual features of the image. However, solving inference in CRFs is in general intractable, and approximation methods are computationally demanding and limited to unary, pairwise and hand-crafted forms of higher order potentials. In this paper, we show that we can learn program heuristics, i.e., policies, for solving inference in higher order CRFs for the task of semantic segmentation, using reinforcement learning. Our method solves inference tasks efficiently without imposing any constraints on the form of the potentials. We show compelling results on the Pascal VOC and MOTS datasets.



### Clustering via torque balance with mass and distance
- **Arxiv ID**: http://arxiv.org/abs/2004.13160v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2004.13160v1)
- **Published**: 2020-04-27 20:34:06+00:00
- **Updated**: 2020-04-27 20:34:06+00:00
- **Authors**: Jie Yang, Chin-Teng Lin
- **Comment**: 28 pages, 12 figures, 7 tables
- **Journal**: None
- **Summary**: Grouping similar objects is a fundamental tool of scientific analysis, ubiquitous in disciplines from biology and chemistry to astronomy and pattern recognition. Inspired by the torque balance that exists in gravitational interactions when galaxies merge, we propose a novel clustering method based on two natural properties of the universe: mass and distance. The concept of torque describing the interactions of mass and distance forms the basis of the proposed parameter-free clustering algorithm, which harnesses torque balance to recognize any cluster, regardless of shape, size, or density. The gravitational interactions govern the merger process, while the concept of torque balance reveals partitions that do not conform to the natural order for removal. Experiments on benchmark data sets show the enormous versatility of the proposed algorithm.



### A Disentangling Invertible Interpretation Network for Explaining Latent Representations
- **Arxiv ID**: http://arxiv.org/abs/2004.13166v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2004.13166v1)
- **Published**: 2020-04-27 20:43:20+00:00
- **Updated**: 2020-04-27 20:43:20+00:00
- **Authors**: Patrick Esser, Robin Rombach, BjÃ¶rn Ommer
- **Comment**: CVPR 2020. Project Page at https://compvis.github.io/iin/
- **Journal**: None
- **Summary**: Neural networks have greatly boosted performance in computer vision by learning powerful representations of input data. The drawback of end-to-end training for maximal overall performance are black-box models whose hidden representations are lacking interpretability: Since distributed coding is optimal for latent layers to improve their robustness, attributing meaning to parts of a hidden feature vector or to individual neurons is hindered. We formulate interpretation as a translation of hidden representations onto semantic concepts that are comprehensible to the user. The mapping between both domains has to be bijective so that semantic modifications in the target domain correctly alter the original representation. The proposed invertible interpretation network can be transparently applied on top of existing architectures with no need to modify or retrain them. Consequently, we translate an original representation to an equivalent yet interpretable one and backwards without affecting the expressiveness and performance of the original. The invertible interpretation network disentangles the hidden representation into separate, semantically meaningful concepts. Moreover, we present an efficient approach to define semantic concepts by only sketching two images and also an unsupervised strategy. Experimental evaluation demonstrates the wide applicability to interpretation of existing classification and image generation networks as well as to semantically guided image manipulation.



### LSHR-Net: a hardware-friendly solution for high-resolution computational imaging using a mixed-weights neural network
- **Arxiv ID**: http://arxiv.org/abs/2004.13173v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2004.13173v1)
- **Published**: 2020-04-27 20:59:51+00:00
- **Updated**: 2020-04-27 20:59:51+00:00
- **Authors**: Fangliang Bai, Jinchao Liu, Xiaojuan Liu, Margarita Osadchy, Chao Wang, Stuart J. Gibson
- **Comment**: None
- **Journal**: None
- **Summary**: Recent work showed neural-network-based approaches to reconstructing images from compressively sensed measurements offer significant improvements in accuracy and signal compression. Such methods can dramatically boost the capability of computational imaging hardware. However, to date, there have been two major drawbacks: (1) the high-precision real-valued sensing patterns proposed in the majority of existing works can prove problematic when used with computational imaging hardware such as a digital micromirror sampling device and (2) the network structures for image reconstruction involve intensive computation, which is also not suitable for hardware deployment. To address these problems, we propose a novel hardware-friendly solution based on mixed-weights neural networks for computational imaging. In particular, learned binary-weight sensing patterns are tailored to the sampling device. Moreover, we proposed a recursive network structure for low-resolution image sampling and high-resolution reconstruction scheme. It reduces both the required number of measurements and reconstruction computation by operating convolution on small intermediate feature maps. The recursive structure further reduced the model size, making the network more computationally efficient when deployed with the hardware. Our method has been validated on benchmark datasets and achieved the state of the art reconstruction accuracy. We tested our proposed network in conjunction with a proof-of-concept hardware setup.



### A scoping review of transfer learning research on medical image analysis using ImageNet
- **Arxiv ID**: http://arxiv.org/abs/2004.13175v5
- **DOI**: 10.1016/j.compbiomed.2020.104115
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2004.13175v5)
- **Published**: 2020-04-27 21:01:45+00:00
- **Updated**: 2020-11-13 18:25:06+00:00
- **Authors**: Mohammad Amin Morid, Alireza Borjali, Guilherme Del Fiol
- **Comment**: None
- **Journal**: Computers in Biology and Medicine, 128 (2021)
- **Summary**: Objective: Employing transfer learning (TL) with convolutional neural networks (CNNs), well-trained on non-medical ImageNet dataset, has shown promising results for medical image analysis in recent years. We aimed to conduct a scoping review to identify these studies and summarize their characteristics in terms of the problem description, input, methodology, and outcome. Materials and Methods: To identify relevant studies, MEDLINE, IEEE, and ACM digital library were searched. Two investigators independently reviewed articles to determine eligibility and to extract data according to a study protocol defined a priori. Results: After screening of 8,421 articles, 102 met the inclusion criteria. Of 22 anatomical areas, eye (18%), breast (14%), and brain (12%) were the most commonly studied. Data augmentation was performed in 72% of fine-tuning TL studies versus 15% of the feature-extracting TL studies. Inception models were the most commonly used in breast related studies (50%), while VGGNet was the common in eye (44%), skin (50%) and tooth (57%) studies. AlexNet for brain (42%) and DenseNet for lung studies (38%) were the most frequently used models. Inception models were the most frequently used for studies that analyzed ultrasound (55%), endoscopy (57%), and skeletal system X-rays (57%). VGGNet was the most common for fundus (42%) and optical coherence tomography images (50%). AlexNet was the most frequent model for brain MRIs (36%) and breast X-Rays (50%). 35% of the studies compared their model with other well-trained CNN models and 33% of them provided visualization for interpretation. Discussion: This study identified the most prevalent tracks of implementation in the literature for data preparation, methodology selection and output evaluation for medical image analysis. Also, we identified several critical research gaps existing in the TL studies on medical image analysis.



### Multi-Task Image-Based Dietary Assessment for Food Recognition and Portion Size Estimation
- **Arxiv ID**: http://arxiv.org/abs/2004.13188v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2004.13188v1)
- **Published**: 2020-04-27 21:35:07+00:00
- **Updated**: 2020-04-27 21:35:07+00:00
- **Authors**: Jiangpeng He, Zeman Shao, Janine Wright, Deborah Kerr, Carol Boushey, Fengqing Zhu
- **Comment**: None
- **Journal**: None
- **Summary**: Deep learning based methods have achieved impressive results in many applications for image-based diet assessment such as food classification and food portion size estimation. However, existing methods only focus on one task at a time, making it difficult to apply in real life when multiple tasks need to be processed together. In this work, we propose an end-to-end multi-task framework that can achieve both food classification and food portion size estimation. We introduce a food image dataset collected from a nutrition study where the groundtruth food portion is provided by registered dietitians. The multi-task learning uses L2-norm based soft parameter sharing to train the classification and regression tasks simultaneously. We also propose the use of cross-domain feature adaptation together with normalization to further improve the performance of food portion size estimation. Our results outperforms the baseline methods for both classification accuracy and mean absolute error for portion estimation, which shows great potential for advancing the field of image-based dietary assessment.



### Graph2Plan: Learning Floorplan Generation from Layout Graphs
- **Arxiv ID**: http://arxiv.org/abs/2004.13204v1
- **DOI**: 10.1145/3386569.3392391
- **Categories**: **cs.CV**, cs.GR, 68T45, 68U05, I.3.6; I.2.10
- **Links**: [PDF](http://arxiv.org/pdf/2004.13204v1)
- **Published**: 2020-04-27 23:17:36+00:00
- **Updated**: 2020-04-27 23:17:36+00:00
- **Authors**: Ruizhen Hu, Zeyu Huang, Yuhan Tang, Oliver van Kaick, Hao Zhang, Hui Huang
- **Comment**: None
- **Journal**: ACM Transactions on Graphics 2020
- **Summary**: We introduce a learning framework for automated floorplan generation which combines generative modeling using deep neural networks and user-in-the-loop designs to enable human users to provide sparse design constraints. Such constraints are represented by a layout graph. The core component of our learning framework is a deep neural network, Graph2Plan, which converts a layout graph, along with a building boundary, into a floorplan that fulfills both the layout and boundary constraints. Given an input building boundary, we allow a user to specify room counts and other layout constraints, which are used to retrieve a set of floorplans, with their associated layout graphs, from a database. For each retrieved layout graph, along with the input boundary, Graph2Plan first generates a corresponding raster floorplan image, and then a refined set of boxes representing the rooms. Graph2Plan is trained on RPLAN, a large-scale dataset consisting of 80K annotated floorplans. The network is mainly based on convolutional processing over both the layout graph, via a graph neural network (GNN), and the input building boundary, as well as the raster floorplan images, via conventional image convolution.



