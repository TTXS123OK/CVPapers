# Arxiv Papers in cs.CV on 2020-05-20
### FashionBERT: Text and Image Matching with Adaptive Loss for Cross-modal Retrieval
- **Arxiv ID**: http://arxiv.org/abs/2005.09801v2
- **DOI**: None
- **Categories**: **cs.IR**, cs.CV, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2005.09801v2)
- **Published**: 2020-05-20 00:41:00+00:00
- **Updated**: 2020-05-29 05:56:10+00:00
- **Authors**: Dehong Gao, Linbo Jin, Ben Chen, Minghui Qiu, Peng Li, Yi Wei, Yi Hu, Hao Wang
- **Comment**: 10 pages, to be published in SIGIR20 Industry Track
- **Journal**: None
- **Summary**: In this paper, we address the text and image matching in cross-modal retrieval of the fashion industry. Different from the matching in the general domain, the fashion matching is required to pay much more attention to the fine-grained information in the fashion images and texts. Pioneer approaches detect the region of interests (i.e., RoIs) from images and use the RoI embeddings as image representations. In general, RoIs tend to represent the "object-level" information in the fashion images, while fashion texts are prone to describe more detailed information, e.g. styles, attributes. RoIs are thus not fine-grained enough for fashion text and image matching. To this end, we propose FashionBERT, which leverages patches as image features. With the pre-trained BERT model as the backbone network, FashionBERT learns high level representations of texts and images. Meanwhile, we propose an adaptive loss to trade off multitask learning in the FashionBERT modeling. Two tasks (i.e., text and image matching and cross-modal retrieval) are incorporated to evaluate FashionBERT. On the public dataset, experiments demonstrate FashionBERT achieves significant improvements in performances than the baseline and state-of-the-art approaches. In practice, FashionBERT is applied in a concrete cross-modal retrieval application. We provide the detailed matching performance and inference efficiency analysis.



### Active Speakers in Context
- **Arxiv ID**: http://arxiv.org/abs/2005.09812v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.SD, eess.AS
- **Links**: [PDF](http://arxiv.org/pdf/2005.09812v1)
- **Published**: 2020-05-20 01:14:23+00:00
- **Updated**: 2020-05-20 01:14:23+00:00
- **Authors**: Juan Leon Alcazar, Fabian Caba Heilbron, Long Mai, Federico Perazzi, Joon-Young Lee, Pablo Arbelaez, Bernard Ghanem
- **Comment**: None
- **Journal**: None
- **Summary**: Current methods for active speak er detection focus on modeling short-term audiovisual information from a single speaker. Although this strategy can be enough for addressing single-speaker scenarios, it prevents accurate detection when the task is to identify who of many candidate speakers are talking. This paper introduces the Active Speaker Context, a novel representation that models relationships between multiple speakers over long time horizons. Our Active Speaker Context is designed to learn pairwise and temporal relations from an structured ensemble of audio-visual observations. Our experiments show that a structured feature ensemble already benefits the active speaker detection performance. Moreover, we find that the proposed Active Speaker Context improves the state-of-the-art on the AVA-ActiveSpeaker dataset achieving a mAP of 87.1%. We present ablation studies that verify that this result is a direct consequence of our long-term multi-speaker analysis.



### Relevant Region Prediction for Crowd Counting
- **Arxiv ID**: http://arxiv.org/abs/2005.09816v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.09816v1)
- **Published**: 2020-05-20 01:53:24+00:00
- **Updated**: 2020-05-20 01:53:24+00:00
- **Authors**: Xinya Chen, Yanrui Bin, Changxin Gao, Nong Sang, Hao Tang
- **Comment**: accepted by Neurocomputing
- **Journal**: None
- **Summary**: Crowd counting is a concerned and challenging task in computer vision. Existing density map based methods excessively focus on the individuals' localization which harms the crowd counting performance in highly congested scenes. In addition, the dependency between the regions of different density is also ignored. In this paper, we propose Relevant Region Prediction (RRP) for crowd counting, which consists of the Count Map and the Region Relation-Aware Module (RRAM). Each pixel in the count map represents the number of heads falling into the corresponding local area in the input image, which discards the detailed spatial information and forces the network pay more attention to counting rather than localizing individuals. Based on the Graph Convolutional Network (GCN), Region Relation-Aware Module is proposed to capture and exploit the important region dependency. The module builds a fully connected directed graph between the regions of different density where each node (region) is represented by weighted global pooled feature, and GCN is learned to map this region graph to a set of relation-aware regions representations. Experimental results on three datasets show that our method obviously outperforms other existing state-of-the-art methods.



### Attention-based network for low-light image enhancement
- **Arxiv ID**: http://arxiv.org/abs/2005.09829v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2005.09829v2)
- **Published**: 2020-05-20 02:43:02+00:00
- **Updated**: 2020-05-21 01:55:38+00:00
- **Authors**: Cheng Zhang, Qingsen Yan, Yu zhu, Xianjun Li, Jinqiu Sun, Yanning Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: The captured images under low light conditions often suffer insufficient brightness and notorious noise. Hence, low-light image enhancement is a key challenging task in computer vision. A variety of methods have been proposed for this task, but these methods often failed in an extreme low-light environment and amplified the underlying noise in the input image. To address such a difficult problem, this paper presents a novel attention-based neural network to generate high-quality enhanced low-light images from the raw sensor data. Specifically, we first employ attention strategy (i.e. channel attention and spatial attention modules) to suppress undesired chromatic aberration and noise. The channel attention module guides the network to refine redundant colour features. The spatial attention module focuses on denoising by taking advantage of the non-local correlation in the image. Furthermore, we propose a new pooling layer, called inverted shuffle layer, which adaptively selects useful information from previous features. Extensive experiments demonstrate the superiority of the proposed network in terms of suppressing the chromatic aberration and noise artifacts in enhancement, especially when the low-light image has severe noise.



### Deep Learning for LiDAR Point Clouds in Autonomous Driving: A Review
- **Arxiv ID**: http://arxiv.org/abs/2005.09830v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.09830v1)
- **Published**: 2020-05-20 03:01:40+00:00
- **Updated**: 2020-05-20 03:01:40+00:00
- **Authors**: Ying Li, Lingfei Ma, Zilong Zhong, Fei Liu, Dongpu Cao, Jonathan Li, Michael A. Chapman
- **Comment**: 21 pages, submitted to IEEE Transactions on Neural Networks and
  Learning Systems
- **Journal**: None
- **Summary**: Recently, the advancement of deep learning in discriminative feature learning from 3D LiDAR data has led to rapid development in the field of autonomous driving. However, automated processing uneven, unstructured, noisy, and massive 3D point clouds is a challenging and tedious task. In this paper, we provide a systematic review of existing compelling deep learning architectures applied in LiDAR point clouds, detailing for specific tasks in autonomous driving such as segmentation, detection, and classification. Although several published research papers focus on specific topics in computer vision for autonomous vehicles, to date, no general survey on deep learning applied in LiDAR point clouds for autonomous vehicles exists. Thus, the goal of this paper is to narrow the gap in this topic. More than 140 key contributions in the recent five years are summarized in this survey, including the milestone 3D deep architectures, the remarkable deep learning applications in 3D semantic segmentation, object detection, and classification; specific datasets, evaluation metrics, and the state of the art performance. Finally, we conclude the remaining challenges and future researches.



### Interactive exploration of population scale pharmacoepidemiology datasets
- **Arxiv ID**: http://arxiv.org/abs/2005.09890v1
- **DOI**: 10.1145/3388440.3414862
- **Categories**: **q-bio.QM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2005.09890v1)
- **Published**: 2020-05-20 07:34:50+00:00
- **Updated**: 2020-05-20 07:34:50+00:00
- **Authors**: Tengel Ekrem Skar, Einar Holsbø, Kristian Svendsen, Lars Ailo Bongo
- **Comment**: None
- **Journal**: None
- **Summary**: Population-scale drug prescription data linked with adverse drug reaction (ADR) data supports the fitting of models large enough to detect drug use and ADR patterns that are not detectable using traditional methods on smaller datasets. However, detecting ADR patterns in large datasets requires tools for scalable data processing, machine learning for data analysis, and interactive visualization. To our knowledge no existing pharmacoepidemiology tool supports all three requirements. We have therefore created a tool for interactive exploration of patterns in prescription datasets with millions of samples. We use Spark to preprocess the data for machine learning and for analyses using SQL queries. We have implemented models in Keras and the scikit-learn framework. The model results are visualized and interpreted using live Python coding in Jupyter. We apply our tool to explore a 384 million prescription data set from the Norwegian Prescription Database combined with a 62 million prescriptions for elders that were hospitalized. We preprocess the data in two minutes, train models in seconds, and plot the results in milliseconds. Our results show the power of combining computational power, short computation times, and ease of use for analysis of population scale pharmacoepidemiology datasets. The code is open source and available at: https://github.com/uit-hdl/norpd_prescription_analyses



### Rethinking Performance Estimation in Neural Architecture Search
- **Arxiv ID**: http://arxiv.org/abs/2005.09917v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.09917v1)
- **Published**: 2020-05-20 09:01:44+00:00
- **Updated**: 2020-05-20 09:01:44+00:00
- **Authors**: Xiawu Zheng, Rongrong Ji, Qiang Wang, Qixiang Ye, Zhenguo Li, Yonghong Tian, Qi Tian
- **Comment**: None
- **Journal**: None
- **Summary**: Neural architecture search (NAS) remains a challenging problem, which is attributed to the indispensable and time-consuming component of performance estimation (PE). In this paper, we provide a novel yet systematic rethinking of PE in a resource constrained regime, termed budgeted PE (BPE), which precisely and effectively estimates the performance of an architecture sampled from an architecture space. Since searching an optimal BPE is extremely time-consuming as it requires to train a large number of networks for evaluation, we propose a Minimum Importance Pruning (MIP) approach. Given a dataset and a BPE search space, MIP estimates the importance of hyper-parameters using random forest and subsequently prunes the minimum one from the next iteration. In this way, MIP effectively prunes less important hyper-parameters to allocate more computational resource on more important ones, thus achieving an effective exploration. By combining BPE with various search algorithms including reinforcement learning, evolution algorithm, random search, and differentiable architecture search, we achieve 1, 000x of NAS speed up with a negligible performance drop comparing to the SOTA



### Range Conditioned Dilated Convolutions for Scale Invariant 3D Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2005.09927v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2005.09927v3)
- **Published**: 2020-05-20 09:24:43+00:00
- **Updated**: 2021-01-22 14:52:57+00:00
- **Authors**: Alex Bewley, Pei Sun, Thomas Mensink, Dragomir Anguelov, Cristian Sminchisescu
- **Comment**: CoRL 2020
- **Journal**: None
- **Summary**: This paper presents a novel 3D object detection framework that processes LiDAR data directly on its native representation: range images. Benefiting from the compactness of range images, 2D convolutions can efficiently process dense LiDAR data of a scene. To overcome scale sensitivity in this perspective view, a novel range-conditioned dilation (RCD) layer is proposed to dynamically adjust a continuous dilation rate as a function of the measured range. Furthermore, localized soft range gating combined with a 3D box-refinement stage improves robustness in occluded areas, and produces overall more accurate bounding box predictions. On the public large-scale Waymo Open Dataset, our method sets a new baseline for range-based 3D detection, outperforming multiview and voxel-based methods over all ranges with unparalleled performance at long range detection.



### Iterative Network for Image Super-Resolution
- **Arxiv ID**: http://arxiv.org/abs/2005.09964v3
- **DOI**: 10.1109/TMM.2021.3078615
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2005.09964v3)
- **Published**: 2020-05-20 11:11:47+00:00
- **Updated**: 2022-01-05 01:56:44+00:00
- **Authors**: Yuqing Liu, Shiqi Wang, Jian Zhang, Shanshe Wang, Siwei Ma, Wen Gao
- **Comment**: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible
- **Journal**: None
- **Summary**: Single image super-resolution (SISR), as a traditional ill-conditioned inverse problem, has been greatly revitalized by the recent development of convolutional neural networks (CNN). These CNN-based methods generally map a low-resolution image to its corresponding high-resolution version with sophisticated network structures and loss functions, showing impressive performances. This paper provides a new insight on conventional SISR algorithm, and proposes a substantially different approach relying on the iterative optimization. A novel iterative super-resolution network (ISRN) is proposed on top of the iterative optimization. We first analyze the observation model of image SR problem, inspiring a feasible solution by mimicking and fusing each iteration in a more general and efficient manner. Considering the drawbacks of batch normalization, we propose a feature normalization (F-Norm, FN) method to regulate the features in network. Furthermore, a novel block with FN is developed to improve the network representation, termed as FNB. Residual-in-residual structure is proposed to form a very deep network, which groups FNBs with a long skip connection for better information delivery and stabling the training phase. Extensive experimental results on testing benchmarks with bicubic (BI) degradation show our ISRN can not only recover more structural information, but also achieve competitive or better PSNR/SSIM results with much fewer parameters compared to other works. Besides BI, we simulate the real-world degradation with blur-downscale (BD) and downscale-noise (DN). ISRN and its extension ISRN+ both achieve better performance than others with BD and DN degradation models.



### Dynamic Refinement Network for Oriented and Densely Packed Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2005.09973v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.09973v2)
- **Published**: 2020-05-20 11:35:50+00:00
- **Updated**: 2020-06-10 23:59:58+00:00
- **Authors**: Xingjia Pan, Yuqiang Ren, Kekai Sheng, Weiming Dong, Haolei Yuan, Xiaowei Guo, Chongyang Ma, Changsheng Xu
- **Comment**: Accepted by CVPR 2020 as Oral
- **Journal**: None
- **Summary**: Object detection has achieved remarkable progress in the past decade. However, the detection of oriented and densely packed objects remains challenging because of following inherent reasons: (1) receptive fields of neurons are all axis-aligned and of the same shape, whereas objects are usually of diverse shapes and align along various directions; (2) detection models are typically trained with generic knowledge and may not generalize well to handle specific objects at test time; (3) the limited dataset hinders the development on this task. To resolve the first two issues, we present a dynamic refinement network that consists of two novel components, i.e., a feature selection module (FSM) and a dynamic refinement head (DRH). Our FSM enables neurons to adjust receptive fields in accordance with the shapes and orientations of target objects, whereas the DRH empowers our model to refine the prediction dynamically in an object-aware manner. To address the limited availability of related benchmarks, we collect an extensive and fully annotated dataset, namely, SKU110K-R, which is relabeled with oriented bounding boxes based on SKU110K. We perform quantitative evaluations on several publicly available benchmarks including DOTA, HRSC2016, SKU110K, and our own SKU110K-R dataset. Experimental results show that our method achieves consistent and substantial gains compared with baseline approaches. The code and dataset are available at https://github.com/Anymake/DRN_CVPR2020.



### AutoML Segmentation for 3D Medical Image Data: Contribution to the MSD Challenge 2018
- **Arxiv ID**: http://arxiv.org/abs/2005.09978v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2005.09978v1)
- **Published**: 2020-05-20 11:47:02+00:00
- **Updated**: 2020-05-20 11:47:02+00:00
- **Authors**: Oliver Rippel, Leon Weninger, Dorit Merhof
- **Comment**: None
- **Journal**: None
- **Summary**: Fueled by recent advances in machine learning, there has been tremendous progress in the field of semantic segmentation for the medical image computing community. However, developed algorithms are often optimized and validated by hand based on one task only. In combination with small datasets, interpreting the generalizability of the results is often difficult. The Medical Segmentation Decathlon challenge addresses this problem, and aims to facilitate development of generalizable 3D semantic segmentation algorithms that require no manual parametrization. Such an algorithm was developed and is presented in this paper. It consists of a 3D convolutional neural network with encoder-decoder architecture employing residual-connections, skip-connections and multi-level generation of predictions. It works on anisotropic voxel-geometries and has anisotropic depth, i.e., the number of downsampling steps is a task-specific parameter. These depths are automatically inferred for each task prior to training. By combining this flexible architecture with on-the-fly data augmentation and little-to-no pre-- or postprocessing, promising results could be achieved. The code developed for this challenge will be available online after the final deadline at: https://github.com/ORippler/MSD_2018



### A Modified Fourier-Mellin Approach for Source Device Identification on Stabilized Videos
- **Arxiv ID**: http://arxiv.org/abs/2005.09984v1
- **DOI**: None
- **Categories**: **cs.MM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2005.09984v1)
- **Published**: 2020-05-20 12:06:40+00:00
- **Updated**: 2020-05-20 12:06:40+00:00
- **Authors**: Sara Mandelli, Fabrizio Argenti, Paolo Bestagini, Massimo Iuliani, Alessandro Piva, Stefano Tubaro
- **Comment**: None
- **Journal**: None
- **Summary**: To decide whether a digital video has been captured by a given device, multimedia forensic tools usually exploit characteristic noise traces left by the camera sensor on the acquired frames. This analysis requires that the noise pattern characterizing the camera and the noise pattern extracted from video frames under analysis are geometrically aligned. However, in many practical scenarios this does not occur, thus a re-alignment or synchronization has to be performed. Current solutions often require time consuming search of the realignment transformation parameters. In this paper, we propose to overcome this limitation by searching scaling and rotation parameters in the frequency domain. The proposed algorithm tested on real videos from a well-known state-of-the-art dataset shows promising results.



### Automated Copper Alloy Grain Size Evaluation Using a Deep-learning CNN
- **Arxiv ID**: http://arxiv.org/abs/2005.09634v1
- **DOI**: None
- **Categories**: **cs.CV**, cond-mat.mtrl-sci, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2005.09634v1)
- **Published**: 2020-05-20 13:13:38+00:00
- **Updated**: 2020-05-20 13:13:38+00:00
- **Authors**: George S. Baggs, Paul Guerrier, Andrew Loeb, Jason C. Jones
- **Comment**: None
- **Journal**: None
- **Summary**: Moog Inc. has automated the evaluation of copper (Cu) alloy grain size using a deep-learning convolutional neural network (CNN). The proof-of-concept automated image acquisition and batch-wise image processing offers the potential for significantly reduced labor, improved accuracy of grain evaluation, and decreased overall turnaround times for approving Cu alloy bar stock for use in flight critical aircraft hardware. A classification accuracy of 91.1% on individual sub-images of the Cu alloy coupons was achieved. Process development included minimizing the variation in acquired image color, brightness, and resolution to create a dataset with 12300 sub-images, and then optimizing the CNN hyperparameters on this dataset using statistical design of experiments (DoE).   Over the development of the automated Cu alloy grain size evaluation, a degree of "explainability" in the artificial intelligence (XAI) output was realized, based on the decomposition of the large raw images into many smaller dataset sub-images, through the ability to explain the CNN ensemble image output via inspection of the classification results from the individual smaller sub-images.



### Deep learning with 4D spatio-temporal data representations for OCT-based force estimation
- **Arxiv ID**: http://arxiv.org/abs/2005.10033v1
- **DOI**: 10.1016/j.media.2020.101730
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2005.10033v1)
- **Published**: 2020-05-20 13:30:36+00:00
- **Updated**: 2020-05-20 13:30:36+00:00
- **Authors**: Nils Gessert, Marcel Bengs, Matthias Schlüter, Alexander Schlaefer
- **Comment**: Accepted for publication in Medical Image Analysis
- **Journal**: None
- **Summary**: Estimating the forces acting between instruments and tissue is a challenging problem for robot-assisted minimally-invasive surgery. Recently, numerous vision-based methods have been proposed to replace electro-mechanical approaches. Moreover, optical coherence tomography (OCT) and deep learning have been used for estimating forces based on deformation observed in volumetric image data. The method demonstrated the advantage of deep learning with 3D volumetric data over 2D depth images for force estimation. In this work, we extend the problem of deep learning-based force estimation to 4D spatio-temporal data with streams of 3D OCT volumes. For this purpose, we design and evaluate several methods extending spatio-temporal deep learning to 4D which is largely unexplored so far. Furthermore, we provide an in-depth analysis of multi-dimensional image data representations for force estimation, comparing our 4D approach to previous, lower-dimensional methods. Also, we analyze the effect of temporal information and we study the prediction of short-term future force values, which could facilitate safety features. For our 4D force estimation architectures, we find that efficient decoupling of spatial and temporal processing is advantageous. We show that using 4D spatio-temporal data outperforms all previously used data representations with a mean absolute error of 10.7mN. We find that temporal information is valuable for force estimation and we demonstrate the feasibility of force prediction.



### Data Consistent CT Reconstruction from Insufficient Data with Learned Prior Images
- **Arxiv ID**: http://arxiv.org/abs/2005.10034v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2005.10034v1)
- **Published**: 2020-05-20 13:30:49+00:00
- **Updated**: 2020-05-20 13:30:49+00:00
- **Authors**: Yixing Huang, Alexander Preuhs, Michael Manhart, Guenter Lauritsch, Andreas Maier
- **Comment**: 10 pages, 9 figures
- **Journal**: None
- **Summary**: Image reconstruction from insufficient data is common in computed tomography (CT), e.g., image reconstruction from truncated data, limited-angle data and sparse-view data. Deep learning has achieved impressive results in this field. However, the robustness of deep learning methods is still a concern for clinical applications due to the following two challenges: a) With limited access to sufficient training data, a learned deep learning model may not generalize well to unseen data; b) Deep learning models are sensitive to noise. Therefore, the quality of images processed by neural networks only may be inadequate. In this work, we investigate the robustness of deep learning in CT image reconstruction by showing false negative and false positive lesion cases. Since learning-based images with incorrect structures are likely not consistent with measured projection data, we propose a data consistent reconstruction (DCR) method to improve their image quality, which combines the advantages of compressed sensing and deep learning: First, a prior image is generated by deep learning. Afterwards, unmeasured projection data are inpainted by forward projection of the prior image. Finally, iterative reconstruction with reweighted total variation regularization is applied, integrating data consistency for measured data and learned prior information for missing data. The efficacy of the proposed method is demonstrated in cone-beam CT with truncated data, limited-angle data and sparse-view data, respectively. For example, for truncated data, DCR achieves a mean root-mean-square error of 24 HU and a mean structure similarity index of 0.999 inside the field-of-view for different patients in the noisy case, while the state-of-the-art U-Net method achieves 55 HU and 0.995 respectively for these two metrics.



### Model-Based Robust Deep Learning: Generalizing to Natural, Out-of-Distribution Data
- **Arxiv ID**: http://arxiv.org/abs/2005.10247v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2005.10247v2)
- **Published**: 2020-05-20 13:46:31+00:00
- **Updated**: 2020-11-02 13:20:37+00:00
- **Authors**: Alexander Robey, Hamed Hassani, George J. Pappas
- **Comment**: None
- **Journal**: None
- **Summary**: While deep learning has resulted in major breakthroughs in many application domains, the frameworks commonly used in deep learning remain fragile to artificially-crafted and imperceptible changes in the data. In response to this fragility, adversarial training has emerged as a principled approach for enhancing the robustness of deep learning with respect to norm-bounded perturbations. However, there are other sources of fragility for deep learning that are arguably more common and less thoroughly studied. Indeed, natural variation such as lighting or weather conditions can significantly degrade the accuracy of trained neural networks, proving that such natural variation presents a significant challenge for deep learning.   In this paper, we propose a paradigm shift from perturbation-based adversarial robustness toward model-based robust deep learning. Our objective is to provide general training algorithms that can be used to train deep neural networks to be robust against natural variation in data. Critical to our paradigm is first obtaining a model of natural variation which can be used to vary data over a range of natural conditions. Such models may be either known a priori or else learned from data. In the latter case, we show that deep generative models can be used to learn models of natural variation that are consistent with realistic conditions. We then exploit such models in three novel model-based robust training algorithms in order to enhance the robustness of deep learning with respect to the given model. Our extensive experiments show that across a variety of naturally-occurring conditions and across various datasets, deep neural networks trained with our model-based algorithms significantly outperform both standard deep learning algorithms as well as norm-bounded robust deep learning algorithms.



### Lung Segmentation from Chest X-rays using Variational Data Imputation
- **Arxiv ID**: http://arxiv.org/abs/2005.10052v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2005.10052v2)
- **Published**: 2020-05-20 13:52:03+00:00
- **Updated**: 2020-07-07 06:12:42+00:00
- **Authors**: Raghavendra Selvan, Erik B. Dam, Nicki S. Detlefsen, Sofus Rischel, Kaining Sheng, Mads Nielsen, Akshay Pai
- **Comment**: Accepted to be presented at the first Workshop on the Art of Learning
  with Missing Values (Artemiss) hosted by the 37th International Conference on
  Machine Learning (ICML). Source code, training data and the trained models
  are available here: https://github.com/raghavian/lungVAE/
- **Journal**: None
- **Summary**: Pulmonary opacification is the inflammation in the lungs caused by many respiratory ailments, including the novel corona virus disease 2019 (COVID-19). Chest X-rays (CXRs) with such opacifications render regions of lungs imperceptible, making it difficult to perform automated image analysis on them. In this work, we focus on segmenting lungs from such abnormal CXRs as part of a pipeline aimed at automated risk scoring of COVID-19 from CXRs. We treat the high opacity regions as missing data and present a modified CNN-based image segmentation network that utilizes a deep generative model for data imputation. We train this model on normal CXRs with extensive data augmentation and demonstrate the usefulness of this model to extend to cases with extreme abnormalities.



### Map Generation from Large Scale Incomplete and Inaccurate Data Labels
- **Arxiv ID**: http://arxiv.org/abs/2005.10053v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV, I.2.10
- **Links**: [PDF](http://arxiv.org/pdf/2005.10053v1)
- **Published**: 2020-05-20 13:59:43+00:00
- **Updated**: 2020-05-20 13:59:43+00:00
- **Authors**: Rui Zhang, Conrad Albrecht, Wei Zhang, Xiaodong Cui, Ulrich Finkler, David Kung, Siyuan Lu
- **Comment**: This paper is accepted by KDD 2020
- **Journal**: None
- **Summary**: Accurately and globally mapping human infrastructure is an important and challenging task with applications in routing, regulation compliance monitoring, and natural disaster response management etc.. In this paper we present progress in developing an algorithmic pipeline and distributed compute system that automates the process of map creation using high resolution aerial images. Unlike previous studies, most of which use datasets that are available only in a few cities across the world, we utilizes publicly available imagery and map data, both of which cover the contiguous United States (CONUS). We approach the technical challenge of inaccurate and incomplete training data adopting state-of-the-art convolutional neural network architectures such as the U-Net and the CycleGAN to incrementally generate maps with increasingly more accurate and more complete labels of man-made infrastructure such as roads and houses. Since scaling the mapping task to CONUS calls for parallelization, we then adopted an asynchronous distributed stochastic parallel gradient descent training scheme to distribute the computational workload onto a cluster of GPUs with nearly linear speed-up.



### Classifying Suspicious Content in Tor Darknet
- **Arxiv ID**: http://arxiv.org/abs/2005.10086v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.10086v2)
- **Published**: 2020-05-20 14:49:02+00:00
- **Updated**: 2020-05-21 15:45:54+00:00
- **Authors**: Eduardo Fidalgo Fernandez, Roberto Andrés Vasco Carofilis, Francisco Jáñez Martino, Pablo Blanco Medina
- **Comment**: To be published on the JNIC 2020 Conference. Summary of already
  published research
- **Journal**: None
- **Summary**: One of the tasks of law enforcement agencies is to find evidence of criminal activity in the Darknet. However, visiting thousands of domains to locate visual information containing illegal acts manually requires a considerable amount of time and resources. Furthermore, the background of the images can pose a challenge when performing classification. To solve this problem, in this paper, we explore the automatic classification Tor Darknet images using Semantic Attention Keypoint Filtering, a strategy that filters non-significant features at a pixel level that do not belong to the object of interest, by combining saliency maps with Bag of Visual Words (BoVW). We evaluated SAKF on a custom Tor image dataset against CNN features: MobileNet v1 and Resnet50, and BoVW using dense SIFT descriptors, achieving a result of 87.98% accuracy and outperforming all other approaches.



### Perceptual Hashing applied to Tor domains recognition
- **Arxiv ID**: http://arxiv.org/abs/2005.10090v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.10090v2)
- **Published**: 2020-05-20 14:53:36+00:00
- **Updated**: 2020-05-21 15:35:25+00:00
- **Authors**: Rubel Biswas, Roberto A. Vasco-Carofilis, Eduardo Fidalgo Fernandez, Francisco Jáñez Martino, Pablo Blanco Medina
- **Comment**: To be published on the JNIC 2020 Conference. Already published
  research summary
- **Journal**: None
- **Summary**: The Tor darknet hosts different types of illegal content, which are monitored by cybersecurity agencies. However, manually classifying Tor content can be slow and error-prone. To support this task, we introduce Frequency-Dominant Neighborhood Structure (F-DNS), a new perceptual hashing method for automatically classifying domains by their screenshots. First, we evaluated F-DNS using images subject to various content preserving operations. We compared them with their original images, achieving better correlation coefficients than other state-of-the-art methods, especially in the case of rotation. Then, we applied F-DNS to categorize Tor domains using the Darknet Usage Service Images-2K (DUSI-2K), a dataset with screenshots of active Tor service domains. Finally, we measured the performance of F-DNS against an image classification approach and a state-of-the-art hashing method. Our proposal obtained 98.75% accuracy in Tor images, surpassing all other methods compared.



### Label Efficient Visual Abstractions for Autonomous Driving
- **Arxiv ID**: http://arxiv.org/abs/2005.10091v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2005.10091v2)
- **Published**: 2020-05-20 14:53:54+00:00
- **Updated**: 2020-07-16 16:57:52+00:00
- **Authors**: Aseem Behl, Kashyap Chitta, Aditya Prakash, Eshed Ohn-Bar, Andreas Geiger
- **Comment**: International Conference on Intelligent Robots and Systems (IROS),
  2020. First two authors contributed equally, listed in alphabetical order
- **Journal**: None
- **Summary**: It is well known that semantic segmentation can be used as an effective intermediate representation for learning driving policies. However, the task of street scene semantic segmentation requires expensive annotations. Furthermore, segmentation algorithms are often trained irrespective of the actual driving task, using auxiliary image-space loss functions which are not guaranteed to maximize driving metrics such as safety or distance traveled per intervention. In this work, we seek to quantify the impact of reducing segmentation annotation costs on learned behavior cloning agents. We analyze several segmentation-based intermediate representations. We use these visual abstractions to systematically study the trade-off between annotation efficiency and driving performance, i.e., the types of classes labeled, the number of image samples used to learn the visual abstraction model, and their granularity (e.g., object masks vs. 2D bounding boxes). Our analysis uncovers several practical insights into how segmentation-based visual abstractions can be exploited in a more label efficient manner. Surprisingly, we find that state-of-the-art driving performance can be achieved with orders of magnitude reduction in annotation cost. Beyond label efficiency, we find several additional training benefits when leveraging visual abstractions, such as a significant reduction in the variance of the learned policy when compared to state-of-the-art end-to-end driving models.



### Classification of Industrial Control Systems screenshots using Transfer Learning
- **Arxiv ID**: http://arxiv.org/abs/2005.10098v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.10098v3)
- **Published**: 2020-05-20 15:00:55+00:00
- **Updated**: 2020-09-11 10:16:42+00:00
- **Authors**: Pablo Blanco Medina, Eduardo Fidalgo Fernandez, Enrique Alegre, Francisco Jáñez Martino, Roberto A. Vasco-Carofilis, Víctor Fidalgo Villar
- **Comment**: None
- **Journal**: None
- **Summary**: Industrial Control Systems depend heavily on security and monitoring protocols. Several tools are available for this purpose, which scout vulnerabilities and take screenshots from various control panels for later analysis. However, they do not adequately classify images into specific control groups, which can difficult operations performed by manual operators. In order to solve this problem, we use transfer learning with five CNN architectures, pre-trained on Imagenet, to determine which one best classifies screenshots obtained from Industrial Controls Systems. Using 337 manually labeled images, we train these architectures and study their performance both in accuracy and CPU and GPU time. We find out that MobilenetV1 is the best architecture based on its 97,95% of F1-Score, and its speed on CPU with 0.47 seconds per image. In systems where time is critical and GPU is available, VGG16 is preferable because it takes 0.04 seconds to process images, but dropping performance to 87,67%.



### Discriminative Dictionary Design for Action Classification in Still Images and Videos
- **Arxiv ID**: http://arxiv.org/abs/2005.10149v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.10149v2)
- **Published**: 2020-05-20 15:56:41+00:00
- **Updated**: 2020-06-06 17:36:11+00:00
- **Authors**: Abhinaba Roy, Biplab Banerjee, Amir Hussain, Soujanya Poria
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we address the problem of action recognition from still images and videos. Traditional local features such as SIFT, STIP etc. invariably pose two potential problems: 1) they are not evenly distributed in different entities of a given category and 2) many of such features are not exclusive of the visual concept the entities represent. In order to generate a dictionary taking the aforementioned issues into account, we propose a novel discriminative method for identifying robust and category specific local features which maximize the class separability to a greater extent. Specifically, we pose the selection of potent local descriptors as filtering based feature selection problem which ranks the local features per category based on a novel measure of distinctiveness. The underlying visual entities are subsequently represented based on the learned dictionary and this stage is followed by action classification using the random forest model followed by label propagation refinement. The framework is validated on the action recognition datasets based on still images (Stanford-40) as well as videos (UCF-50) and exhibits superior performances than the representative methods from the literature.



### Reducing Overlearning through Disentangled Representations by Suppressing Unknown Tasks
- **Arxiv ID**: http://arxiv.org/abs/2005.10220v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2005.10220v1)
- **Published**: 2020-05-20 17:31:44+00:00
- **Updated**: 2020-05-20 17:31:44+00:00
- **Authors**: Naveen Panwar, Tarun Tater, Anush Sankaran, Senthil Mani
- **Comment**: Added appendix with additional results
- **Journal**: None
- **Summary**: Existing deep learning approaches for learning visual features tend to overlearn and extract more information than what is required for the task at hand. From a privacy preservation perspective, the input visual information is not protected from the model; enabling the model to become more intelligent than it is trained to be. Current approaches for suppressing additional task learning assume the presence of ground truth labels for the tasks to be suppressed during training time. In this research, we propose a three-fold novel contribution: (i) a model-agnostic solution for reducing model overlearning by suppressing all the unknown tasks, (ii) a novel metric to measure the trust score of a trained deep learning model, and (iii) a simulated benchmark dataset, PreserveTask, having five different fundamental image classification tasks to study the generalization nature of models. In the first set of experiments, we learn disentangled representations and suppress overlearning of five popular deep learning models: VGG16, VGG19, Inception-v1, MobileNet, and DenseNet on PreserverTask dataset. Additionally, we show results of our framework on color-MNIST dataset and practical applications of face attribute preservation in Diversity in Faces (DiF) and IMDB-Wiki dataset.



### Compute-Bound and Low-Bandwidth Distributed 3D Graph-SLAM
- **Arxiv ID**: http://arxiv.org/abs/2005.10222v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.10222v1)
- **Published**: 2020-05-20 17:39:55+00:00
- **Updated**: 2020-05-20 17:39:55+00:00
- **Authors**: Jincheng Zhang, Andrew R. Willis, Jamie Godwin
- **Comment**: None
- **Journal**: None
- **Summary**: This article describes a new approach for distributed 3D SLAM map building. The key contribution of this article is the creation of a distributed graph-SLAM map-building architecture responsive to bandwidth and computational needs of the robotic platform. Responsiveness is afforded by the integration of a 3D point cloud to plane cloud compression algorithm that approximates dense 3D point cloud using local planar patches. Compute bound platforms may restrict the computational duration of the compression algorithm and low-bandwidth platforms can restrict the size of the compression result. The backbone of the approach is an ultra-fast adaptive 3D compression algorithm that transforms swaths of 3D planar surface data into planar patches attributed with image textures. Our approach uses DVO SLAM, a leading algorithm for 3D mapping, and extends it by computationally isolating map integration tasks from local Guidance, Navigation, and Control tasks and includes an addition of a network protocol to share the compressed plane clouds. The joint effect of these contributions allows agents with 3D sensing capabilities to calculate and communicate compressed map information commensurate with their onboard computational resources and communication channel capacities. This opens SLAM mapping to new categories of robotic platforms that may have computational and memory limits that prohibit other SLAM solutions.



### Intra- and Inter-Action Understanding via Temporal Action Parsing
- **Arxiv ID**: http://arxiv.org/abs/2005.10229v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.10229v1)
- **Published**: 2020-05-20 17:45:18+00:00
- **Updated**: 2020-05-20 17:45:18+00:00
- **Authors**: Dian Shao, Yue Zhao, Bo Dai, Dahua Lin
- **Comment**: CVPR 2020 Poster; Project page: https://sdolivia.github.io/TAPOS/
- **Journal**: None
- **Summary**: Current methods for action recognition primarily rely on deep convolutional networks to derive feature embeddings of visual and motion features. While these methods have demonstrated remarkable performance on standard benchmarks, we are still in need of a better understanding as to how the videos, in particular their internal structures, relate to high-level semantics, which may lead to benefits in multiple aspects, e.g. interpretable predictions and even new methods that can take the recognition performances to a next level. Towards this goal, we construct TAPOS, a new dataset developed on sport videos with manual annotations of sub-actions, and conduct a study on temporal action parsing on top. Our study shows that a sport activity usually consists of multiple sub-actions and that the awareness of such temporal structures is beneficial to action recognition. We also investigate a number of temporal parsing methods, and thereon devise an improved method that is capable of mining sub-actions from training data without knowing the labels of them. On the constructed TAPOS, the proposed method is shown to reveal intra-action information, i.e. how action instances are made of sub-actions, and inter-action information, i.e. one specific sub-action may commonly appear in various actions.



### Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere
- **Arxiv ID**: http://arxiv.org/abs/2005.10242v10
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2005.10242v10)
- **Published**: 2020-05-20 17:59:57+00:00
- **Updated**: 2022-08-15 22:04:26+00:00
- **Authors**: Tongzhou Wang, Phillip Isola
- **Comment**: International Conference on Machine Learning (ICML), 2020
- **Journal**: None
- **Summary**: Contrastive representation learning has been outstandingly successful in practice. In this work, we identify two key properties related to the contrastive loss: (1) alignment (closeness) of features from positive pairs, and (2) uniformity of the induced distribution of the (normalized) features on the hypersphere. We prove that, asymptotically, the contrastive loss optimizes these properties, and analyze their positive effects on downstream tasks. Empirically, we introduce an optimizable metric to quantify each property. Extensive experiments on standard vision and language datasets confirm the strong agreement between both metrics and downstream task performance. Remarkably, directly optimizing for these two metrics leads to representations with comparable or better performance at downstream tasks than contrastive learning.   Project Page: https://tongzhouwang.info/hypersphere   Code: https://github.com/SsnL/align_uniform , https://github.com/SsnL/moco_align_uniform



### What Makes for Good Views for Contrastive Learning?
- **Arxiv ID**: http://arxiv.org/abs/2005.10243v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2005.10243v3)
- **Published**: 2020-05-20 17:59:57+00:00
- **Updated**: 2020-12-18 10:01:34+00:00
- **Authors**: Yonglong Tian, Chen Sun, Ben Poole, Dilip Krishnan, Cordelia Schmid, Phillip Isola
- **Comment**: NeurIPS 2020. Project page: https://hobbitlong.github.io/InfoMin/
- **Journal**: None
- **Summary**: Contrastive learning between multiple views of the data has recently achieved state of the art performance in the field of self-supervised representation learning. Despite its success, the influence of different view choices has been less studied. In this paper, we use theoretical and empirical analysis to better understand the importance of view selection, and argue that we should reduce the mutual information (MI) between views while keeping task-relevant information intact. To verify this hypothesis, we devise unsupervised and semi-supervised frameworks that learn effective views by aiming to reduce their MI. We also consider data augmentation as a way to reduce MI, and show that increasing data augmentation indeed leads to decreasing MI and improves downstream classification accuracy. As a by-product, we achieve a new state-of-the-art accuracy on unsupervised pre-training for ImageNet classification ($73\%$ top-1 linear readout with a ResNet-50). In addition, transferring our models to PASCAL VOC object detection and COCO instance segmentation consistently outperforms supervised pre-training. Code:http://github.com/HobbitLong/PyContrast



### Naive-Student: Leveraging Semi-Supervised Learning in Video Sequences for Urban Scene Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2005.10266v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.10266v4)
- **Published**: 2020-05-20 18:00:05+00:00
- **Updated**: 2020-07-20 03:40:38+00:00
- **Authors**: Liang-Chieh Chen, Raphael Gontijo Lopes, Bowen Cheng, Maxwell D. Collins, Ekin D. Cubuk, Barret Zoph, Hartwig Adam, Jonathon Shlens
- **Comment**: Accepted to ECCV 2020
- **Journal**: None
- **Summary**: Supervised learning in large discriminative models is a mainstay for modern computer vision. Such an approach necessitates investing in large-scale human-annotated datasets for achieving state-of-the-art results. In turn, the efficacy of supervised learning may be limited by the size of the human annotated dataset. This limitation is particularly notable for image segmentation tasks, where the expense of human annotation is especially large, yet large amounts of unlabeled data may exist. In this work, we ask if we may leverage semi-supervised learning in unlabeled video sequences and extra images to improve the performance on urban scene segmentation, simultaneously tackling semantic, instance, and panoptic segmentation. The goal of this work is to avoid the construction of sophisticated, learned architectures specific to label propagation (e.g., patch matching and optical flow). Instead, we simply predict pseudo-labels for the unlabeled data and train subsequent models with both human-annotated and pseudo-labeled data. The procedure is iterated for several times. As a result, our Naive-Student model, trained with such simple yet effective iterative semi-supervised learning, attains state-of-the-art results at all three Cityscapes benchmarks, reaching the performance of 67.8% PQ, 42.6% AP, and 85.2% mIOU on the test set. We view this work as a notable step towards building a simple procedure to harness unlabeled video sequences and extra images to surpass state-of-the-art performance on core computer vision tasks.



### Maplets: An Efficient Approach for Cooperative SLAM Map Building Under Communication and Computation Constraints
- **Arxiv ID**: http://arxiv.org/abs/2005.10310v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.10310v1)
- **Published**: 2020-05-20 18:49:31+00:00
- **Updated**: 2020-05-20 18:49:31+00:00
- **Authors**: Kevin M. Brink, Jincheng Zhang, Andrew R. Willis, Ryan E. Sherrill, Jamie L. Godwin
- **Comment**: None
- **Journal**: None
- **Summary**: This article introduces an approach to facilitate cooperative exploration and mapping of large-scale, near-ground, underground, or indoor spaces via a novel integration framework for locally-dense agent map data. The effort targets limited Size, Weight, and Power (SWaP) agents with an emphasis on limiting required communications and redundant processing. The approach uses a unique organization of batch optimization engines to enable a highly efficient two-tier optimization structure. Tier I consist of agents that create and potentially share local maplets (local maps, limited in size) which are generated using Simultaneous Localization and Mapping (SLAM) map-building software and then marginalized to a more compact parameterization. Maplets are generated in an overlapping manner and used to estimate the transform and uncertainty between those overlapping maplets, providing accurate and compact odometry or delta-pose representation between maplet's local frames. The delta poses can be shared between agents, and in cases where maplets have salient features (for loop closures), the compact representation of the maplet can also be shared.   The second optimization tier consists of a global optimizer that seeks to optimize those maplet-to-maplet transformations, including any loop closures identified. This can provide an accurate global "skeleton"' of the traversed space without operating on the high-density point cloud. This compact version of the map data allows for scalable, cooperative exploration with limited communication requirements where most of the individual maplets, or low fidelity renderings, are only shared if desired.



### A Study of Deep Learning Colon Cancer Detection in Limited Data Access Scenarios
- **Arxiv ID**: http://arxiv.org/abs/2005.10326v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2005.10326v2)
- **Published**: 2020-05-20 19:28:07+00:00
- **Updated**: 2020-05-22 09:03:54+00:00
- **Authors**: Apostolia Tsirikoglou, Karin Stacke, Gabriel Eilertsen, Martin Lindvall, Jonas Unger
- **Comment**: Presented at the ICLR 2020 Workshop on AI for Overcoming Global
  Disparities in Cancer Care (AI4CC)
- **Journal**: None
- **Summary**: Digitization of histopathology slides has led to several advances, from easy data sharing and collaborations to the development of digital diagnostic tools. Deep learning (DL) methods for classification and detection have shown great potential, but often require large amounts of training data that are hard to collect, and annotate. For many cancer types, the scarceness of data creates barriers for training DL models. One such scenario relates to detecting tumor metastasis in lymph node tissue, where the low ratio of tumor to non-tumor cells makes the diagnostic task hard and time-consuming. DL-based tools can allow faster diagnosis, with potentially increased quality. Unfortunately, due to the sparsity of tumor cells, annotating this type of data demands a high level of effort from pathologists. Using weak annotations from slide-level images have shown great potential, but demand access to a substantial amount of data as well. In this study, we investigate mitigation strategies for limited data access scenarios. Particularly, we address whether it is possible to exploit mutual structure between tissues to develop general techniques, wherein data from one type of cancer in a particular tissue could have diagnostic value for other cancers in other tissues. Our case is exemplified by a DL model for metastatic colon cancer detection in lymph nodes. Could such a model be trained with little or even no lymph node data? As alternative data sources, we investigate 1) tumor cells taken from the primary colon tumor tissue, and 2) cancer data from a different organ (breast), either as is or transformed to the target domain (colon) using Cycle-GANs. We show that the suggested approaches make it possible to detect cancer metastasis with no or very little lymph node data, opening up for the possibility that existing, annotated histopathology data could generalize to other domains.



### InfoScrub: Towards Attribute Privacy by Targeted Obfuscation
- **Arxiv ID**: http://arxiv.org/abs/2005.10329v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.CR
- **Links**: [PDF](http://arxiv.org/pdf/2005.10329v2)
- **Published**: 2020-05-20 19:48:04+00:00
- **Updated**: 2021-06-01 13:55:02+00:00
- **Authors**: Hui-Po Wang, Tribhuvanesh Orekondy, Mario Fritz
- **Comment**: 20 pages, 7 figures
- **Journal**: None
- **Summary**: Personal photos of individuals when shared online, apart from exhibiting a myriad of memorable details, also reveals a wide range of private information and potentially entails privacy risks (e.g., online harassment, tracking). To mitigate such risks, it is crucial to study techniques that allow individuals to limit the private information leaked in visual data. We tackle this problem in a novel image obfuscation framework: to maximize entropy on inferences over targeted privacy attributes, while retaining image fidelity. We approach the problem based on an encoder-decoder style architecture, with two key novelties: (a) introducing a discriminator to perform bi-directional translation simultaneously from multiple unpaired domains; (b) predicting an image interpolation which maximizes uncertainty over a target set of attributes. We find our approach generates obfuscated images faithful to the original input images, and additionally increase uncertainty by 6.2$\times$ (or up to 0.85 bits) over the non-obfuscated counterparts.



### Adversarial Canonical Correlation Analysis
- **Arxiv ID**: http://arxiv.org/abs/2005.10349v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2005.10349v2)
- **Published**: 2020-05-20 20:46:35+00:00
- **Updated**: 2020-06-09 21:31:21+00:00
- **Authors**: Benjamin Dutton
- **Comment**: None
- **Journal**: None
- **Summary**: Canonical Correlation Analysis (CCA) is a statistical technique used to extract common information from multiple data sources or views. It has been used in various representation learning problems, such as dimensionality reduction, word embedding, and clustering. Recent work has given CCA probabilistic footing in a deep learning context and uses a variational lower bound for the data log likelihood to estimate model parameters. Alternatively, adversarial techniques have arisen in recent years as a powerful alternative to variational Bayesian methods in autoencoders. In this work, we explore straightforward adversarial alternatives to recent work in Deep Variational CCA (VCCA and VCCA-Private) we call ACCA and ACCA-Private and show how these approaches offer a stronger and more flexible way to match the approximate posteriors coming from encoders to much larger classes of priors than the VCCA and VCCA-Private models. This allows new priors for what constitutes a good representation, such as disentangling underlying factors of variation, to be more directly pursued. We offer further analysis on the multi-level disentangling properties of VCCA-Private and ACCA-Private through the use of a newly designed dataset we call Tangled MNIST. We also design a validation criteria for these models that is theoretically grounded, task-agnostic, and works well in practice. Lastly, we fill a minor research gap by deriving an additional variational lower bound for VCCA that allows the representation to use view-specific information from both input views.



### WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose
- **Arxiv ID**: http://arxiv.org/abs/2005.10353v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.10353v2)
- **Published**: 2020-05-20 20:53:01+00:00
- **Updated**: 2020-09-22 22:54:45+00:00
- **Authors**: Yijun Zhou, James Gregson
- **Comment**: Accepted at BMVC 2020
- **Journal**: None
- **Summary**: We present an end-to-end head-pose estimation network designed to predict Euler angles through the full range head yaws from a single RGB image. Existing methods perform well for frontal views but few target head pose from all viewpoints. This has applications in autonomous driving and retail. Our network builds on multi-loss approaches with changes to loss functions and training strategies adapted to wide range estimation. Additionally, we extract ground truth labelings of anterior views from a current panoptic dataset for the first time. The resulting Wide Headpose Estimation Network (WHENet) is the first fine-grained modern method applicable to the full-range of head yaws (hence wide) yet also meets or beats state-of-the-art methods for frontal head pose estimation. Our network is compact and efficient for mobile devices and applications.



### TAO: A Large-Scale Benchmark for Tracking Any Object
- **Arxiv ID**: http://arxiv.org/abs/2005.10356v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.10356v1)
- **Published**: 2020-05-20 21:07:28+00:00
- **Updated**: 2020-05-20 21:07:28+00:00
- **Authors**: Achal Dave, Tarasha Khurana, Pavel Tokmakov, Cordelia Schmid, Deva Ramanan
- **Comment**: Project page: http://taodataset.org/
- **Journal**: None
- **Summary**: For many years, multi-object tracking benchmarks have focused on a handful of categories. Motivated primarily by surveillance and self-driving applications, these datasets provide tracks for people, vehicles, and animals, ignoring the vast majority of objects in the world. By contrast, in the related field of object detection, the introduction of large-scale, diverse datasets (e.g., COCO) have fostered significant progress in developing highly robust solutions. To bridge this gap, we introduce a similarly diverse dataset for Tracking Any Object (TAO). It consists of 2,907 high resolution videos, captured in diverse environments, which are half a minute long on average. Importantly, we adopt a bottom-up approach for discovering a large vocabulary of 833 categories, an order of magnitude more than prior tracking benchmarks. To this end, we ask annotators to label objects that move at any point in the video, and give names to them post factum. Our vocabulary is both significantly larger and qualitatively different from existing tracking datasets. To ensure scalability of annotation, we employ a federated approach that focuses manual effort on labeling tracks for those relevant objects in a video (e.g., those that move). We perform an extensive evaluation of state-of-the-art trackers and make a number of important discoveries regarding large-vocabulary tracking in an open-world. In particular, we show that existing single- and multi-object trackers struggle when applied to this scenario in the wild, and that detection-based, multi-object trackers are in fact competitive with user-initialized ones. We hope that our dataset and analysis will boost further progress in the tracking community.



### VideoForensicsHQ: Detecting High-quality Manipulated Face Videos
- **Arxiv ID**: http://arxiv.org/abs/2005.10360v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.10360v2)
- **Published**: 2020-05-20 21:17:43+00:00
- **Updated**: 2021-06-02 12:00:26+00:00
- **Authors**: Gereon Fox, Wentao Liu, Hyeongwoo Kim, Hans-Peter Seidel, Mohamed Elgharib, Christian Theobalt
- **Comment**: ICME 2021 camera-ready
- **Journal**: None
- **Summary**: There are concerns that new approaches to the synthesis of high quality face videos may be misused to manipulate videos with malicious intent. The research community therefore developed methods for the detection of modified footage and assembled benchmark datasets for this task. In this paper, we examine how the performance of forgery detectors depends on the presence of artefacts that the human eye can see. We introduce a new benchmark dataset for face video forgery detection, of unprecedented quality. It allows us to demonstrate that existing detection techniques have difficulties detecting fakes that reliably fool the human eye. We thus introduce a new family of detectors that examine combinations of spatial and temporal features and outperform existing approaches both in terms of detection accuracy and generalization.



