# Arxiv Papers in cs.CV on 2018-02-14
### Web-Scale Responsive Visual Search at Bing
- **Arxiv ID**: http://arxiv.org/abs/1802.04914v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.04914v2)
- **Published**: 2018-02-14 01:15:22+00:00
- **Updated**: 2018-02-20 23:56:07+00:00
- **Authors**: Houdong Hu, Yan Wang, Linjun Yang, Pavel Komlev, Li Huang, Xi Chen, Jiapei Huang, Ye Wu, Meenaz Merchant, Arun Sacheti
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we introduce a web-scale general visual search system deployed in Microsoft Bing. The system accommodates tens of billions of images in the index, with thousands of features for each image, and can respond in less than 200 ms. In order to overcome the challenges in relevance, latency, and scalability in such large scale of data, we employ a cascaded learning-to-rank framework based on various latest deep learning visual features, and deploy in a distributed heterogeneous computing platform. Quantitative and qualitative experiments show that our system is able to support various applications on Bing website and apps.



### MemeSequencer: Sparse Matching for Embedding Image Macros
- **Arxiv ID**: http://arxiv.org/abs/1802.04936v1
- **DOI**: None
- **Categories**: **cs.SI**, cs.CV, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1802.04936v1)
- **Published**: 2018-02-14 02:53:20+00:00
- **Updated**: 2018-02-14 02:53:20+00:00
- **Authors**: Abhimanyu Dubey, Esteban Moro, Manuel Cebrian, Iyad Rahwan
- **Comment**: 9 pages (+2 pages references), camera ready version for International
  World Wide Web Conference (WWW) 2018
- **Journal**: None
- **Summary**: The analysis of the creation, mutation, and propagation of social media content on the Internet is an essential problem in computational social science, affecting areas ranging from marketing to political mobilization. A first step towards understanding the evolution of images online is the analysis of rapidly modifying and propagating memetic imagery or `memes'. However, a pitfall in proceeding with such an investigation is the current incapability to produce a robust semantic space for such imagery, capable of understanding differences in Image Macros. In this study, we provide a first step in the systematic study of image evolution on the Internet, by proposing an algorithm based on sparse representations and deep learning to decouple various types of content in such images and produce a rich semantic embedding. We demonstrate the benefits of our approach on a variety of tasks pertaining to memes and Image Macros, such as image clustering, image retrieval, topic prediction and virality prediction, surpassing the existing methods on each. In addition to its utility on quantitative tasks, our method opens up the possibility of obtaining the first large-scale understanding of the evolution and propagation of memetic imagery.



### Disjoint Multi-task Learning between Heterogeneous Human-centric Tasks
- **Arxiv ID**: http://arxiv.org/abs/1802.04962v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.04962v1)
- **Published**: 2018-02-14 05:36:14+00:00
- **Updated**: 2018-02-14 05:36:14+00:00
- **Authors**: Dong-Jin Kim, Jinsoo Choi, Tae-Hyun Oh, Youngjin Yoon, In So Kweon
- **Comment**: 10 pages, 7 figures
- **Journal**: None
- **Summary**: Human behavior understanding is arguably one of the most important mid-level components in artificial intelligence. In order to efficiently make use of data, multi-task learning has been studied in diverse computer vision tasks including human behavior understanding. However, multi-task learning relies on task specific datasets and constructing such datasets can be cumbersome. It requires huge amounts of data, labeling efforts, statistical consideration etc. In this paper, we leverage existing single-task datasets for human action classification and captioning data for efficient human behavior learning. Since the data in each dataset has respective heterogeneous annotations, traditional multi-task learning is not effective in this scenario. To this end, we propose a novel alternating directional optimization method to efficiently learn from the heterogeneous data. We demonstrate the effectiveness of our model and show performance improvements on both classification and sentence retrieval tasks in comparison to the models trained on each of the single-task datasets.



### Paraphrasing Complex Network: Network Compression via Factor Transfer
- **Arxiv ID**: http://arxiv.org/abs/1802.04977v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.04977v3)
- **Published**: 2018-02-14 07:46:15+00:00
- **Updated**: 2020-07-22 12:42:18+00:00
- **Authors**: Jangho Kim, SeongUk Park, Nojun Kwak
- **Comment**: Advances in Neural Information Processing Systems
- **Journal**: None
- **Summary**: Many researchers have sought ways of model compression to reduce the size of a deep neural network (DNN) with minimal performance degradation in order to use DNNs in embedded systems. Among the model compression methods, a method called knowledge transfer is to train a student network with a stronger teacher network. In this paper, we propose a novel knowledge transfer method which uses convolutional operations to paraphrase teacher's knowledge and to translate it for the student. This is done by two convolutional modules, which are called a paraphraser and a translator. The paraphraser is trained in an unsupervised manner to extract the teacher factors which are defined as paraphrased information of the teacher network. The translator located at the student network extracts the student factors and helps to translate the teacher factors by mimicking them. We observed that our student network trained with the proposed factor transfer method outperforms the ones trained with conventional knowledge transfer methods.



### M4CD: A Robust Change Detection Method for Intelligent Visual Surveillance
- **Arxiv ID**: http://arxiv.org/abs/1802.04979v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.04979v1)
- **Published**: 2018-02-14 07:51:59+00:00
- **Updated**: 2018-02-14 07:51:59+00:00
- **Authors**: Kunfeng Wang, Chao Gou, Fei-Yue Wang
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we propose a robust change detection method for intelligent visual surveillance. This method, named M4CD, includes three major steps. Firstly, a sample-based background model that integrates color and texture cues is built and updated over time. Secondly, multiple heterogeneous features (including brightness variation, chromaticity variation, and texture variation) are extracted by comparing the input frame with the background model, and a multi-source learning strategy is designed to online estimate the probability distributions for both foreground and background. The three features are approximately conditionally independent, making multi-source learning feasible. Pixel-wise foreground posteriors are then estimated with Bayes rule. Finally, the Markov random field (MRF) optimization and heuristic post-processing techniques are used sequentially to improve accuracy. In particular, a two-layer MRF model is constructed to represent pixel-based and superpixel-based contextual constraints compactly. Experimental results on the CDnet dataset indicate that M4CD is robust under complex environments and ranks among the top methods.



### Recursive Chaining of Reversible Image-to-image Translators For Face Aging
- **Arxiv ID**: http://arxiv.org/abs/1802.05023v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.05023v2)
- **Published**: 2018-02-14 10:22:38+00:00
- **Updated**: 2018-08-06 19:24:00+00:00
- **Authors**: Ari Heljakka, Arno Solin, Juho Kannala
- **Comment**: To appear in Advanced Concepts for Intelligent Vision Systems (ACIVS)
  2018
- **Journal**: None
- **Summary**: This paper addresses the modeling and simulation of progressive changes over time, such as human face aging. By treating the age phases as a sequence of image domains, we construct a chain of transformers that map images from one age domain to the next. Leveraging recent adversarial image translation methods, our approach requires no training samples of the same individual at different ages. Here, the model must be flexible enough to translate a child face to a young adult, and all the way through the adulthood to old age. We find that some transformers in the chain can be recursively applied on their own output to cover multiple phases, compressing the chain. The structure of the chain also unearths information about the underlying physical process. We demonstrate the performance of our method with precise and intuitive metrics, and visually match with the face aging state-of-the-art.



### The Multiscale Bowler-Hat Transform for Vessel Enhancement in 3D Biomedical Images
- **Arxiv ID**: http://arxiv.org/abs/1802.05097v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.05097v1)
- **Published**: 2018-02-14 13:59:46+00:00
- **Updated**: 2018-02-14 13:59:46+00:00
- **Authors**: Cigdem Sazak, Carl J. Nelson, Boguslaw Obara
- **Comment**: None
- **Journal**: None
- **Summary**: Enhancement and detection of 3D vessel-like structures has long been an open problem as most existing image processing methods fail in many aspects, including a lack of uniform enhancement between vessels of different radii and a lack of enhancement at the junctions.   Here, we propose a method based on mathematical morphology to enhance 3D vessel-like structures in biomedical images. The proposed method, 3D bowler-hat transform, combines sphere and line structuring elements to enhance vessel-like structures. The proposed method is validated on synthetic and real data and compared with state-of-the-art methods.   Our results show that the proposed method achieves a high-quality vessel-like structures enhancement in both synthetic and real biomedical images, and is able to cope with variations in vessels thickness throughout vascular networks while remaining robust at junctions.



### Sampling Superquadric Point Clouds with Normals
- **Arxiv ID**: http://arxiv.org/abs/1802.05176v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.05176v1)
- **Published**: 2018-02-14 16:04:27+00:00
- **Updated**: 2018-02-14 16:04:27+00:00
- **Authors**: Paulo Ferreira
- **Comment**: None
- **Journal**: None
- **Summary**: Superquadrics provide a compact representation of common shapes and have been used both for object/surface modelling in computer graphics and as object-part representation in computer vision and robotics. Superquadrics refer to a family of shapes: here we deal with the superellipsoids and superparaboloids. Due to the strong non-linearities involved in the equations, uniform or close-to-uniform sampling is not attainable through a naive approach of direct sampling from the parametric formulation. This is specially true for more `cubic' superquadrics (with shape parameters close to $0.1$). We extend a previous solution of 2D close-to-uniform uniform sampling of superellipses to the superellipsoid (3D) case and derive our own for the superparaboloid. Additionally, we are able to provide normals for each sampled point. To the best of our knowledge, this is the first complete approach for close-to-uniform sampling of superellipsoids and superparaboloids in one single framework. We present derivations, pseudocode and qualitative and quantitative results using our code, which is available online.



### Fully Convolutional Network Ensembles for White Matter Hyperintensities Segmentation in MR Images
- **Arxiv ID**: http://arxiv.org/abs/1802.05203v3
- **DOI**: 10.1016/j.neuroimage.2018.07.005
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.05203v3)
- **Published**: 2018-02-14 16:49:41+00:00
- **Updated**: 2018-09-19 09:47:47+00:00
- **Authors**: Hongwei Li, Gongfa Jiang, Jianguo Zhang, Ruixuan Wang, Zhaolei Wang, Wei-Shi Zheng, Bjoern Menze
- **Comment**: final version in NeuroImage
- **Journal**: Neuroimage. 2018 Aug 17. pii: S1053-8119(18)30597-4
- **Summary**: White matter hyperintensities (WMH) are commonly found in the brains of healthy elderly individuals and have been associated with various neurological and geriatric disorders. In this paper, we present a study using deep fully convolutional network and ensemble models to automatically detect such WMH using fluid attenuation inversion recovery (FLAIR) and T1 magnetic resonance (MR) scans. The algorithm was evaluated and ranked 1 st in the WMH Segmentation Challenge at MICCAI 2017. In the evaluation stage, the implementation of the algorithm was submitted to the challenge organizers, who then independently tested it on a hidden set of 110 cases from 5 scanners. Averaged dice score, precision and robust Hausdorff distance obtained on held-out test datasets were 80%, 84% and 6.30mm respectively. These were the highest achieved in the challenge, suggesting the proposed method is the state-of-the-art. In this paper, we provide detailed descriptions and quantitative analysis on key components of the system. Furthermore, a study of cross-scanner evaluation is presented to discuss how the combination of modalities and data augmentation affect the generalization capability of the system. The adaptability of the system to different scanners and protocols is also investigated. A quantitative study is further presented to test the effect of ensemble size. Additionally, software and models of our method are made publicly available. The effectiveness and generalization capability of the proposed system show its potential for real-world clinical practice.



### Learning Privacy Preserving Encodings through Adversarial Training
- **Arxiv ID**: http://arxiv.org/abs/1802.05214v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CR, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1802.05214v3)
- **Published**: 2018-02-14 17:04:07+00:00
- **Updated**: 2018-12-04 19:24:57+00:00
- **Authors**: Francesco Pittaluga, Sanjeev J. Koppal, Ayan Chakrabarti
- **Comment**: To appear in WACV 2019
- **Journal**: None
- **Summary**: We present a framework to learn privacy-preserving encodings of images that inhibit inference of chosen private attributes, while allowing recovery of other desirable information. Rather than simply inhibiting a given fixed pre-trained estimator, our goal is that an estimator be unable to learn to accurately predict the private attributes even with knowledge of the encoding function. We use a natural adversarial optimization-based formulation for this---training the encoding function against a classifier for the private attribute, with both modeled as deep neural networks. The key contribution of our work is a stable and convergent optimization approach that is successful at learning an encoder with our desired properties---maintaining utility while inhibiting inference of private attributes, not just within the adversarial optimization, but also by classifiers that are trained after the encoder is fixed. We adopt a rigorous experimental protocol for verification wherein classifiers are trained exhaustively till saturation on the fixed encoders. We evaluate our approach on tasks of real-world complexity---learning high-dimensional encodings that inhibit detection of different scene categories---and find that it yields encoders that are resilient at maintaining privacy.



### Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise
- **Arxiv ID**: http://arxiv.org/abs/1802.05300v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.CL, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1802.05300v4)
- **Published**: 2018-02-14 19:48:50+00:00
- **Updated**: 2019-01-28 19:55:36+00:00
- **Authors**: Dan Hendrycks, Mantas Mazeika, Duncan Wilson, Kevin Gimpel
- **Comment**: NeurIPS 2018. PyTorch code available at
  https://github.com/mmazeika/glc
- **Journal**: None
- **Summary**: The growing importance of massive datasets used for deep learning makes robustness to label noise a critical property for classifiers to have. Sources of label noise include automatic labeling, non-expert labeling, and label corruption by data poisoning adversaries. Numerous previous works assume that no source of labels can be trusted. We relax this assumption and assume that a small subset of the training data is trusted. This enables substantial label corruption robustness performance gains. In addition, particularly severe label noise can be combated by using a set of trusted data with clean labels. We utilize trusted data by proposing a loss correction technique that utilizes trusted examples in a data-efficient manner to mitigate the effects of label noise on deep neural network classifiers. Across vision and natural language processing tasks, we experiment with various label noises at several strengths, and show that our method significantly outperforms existing methods.



### Spatial Coherence of Oriented White Matter Microstructure: Applications to White Matter Regions Associated with Genetic Similarity
- **Arxiv ID**: http://arxiv.org/abs/1802.05342v1
- **DOI**: 10.1016/j.neuroimage.2018.01.050
- **Categories**: **stat.AP**, cs.CV, q-bio.QM
- **Links**: [PDF](http://arxiv.org/pdf/1802.05342v1)
- **Published**: 2018-02-14 22:31:14+00:00
- **Updated**: 2018-02-14 22:31:14+00:00
- **Authors**: Haraldur T. Hallgr√≠msson, Matthew Cieslak, Luca Foschini, Scott T. Grafton, Ambuj K. Singh
- **Comment**: None
- **Journal**: NeuroImage (2018)
- **Summary**: We present a method to discover differences between populations with respect to the spatial coherence of their oriented white matter microstructure in arbitrarily shaped white matter regions. This method is applied to diffusion MRI scans of a subset of the Human Connectome Project dataset: 57 pairs of monozygotic and 52 pairs of dizygotic twins. After controlling for morphological similarity between twins, we identify 3.7% of all white matter as being associated with genetic similarity (35.1k voxels, $p < 10^{-4}$, false discovery rate 1.5%), 75% of which spatially clusters into twenty-two contiguous white matter regions. Furthermore, we show that the orientation similarity within these regions generalizes to a subset of 47 pairs of non-twin siblings, and show that these siblings are on average as similar as dizygotic twins. The regions are located in deep white matter including the superior longitudinal fasciculus, the optic radiations, the middle cerebellar peduncle, the corticospinal tract, and within the anterior temporal lobe, as well as the cerebellum, brain stem, and amygdalae.   These results extend previous work using undirected fractional anisotrophy for measuring putative heritable influences in white matter. Our multidirectional extension better accounts for crossing fiber connections within voxels. This bottom up approach has at its basis a novel measurement of coherence within neighboring voxel dyads between subjects, and avoids some of the fundamental ambiguities encountered with tractographic approaches to white matter analysis that estimate global connectivity.



