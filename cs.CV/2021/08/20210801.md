# Arxiv Papers in cs.CV on 2021-08-01
### LASOR: Learning Accurate 3D Human Pose and Shape Via Synthetic Occlusion-Aware Data and Neural Mesh Rendering
- **Arxiv ID**: http://arxiv.org/abs/2108.00351v5
- **DOI**: 10.1109/TIP.2022.3149229
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2108.00351v5)
- **Published**: 2021-08-01 02:09:16+00:00
- **Updated**: 2022-01-29 12:36:13+00:00
- **Authors**: Kaibing Yang, Renshu Gu, Maoyu Wang, Masahiro Toyoura, Gang Xu
- **Comment**: None
- **Journal**: None
- **Summary**: A key challenge in the task of human pose and shape estimation is occlusion, including self-occlusions, object-human occlusions, and inter-person occlusions. The lack of diverse and accurate pose and shape training data becomes a major bottleneck, especially for scenes with occlusions in the wild. In this paper, we focus on the estimation of human pose and shape in the case of inter-person occlusions, while also handling object-human occlusions and self-occlusion. We propose a novel framework that synthesizes occlusion-aware silhouette and 2D keypoints data and directly regress to the SMPL pose and shape parameters. A neural 3D mesh renderer is exploited to enable silhouette supervision on the fly, which contributes to great improvements in shape estimation. In addition, keypoints-and-silhouette-driven training data in panoramic viewpoints are synthesized to compensate for the lack of viewpoint diversity in any existing dataset. Experimental results show that we are among the state-of-the-art on the 3DPW and 3DPW-Crowd datasets in terms of pose estimation accuracy. The proposed method evidently outperforms Mesh Transformer, 3DCrowdNet and ROMP in terms of shape estimation. Top performance is also achieved on SSP-3D in terms of shape prediction accuracy. Demo and code will be available at https://igame-lab.github.io/LASOR/.



### BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervised Learning
- **Arxiv ID**: http://arxiv.org/abs/2108.00352v1
- **DOI**: None
- **Categories**: **cs.CR**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2108.00352v1)
- **Published**: 2021-08-01 02:22:31+00:00
- **Updated**: 2021-08-01 02:22:31+00:00
- **Authors**: Jinyuan Jia, Yupei Liu, Neil Zhenqiang Gong
- **Comment**: To appear in IEEE Symposium on Security and Privacy, 2022
- **Journal**: None
- **Summary**: Self-supervised learning in computer vision aims to pre-train an image encoder using a large amount of unlabeled images or (image, text) pairs. The pre-trained image encoder can then be used as a feature extractor to build downstream classifiers for many downstream tasks with a small amount of or no labeled training data. In this work, we propose BadEncoder, the first backdoor attack to self-supervised learning. In particular, our BadEncoder injects backdoors into a pre-trained image encoder such that the downstream classifiers built based on the backdoored image encoder for different downstream tasks simultaneously inherit the backdoor behavior. We formulate our BadEncoder as an optimization problem and we propose a gradient descent based method to solve it, which produces a backdoored image encoder from a clean one. Our extensive empirical evaluation results on multiple datasets show that our BadEncoder achieves high attack success rates while preserving the accuracy of the downstream classifiers. We also show the effectiveness of BadEncoder using two publicly available, real-world image encoders, i.e., Google's image encoder pre-trained on ImageNet and OpenAI's Contrastive Language-Image Pre-training (CLIP) image encoder pre-trained on 400 million (image, text) pairs collected from the Internet. Moreover, we consider defenses including Neural Cleanse and MNTD (empirical defenses) as well as PatchGuard (a provable defense). Our results show that these defenses are insufficient to defend against BadEncoder, highlighting the needs for new defenses against our BadEncoder. Our code is publicly available at: https://github.com/jjy1994/BadEncoder.



### ELLIPSDF: Joint Object Pose and Shape Optimization with a Bi-level Ellipsoid and Signed Distance Function Description
- **Arxiv ID**: http://arxiv.org/abs/2108.00355v1
- **DOI**: 10.1109/ICCV48922.2021.00589
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2108.00355v1)
- **Published**: 2021-08-01 03:07:31+00:00
- **Updated**: 2021-08-01 03:07:31+00:00
- **Authors**: Mo Shan, Qiaojun Feng, You-Yi Jau, Nikolay Atanasov
- **Comment**: Accepted by ICCV 2021
- **Journal**: 2021 IEEE/CVF International Conference on Computer Vision (ICCV),
  Montreal, QC, Canada, pp. 5926-5935
- **Summary**: Autonomous systems need to understand the semantics and geometry of their surroundings in order to comprehend and safely execute object-level task specifications. This paper proposes an expressive yet compact model for joint object pose and shape optimization, and an associated optimization algorithm to infer an object-level map from multi-view RGB-D camera observations. The model is expressive because it captures the identities, positions, orientations, and shapes of objects in the environment. It is compact because it relies on a low-dimensional latent representation of implicit object shape, allowing onboard storage of large multi-category object maps. Different from other works that rely on a single object representation format, our approach has a bi-level object model that captures both the coarse level scale as well as the fine level shape details. Our approach is evaluated on the large-scale real-world ScanNet dataset and compared against state-of-the-art methods.



### Applications of Artificial Neural Networks in Microorganism Image Analysis: A Comprehensive Review from Conventional Multilayer Perceptron to Popular Convolutional Neural Network and Potential Visual Transformer
- **Arxiv ID**: http://arxiv.org/abs/2108.00358v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2108.00358v3)
- **Published**: 2021-08-01 03:46:48+00:00
- **Updated**: 2022-03-24 11:44:50+00:00
- **Authors**: Jinghua Zhang, Chen Li, Yimin Yin, Jiawei Zhang, Marcin Grzegorzek
- **Comment**: None
- **Journal**: None
- **Summary**: Microorganisms are widely distributed in the human daily living environment. They play an essential role in environmental pollution control, disease prevention and treatment, and food and drug production. The analysis of microorganisms is essential for making full use of different microorganisms. The conventional analysis methods are laborious and time-consuming. Therefore, the automatic image analysis based on artificial neural networks is introduced to optimize it. However, the automatic microorganism image analysis faces many challenges, such as the requirement of a robust algorithm caused by various application occasions, insignificant features and easy under-segmentation caused by the image characteristic, and various analysis tasks. Therefore, we conduct this review to comprehensively discuss the characteristics of microorganism image analysis based on artificial neural networks. In this review, the background and motivation are introduced first. Then, the development of artificial neural networks and representative networks are presented. After that, the papers related to microorganism image analysis based on classical and deep neural networks are reviewed from the perspectives of different tasks. In the end, the methodology analysis and potential direction are discussed.



### Neural Free-Viewpoint Performance Rendering under Complex Human-object Interactions
- **Arxiv ID**: http://arxiv.org/abs/2108.00362v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/2108.00362v2)
- **Published**: 2021-08-01 04:53:54+00:00
- **Updated**: 2021-08-03 06:22:47+00:00
- **Authors**: Guoxing Sun, Xin Chen, Yizhang Chen, Anqi Pang, Pei Lin, Yuheng Jiang, Lan Xu, Jingya Wang, Jingyi Yu
- **Comment**: Accepted by ACM MM 2021
- **Journal**: None
- **Summary**: 4D reconstruction of human-object interaction is critical for immersive VR/AR experience and human activity understanding. Recent advances still fail to recover fine geometry and texture results from sparse RGB inputs, especially under challenging human-object interactions scenarios. In this paper, we propose a neural human performance capture and rendering system to generate both high-quality geometry and photo-realistic texture of both human and objects under challenging interaction scenarios in arbitrary novel views, from only sparse RGB streams. To deal with complex occlusions raised by human-object interactions, we adopt a layer-wise scene decoupling strategy and perform volumetric reconstruction and neural rendering of the human and object. Specifically, for geometry reconstruction, we propose an interaction-aware human-object capture scheme that jointly considers the human reconstruction and object reconstruction with their correlations. Occlusion-aware human reconstruction and robust human-aware object tracking are proposed for consistent 4D human-object dynamic reconstruction. For neural texture rendering, we propose a layer-wise human-object rendering scheme, which combines direction-aware neural blending weight learning and spatial-temporal texture completion to provide high-resolution and photo-realistic texture results in the occluded scenarios. Extensive experiments demonstrate the effectiveness of our approach to achieve high-quality geometry and texture reconstruction in free viewpoints for challenging human-object interactions.



### Knowing When to Quit: Selective Cascaded Regression with Patch Attention for Real-Time Face Alignment
- **Arxiv ID**: http://arxiv.org/abs/2108.00377v2
- **DOI**: 10.1145/3474085.3475401
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2108.00377v2)
- **Published**: 2021-08-01 06:51:47+00:00
- **Updated**: 2021-08-03 07:21:08+00:00
- **Authors**: Gil Shapira, Noga Levy, Ishay Goldin, Roy J. Jevnisek
- **Comment**: Accepted to the 29th ACM International Conference on Multimedia (MM
  21)
- **Journal**: None
- **Summary**: Facial landmarks (FLM) estimation is a critical component in many face-related applications. In this work, we aim to optimize for both accuracy and speed and explore the trade-off between them. Our key observation is that not all faces are created equal. Frontal faces with neutral expressions converge faster than faces with extreme poses or expressions. To differentiate among samples, we train our model to predict the regression error after each iteration. If the current iteration is accurate enough, we stop iterating, saving redundant iterations while keeping the accuracy in check. We also observe that as neighboring patches overlap, we can infer all facial landmarks (FLMs) with only a small number of patches without a major accuracy sacrifice. Architecturally, we offer a multi-scale, patch-based, lightweight feature extractor with a fine-grained local patch attention module, which computes a patch weighting according to the information in the patch itself and enhances the expressive power of the patch features. We analyze the patch attention data to infer where the model is attending when regressing facial landmarks and compare it to face attention in humans. Our model runs in real-time on a mobile device GPU, with 95 Mega Multiply-Add (MMA) operations, outperforming all state-of-the-art methods under 1000 MMA, with a normalized mean error of 8.16 on the 300W challenging dataset.



### Visual Boundary Knowledge Translation for Foreground Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2108.00379v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2108.00379v1)
- **Published**: 2021-08-01 07:10:25+00:00
- **Updated**: 2021-08-01 07:10:25+00:00
- **Authors**: Zunlei Feng, Lechao Cheng, Xinchao Wang, Xiang Wang, Yajie Liu, Xiangtong Du, Mingli Song
- **Comment**: Accepted by AAAI 2021
- **Journal**: None
- **Summary**: When confronted with objects of unknown types in an image, humans can effortlessly and precisely tell their visual boundaries. This recognition mechanism and underlying generalization capability seem to contrast to state-of-the-art image segmentation networks that rely on large-scale category-aware annotated training samples. In this paper, we make an attempt towards building models that explicitly account for visual boundary knowledge, in hope to reduce the training effort on segmenting unseen categories. Specifically, we investigate a new task termed as Boundary Knowledge Translation (BKT). Given a set of fully labeled categories, BKT aims to translate the visual boundary knowledge learned from the labeled categories, to a set of novel categories, each of which is provided only a few labeled samples. To this end, we propose a Translation Segmentation Network (Trans-Net), which comprises a segmentation network and two boundary discriminators. The segmentation network, combined with a boundary-aware self-supervised mechanism, is devised to conduct foreground segmentation, while the two discriminators work together in an adversarial manner to ensure an accurate segmentation of the novel categories under light supervision. Exhaustive experiments demonstrate that, with only tens of labeled samples as guidance, Trans-Net achieves close results on par with fully supervised methods.



### Edge-competing Pathological Liver Vessel Segmentation with Limited Labels
- **Arxiv ID**: http://arxiv.org/abs/2108.00384v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2108.00384v1)
- **Published**: 2021-08-01 07:28:32+00:00
- **Updated**: 2021-08-01 07:28:32+00:00
- **Authors**: Zunlei Feng, Zhonghua Wang, Xinchao Wang, Xiuming Zhang, Lechao Cheng, Jie Lei, Yuexuan Wang, Mingli Song
- **Comment**: Accepted by AAAI 2021
- **Journal**: None
- **Summary**: The microvascular invasion (MVI) is a major prognostic factor in hepatocellular carcinoma, which is one of the malignant tumors with the highest mortality rate. The diagnosis of MVI needs discovering the vessels that contain hepatocellular carcinoma cells and counting their number in each vessel, which depends heavily on experiences of the doctor, is largely subjective and time-consuming. However, there is no algorithm as yet tailored for the MVI detection from pathological images. This paper collects the first pathological liver image dataset containing 522 whole slide images with labels of vessels, MVI, and hepatocellular carcinoma grades. The first and essential step for the automatic diagnosis of MVI is the accurate segmentation of vessels. The unique characteristics of pathological liver images, such as super-large size, multi-scale vessel, and blurred vessel edges, make the accurate vessel segmentation challenging. Based on the collected dataset, we propose an Edge-competing Vessel Segmentation Network (EVS-Net), which contains a segmentation network and two edge segmentation discriminators. The segmentation network, combined with an edge-aware self-supervision mechanism, is devised to conduct vessel segmentation with limited labeled patches. Meanwhile, two discriminators are introduced to distinguish whether the segmented vessel and background contain residual features in an adversarial manner. In the training stage, two discriminators are devised tocompete for the predicted position of edges. Exhaustive experiments demonstrate that, with only limited labeled patches, EVS-Net achieves a close performance of fully supervised methods, which provides a convenient tool for the pathological liver vessel segmentation. Code is publicly available at https://github.com/zju-vipa/EVS-Net.



### Boundary Knowledge Translation based Reference Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2108.01075v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2108.01075v1)
- **Published**: 2021-08-01 07:40:09+00:00
- **Updated**: 2021-08-01 07:40:09+00:00
- **Authors**: Lechao Cheng, Zunlei Feng, Xinchao Wang, Ya Jie Liu, Jie Lei, Mingli Song
- **Comment**: Accepted by IJCAI 2021. arXiv admin note: text overlap with
  arXiv:2108.00379
- **Journal**: None
- **Summary**: Given a reference object of an unknown type in an image, human observers can effortlessly find the objects of the same category in another image and precisely tell their visual boundaries. Such visual cognition capability of humans seems absent from the current research spectrum of computer vision. Existing segmentation networks, for example, rely on a humongous amount of labeled data, which is laborious and costly to collect and annotate; besides, the performance of segmentation networks tend to downgrade as the number of the category increases. In this paper, we introduce a novel Reference semantic segmentation Network (Ref-Net) to conduct visual boundary knowledge translation. Ref-Net contains a Reference Segmentation Module (RSM) and a Boundary Knowledge Translation Module (BKTM). Inspired by the human recognition mechanism, RSM is devised only to segment the same category objects based on the features of the reference objects. BKTM, on the other hand, introduces two boundary discriminator branches to conduct inner and outer boundary segmentation of the target objectin an adversarial manner, and translate the annotated boundary knowledge of open-source datasets into the segmentation network. Exhaustive experiments demonstrate that, with tens of finely-grained annotated samples as guidance, Ref-Net achieves results on par with fully supervised methods on six datasets.



### WAS-VTON: Warping Architecture Search for Virtual Try-on Network
- **Arxiv ID**: http://arxiv.org/abs/2108.00386v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2108.00386v1)
- **Published**: 2021-08-01 07:52:56+00:00
- **Updated**: 2021-08-01 07:52:56+00:00
- **Authors**: Zhenyu Xie, Xujie Zhang, Fuwei Zhao, Haoye Dong, Michael C. Kampffmeyer, Haonan Yan, Xiaodan Liang
- **Comment**: None
- **Journal**: None
- **Summary**: Despite recent progress on image-based virtual try-on, current methods are constraint by shared warping networks and thus fail to synthesize natural try-on results when faced with clothing categories that require different warping operations. In this paper, we address this problem by finding clothing category-specific warping networks for the virtual try-on task via Neural Architecture Search (NAS). We introduce a NAS-Warping Module and elaborately design a bilevel hierarchical search space to identify the optimal network-level and operation-level flow estimation architecture. Given the network-level search space, containing different numbers of warping blocks, and the operation-level search space with different convolution operations, we jointly learn a combination of repeatable warping cells and convolution operations specifically for the clothing-person alignment. Moreover, a NAS-Fusion Module is proposed to synthesize more natural final try-on results, which is realized by leveraging particular skip connections to produce better-fused features that are required for seamlessly fusing the warped clothing and the unchanged person part. We adopt an efficient and stable one-shot searching strategy to search the above two modules. Extensive experiments demonstrate that our WAS-VTON significantly outperforms the previous fixed-architecture try-on methods with more natural warping results and virtual try-on results.



### Developing a Compressed Object Detection Model based on YOLOv4 for Deployment on Embedded GPU Platform of Autonomous System
- **Arxiv ID**: http://arxiv.org/abs/2108.00392v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2108.00392v1)
- **Published**: 2021-08-01 08:19:51+00:00
- **Updated**: 2021-08-01 08:19:51+00:00
- **Authors**: Issac Sim, Ju-Hyung Lim, Young-Wan Jang, JiHwan You, SeonTaek Oh, Young-Keun Kim
- **Comment**: in Chinese language
- **Journal**: None
- **Summary**: Latest CNN-based object detection models are quite accurate but require a high-performance GPU to run in real-time. They still are heavy in terms of memory size and speed for an embedded system with limited memory space. Since the object detection for autonomous system is run on an embedded processor, it is preferable to compress the detection network as light as possible while preserving the detection accuracy. There are several popular lightweight detection models but their accuracy is too low for safe driving applications. Therefore, this paper proposes a new object detection model, referred as YOffleNet, which is compressed at a high ratio while minimizing the accuracy loss for real-time and safe driving application on an autonomous system. The backbone network architecture is based on YOLOv4, but we could compress the network greatly by replacing the high-calculation-load CSP DenseNet with the lighter modules of ShuffleNet. Experiments with KITTI dataset showed that the proposed YOffleNet is compressed by 4.7 times than the YOLOv4-s that could achieve as fast as 46 FPS on an embedded GPU system(NVIDIA Jetson AGX Xavier). Compared to the high compression ratio, the accuracy is reduced slightly to 85.8% mAP, that is only 2.6% lower than YOLOv4-s. Thus, the proposed network showed a high potential to be deployed on the embedded system of the autonomous system for the real-time and accurate object detection applications.



### Deep graph matching meets mixed-integer linear programming: Relax at your own risk ?
- **Arxiv ID**: http://arxiv.org/abs/2108.00394v5
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, math.OC
- **Links**: [PDF](http://arxiv.org/pdf/2108.00394v5)
- **Published**: 2021-08-01 08:29:55+00:00
- **Updated**: 2022-04-28 08:07:07+00:00
- **Authors**: Zhoubo Xu, Puqing Chen, Romain Raveaux, Xin Yang, Huadong Liu
- **Comment**: The paper is under consideration at Pattern Recognition
- **Journal**: None
- **Summary**: Graph matching is an important problem that has received widespread attention, especially in the field of computer vision. Recently, state-of-the-art methods seek to incorporate graph matching with deep learning. However, there is no research to explain what role the graph matching algorithm plays in the model. Therefore, we propose an approach integrating a MILP formulation of the graph matching problem. This formulation is solved to optimal and it provides inherent baseline. Meanwhile, similar approaches are derived by releasing the optimal guarantee of the graph matching solver and by introducing a quality level. This quality level controls the quality of the solutions provided by the graph matching solver. In addition, several relaxations of the graph matching problem are put to the test. Our experimental evaluation gives several theoretical insights and guides the direction of deep graph matching methods.



### BORM: Bayesian Object Relation Model for Indoor Scene Recognition
- **Arxiv ID**: http://arxiv.org/abs/2108.00397v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2108.00397v1)
- **Published**: 2021-08-01 08:31:18+00:00
- **Updated**: 2021-08-01 08:31:18+00:00
- **Authors**: Liguang Zhou, Jun Cen, Xingchao Wang, Zhenglong Sun, Tin Lun Lam, Yangsheng Xu
- **Comment**: 8 pages, 5 figures, conference, Accepted by IROS2021
- **Journal**: IROS2021
- **Summary**: Scene recognition is a fundamental task in robotic perception. For human beings, scene recognition is reasonable because they have abundant object knowledge of the real world. The idea of transferring prior object knowledge from humans to scene recognition is significant but still less exploited. In this paper, we propose to utilize meaningful object representations for indoor scene representation. First, we utilize an improved object model (IOM) as a baseline that enriches the object knowledge by introducing a scene parsing algorithm pretrained on the ADE20K dataset with rich object categories related to the indoor scene. To analyze the object co-occurrences and pairwise object relations, we formulate the IOM from a Bayesian perspective as the Bayesian object relation model (BORM). Meanwhile, we incorporate the proposed BORM with the PlacesCNN model as the combined Bayesian object relation model (CBORM) for scene recognition and significantly outperforms the state-of-the-art methods on the reduced Places365 dataset, and SUN RGB-D dataset without retraining, showing the excellent generalization ability of the proposed method. Code can be found at https://github.com/hszhoushen/borm.



### Object-to-Scene: Learning to Transfer Object Knowledge to Indoor Scene Recognition
- **Arxiv ID**: http://arxiv.org/abs/2108.00399v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2108.00399v1)
- **Published**: 2021-08-01 08:37:08+00:00
- **Updated**: 2021-08-01 08:37:08+00:00
- **Authors**: Bo Miao, Liguang Zhou, Ajmal Mian, Tin Lun Lam, Yangsheng Xu
- **Comment**: Accepted by IROS2021
- **Journal**: None
- **Summary**: Accurate perception of the surrounding scene is helpful for robots to make reasonable judgments and behaviours. Therefore, developing effective scene representation and recognition methods are of significant importance in robotics. Currently, a large body of research focuses on developing novel auxiliary features and networks to improve indoor scene recognition ability. However, few of them focus on directly constructing object features and relations for indoor scene recognition. In this paper, we analyze the weaknesses of current methods and propose an Object-to-Scene (OTS) method, which extracts object features and learns object relations to recognize indoor scenes. The proposed OTS first extracts object features based on the segmentation network and the proposed object feature aggregation module (OFAM). Afterwards, the object relations are calculated and the scene representation is constructed based on the proposed object attention module (OAM) and global relation aggregation module (GRAM). The final results in this work show that OTS successfully extracts object features and learns object relations from the segmentation network. Moreover, OTS outperforms the state-of-the-art methods by more than 2\% on indoor scene recognition without using any additional streams. Code is publicly available at: https://github.com/FreeformRobotics/OTS.



### Advances in adversarial attacks and defenses in computer vision: A survey
- **Arxiv ID**: http://arxiv.org/abs/2108.00401v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.CR, cs.CY, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2108.00401v2)
- **Published**: 2021-08-01 08:54:47+00:00
- **Updated**: 2021-09-02 09:14:33+00:00
- **Authors**: Naveed Akhtar, Ajmal Mian, Navid Kardan, Mubarak Shah
- **Comment**: 35 pages, 450+ references
- **Journal**: None
- **Summary**: Deep Learning (DL) is the most widely used tool in the contemporary field of computer vision. Its ability to accurately solve complex problems is employed in vision research to learn deep neural models for a variety of tasks, including security critical applications. However, it is now known that DL is vulnerable to adversarial attacks that can manipulate its predictions by introducing visually imperceptible perturbations in images and videos. Since the discovery of this phenomenon in 2013~[1], it has attracted significant attention of researchers from multiple sub-fields of machine intelligence. In [2], we reviewed the contributions made by the computer vision community in adversarial attacks on deep learning (and their defenses) until the advent of year 2018. Many of those contributions have inspired new directions in this area, which has matured significantly since witnessing the first generation methods. Hence, as a legacy sequel of [2], this literature review focuses on the advances in this area since 2018. To ensure authenticity, we mainly consider peer-reviewed contributions published in the prestigious sources of computer vision and machine learning research. Besides a comprehensive literature review, the article also provides concise definitions of technical terminologies for non-experts in this domain. Finally, this article discusses challenges and future outlook of this direction based on the literature reviewed herein and [2].



### Style Curriculum Learning for Robust Medical Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2108.00402v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2108.00402v1)
- **Published**: 2021-08-01 08:56:24+00:00
- **Updated**: 2021-08-01 08:56:24+00:00
- **Authors**: Zhendong Liu, Van Manh, Xin Yang, Xiaoqiong Huang, Karim Lekadir, VÃ­ctor Campello, Nishant Ravikumar, Alejandro F Frangi, Dong Ni
- **Comment**: Accepted by MICCAI-2021
- **Journal**: None
- **Summary**: The performance of deep segmentation models often degrades due to distribution shifts in image intensities between the training and test data sets. This is particularly pronounced in multi-centre studies involving data acquired using multi-vendor scanners, with variations in acquisition protocols. It is challenging to address this degradation because the shift is often not known \textit{a priori} and hence difficult to model. We propose a novel framework to ensure robust segmentation in the presence of such distribution shifts. Our contribution is three-fold. First, inspired by the spirit of curriculum learning, we design a novel style curriculum to train the segmentation models using an easy-to-hard mode. A style transfer model with style fusion is employed to generate the curriculum samples. Gradually focusing on complex and adversarial style samples can significantly boost the robustness of the models. Second, instead of subjectively defining the curriculum complexity, we adopt an automated gradient manipulation method to control the hard and adversarial sample generation process. Third, we propose the Local Gradient Sign strategy to aggregate the gradient locally and stabilise training during gradient manipulation. The proposed framework can generalise to unknown distribution without using any target data. Extensive experiments on the public M\&Ms Challenge dataset demonstrate that our proposed framework can generalise deep models well to unknown distributions and achieve significant improvements in segmentation accuracy.



### Discovering Distinctive "Semantics" in Super-Resolution Networks
- **Arxiv ID**: http://arxiv.org/abs/2108.00406v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2108.00406v3)
- **Published**: 2021-08-01 09:12:44+00:00
- **Updated**: 2022-05-22 16:24:07+00:00
- **Authors**: Yihao Liu, Anran Liu, Jinjin Gu, Zhipeng Zhang, Wenhao Wu, Yu Qiao, Chao Dong
- **Comment**: discovering and interpreting deep degradation representations (DDR)
  in super-resolution networks
- **Journal**: None
- **Summary**: Image super-resolution (SR) is a representative low-level vision problem. Although deep SR networks have achieved extraordinary success, we are still unaware of their working mechanisms. Specifically, whether SR networks can learn semantic information, or just perform complex mapping function? What hinders SR networks from generalizing to real-world data? These questions not only raise our curiosity, but also influence SR network development. In this paper, we make the primary attempt to answer the above fundamental questions. After comprehensively analyzing the feature representations (via dimensionality reduction and visualization), we successfully discover the distinctive "semantics" in SR networks, i.e., deep degradation representations (DDR), which relate to image degradation instead of image content. We show that a well-trained deep SR network is naturally a good descriptor of degradation information. Our experiments also reveal two key factors (adversarial learning and global residual) that influence the extraction of such semantics. We further apply DDR in several interesting applications (such as distortion identification, blind SR and generalization evaluation) and achieve promising results, demonstrating the correctness and effectiveness of our findings.



### CSC-Unet: A Novel Convolutional Sparse Coding Strategy based Neural Network for Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2108.00408v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2108.00408v1)
- **Published**: 2021-08-01 09:16:31+00:00
- **Updated**: 2021-08-01 09:16:31+00:00
- **Authors**: Haitong Tang, Shuang He, Xia Lu, Qin Yu, Kaiyue Liu, Hongjie Yan, Nizhuan Wang
- **Comment**: None
- **Journal**: None
- **Summary**: It is a challenging task to accurately perform semantic segmentation due to the complexity of real picture scenes. Many semantic segmentation methods based on traditional deep learning insufficiently captured the semantic and appearance information of images, which put limit on their generality and robustness for various application scenes. In this paper, we proposed a novel strategy that reformulated the popularly-used convolution operation to multi-layer convolutional sparse coding block to ease the aforementioned deficiency. This strategy can be possibly used to significantly improve the segmentation performance of any semantic segmentation model that involves convolutional operations. To prove the effectiveness of our idea, we chose the widely-used U-Net model for the demonstration purpose, and we designed CSC-Unet model series based on U-Net. Through extensive analysis and experiments, we provided credible evidence showing that the multi-layer convolutional sparse coding block enables semantic segmentation model to converge faster, can extract finer semantic and appearance information of images, and improve the ability to recover spatial detail information. The best CSC-Unet model significantly outperforms the results of the original U-Net on three public datasets with different scenarios, i.e., 87.14% vs. 84.71% on DeepCrack dataset, 68.91% vs. 67.09% on Nuclei dataset, and 53.68% vs. 48.82% on CamVid dataset, respectively.



### Automated Pest Detection with DNN on the Edge for Precision Agriculture
- **Arxiv ID**: http://arxiv.org/abs/2108.00421v1
- **DOI**: 10.1109/JETCAS.2021.3101740
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2108.00421v1)
- **Published**: 2021-08-01 10:17:48+00:00
- **Updated**: 2021-08-01 10:17:48+00:00
- **Authors**: Andrea Albanese, Matteo Nardello, Davide Brunelli
- **Comment**: 10 pages, 12 figures, 3 tables
- **Journal**: None
- **Summary**: Artificial intelligence has smoothly penetrated several economic activities, especially monitoring and control applications, including the agriculture sector. However, research efforts toward low-power sensing devices with fully functional machine learning (ML) on-board are still fragmented and limited in smart farming. Biotic stress is one of the primary causes of crop yield reduction. With the development of deep learning in computer vision technology, autonomous detection of pest infestation through images has become an important research direction for timely crop disease diagnosis. This paper presents an embedded system enhanced with ML functionalities, ensuring continuous detection of pest infestation inside fruit orchards. The embedded solution is based on a low-power embedded sensing system along with a Neural Accelerator able to capture and process images inside common pheromone-based traps. Three different ML algorithms have been trained and deployed, highlighting the capabilities of the platform. Moreover, the proposed approach guarantees an extended battery life thanks to the integration of energy harvesting functionalities. Results show how it is possible to automate the task of pest infestation for unlimited time without the farmer's intervention.



### An Effective and Robust Detector for Logo Detection
- **Arxiv ID**: http://arxiv.org/abs/2108.00422v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2108.00422v1)
- **Published**: 2021-08-01 10:17:53+00:00
- **Updated**: 2021-08-01 10:17:53+00:00
- **Authors**: Xiaojun Jia, Huanqian Yan, Yonglin Wu, Xingxing Wei, Xiaochun Cao, Yong Zhang
- **Comment**: 5 pages
- **Journal**: None
- **Summary**: In recent years, intellectual property (IP), which represents literary, inventions, artistic works, etc, gradually attract more and more people's attention. Particularly, with the rise of e-commerce, the IP not only represents the product design and brands, but also represents the images/videos displayed on e-commerce platforms. Unfortunately, some attackers adopt some adversarial methods to fool the well-trained logo detection model for infringement. To overcome this problem, a novel logo detector based on the mechanism of looking and thinking twice is proposed in this paper for robust logo detection. The proposed detector is different from other mainstream detectors, which can effectively detect small objects, long-tail objects, and is robust to adversarial images. In detail, we extend detectoRS algorithm to a cascade schema with an equalization loss function, multi-scale transformations, and adversarial data augmentation. A series of experimental results have shown that the proposed method can effectively improve the robustness of the detection model. Moreover, we have applied the proposed methods to competition ACM MM2021 Robust Logo Detection that is organized by Alibaba on the Tianchi platform and won top 2 in 36489 teams. Code is available at https://github.com/jiaxiaojunQAQ/Robust-Logo-Detection.



### Hyper360 -- a Next Generation Toolset for Immersive Media
- **Arxiv ID**: http://arxiv.org/abs/2108.00430v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2108.00430v1)
- **Published**: 2021-08-01 11:04:32+00:00
- **Updated**: 2021-08-01 11:04:32+00:00
- **Authors**: Hannes Fassold, Antonis Karakottas, Dorothea Tsatsou, Dimitrios Zarpalas, Barnabas Takacs, Christian Fuhrhop, Angelo Manfredi, Nicolas Patz, Simona Tonoli, Iana Dulskaia
- **Comment**: Technical report
- **Journal**: None
- **Summary**: Spherical 360{\deg} video is a novel media format, rapidly becoming adopted in media production and consumption of immersive media. Due to its novelty, there is a lack of tools for producing highly engaging interactive 360{\deg} video for consumption on a multitude of platforms. In this work, we describe the work done so far in the Hyper360 project on tools for mixed 360{\deg} video and 3D content. Furthermore, the first pilots which have been produced with the Hyper360 tools and results of the audience assessment of the produced pilots are presented.



### Generating Master Faces for Dictionary Attacks with a Network-Assisted Latent Space Evolution
- **Arxiv ID**: http://arxiv.org/abs/2108.01077v3
- **DOI**: None
- **Categories**: **cs.CR**, cs.CV, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/2108.01077v3)
- **Published**: 2021-08-01 12:55:23+00:00
- **Updated**: 2021-08-19 18:08:43+00:00
- **Authors**: Ron Shmelkin, Tomer Friedlander, Lior Wolf
- **Comment**: accepted to IEEE International Conference on Automatic Face & Gesture
  Recognition 2021
- **Journal**: None
- **Summary**: A master face is a face image that passes face-based identity-authentication for a large portion of the population. These faces can be used to impersonate, with a high probability of success, any user, without having access to any user-information. We optimize these faces, by using an evolutionary algorithm in the latent embedding space of the StyleGAN face generator. Multiple evolutionary strategies are compared, and we propose a novel approach that employs a neural network in order to direct the search in the direction of promising samples, without adding fitness evaluations. The results we present demonstrate that it is possible to obtain a high coverage of the LFW identities (over 40%) with less than 10 master faces, for three leading deep face recognition systems.



### SSPU-Net: Self-Supervised Point Cloud Upsampling via Differentiable Rendering
- **Arxiv ID**: http://arxiv.org/abs/2108.00454v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2108.00454v2)
- **Published**: 2021-08-01 13:26:01+00:00
- **Updated**: 2021-08-03 13:32:40+00:00
- **Authors**: Yifan Zhao, Le Hui, Jin Xie
- **Comment**: Accepted by ACM Multimedia 2021
- **Journal**: None
- **Summary**: Point clouds obtained from 3D sensors are usually sparse. Existing methods mainly focus on upsampling sparse point clouds in a supervised manner by using dense ground truth point clouds. In this paper, we propose a self-supervised point cloud upsampling network (SSPU-Net) to generate dense point clouds without using ground truth. To achieve this, we exploit the consistency between the input sparse point cloud and generated dense point cloud for the shapes and rendered images. Specifically, we first propose a neighbor expansion unit (NEU) to upsample the sparse point clouds, where the local geometric structures of the sparse point clouds are exploited to learn weights for point interpolation. Then, we develop a differentiable point cloud rendering unit (DRU) as an end-to-end module in our network to render the point cloud into multi-view images. Finally, we formulate a shape-consistent loss and an image-consistent loss to train the network so that the shapes of the sparse and dense point clouds are as consistent as possible. Extensive results on the CAD and scanned datasets demonstrate that our method can achieve impressive results in a self-supervised manner. Code is available at https://github.com/fpthink/SSPU-Net.



### Explainable Deep Few-shot Anomaly Detection with Deviation Networks
- **Arxiv ID**: http://arxiv.org/abs/2108.00462v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2108.00462v1)
- **Published**: 2021-08-01 14:33:17+00:00
- **Updated**: 2021-08-01 14:33:17+00:00
- **Authors**: Guansong Pang, Choubo Ding, Chunhua Shen, Anton van den Hengel
- **Comment**: 16 pages, 8 figures, 5 tables
- **Journal**: None
- **Summary**: Existing anomaly detection paradigms overwhelmingly focus on training detection models using exclusively normal data or unlabeled data (mostly normal samples). One notorious issue with these approaches is that they are weak in discriminating anomalies from normal samples due to the lack of the knowledge about the anomalies. Here, we study the problem of few-shot anomaly detection, in which we aim at using a few labeled anomaly examples to train sample-efficient discriminative detection models. To address this problem, we introduce a novel weakly-supervised anomaly detection framework to train detection models without assuming the examples illustrating all possible classes of anomaly.   Specifically, the proposed approach learns discriminative normality (regularity) by leveraging the labeled anomalies and a prior probability to enforce expressive representations of normality and unbounded deviated representations of abnormality. This is achieved by an end-to-end optimization of anomaly scores with a neural deviation learning, in which the anomaly scores of normal samples are imposed to approximate scalar scores drawn from the prior while that of anomaly examples is enforced to have statistically significant deviations from these sampled scores in the upper tail. Furthermore, our model is optimized to learn fine-grained normality and abnormality by top-K multiple-instance-learning-based feature subspace deviation learning, allowing more generalized representations. Comprehensive experiments on nine real-world image anomaly detection benchmarks show that our model is substantially more sample-efficient and robust, and performs significantly better than state-of-the-art competing methods in both closed-set and open-set settings. Our model can also offer explanation capability as a result of its prior-driven anomaly score learning. Code and datasets are available at: https://git.io/DevNet.



### Self-supervised Learning with Local Attention-Aware Feature
- **Arxiv ID**: http://arxiv.org/abs/2108.00475v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2108.00475v1)
- **Published**: 2021-08-01 15:26:30+00:00
- **Updated**: 2021-08-01 15:26:30+00:00
- **Authors**: Trung X. Pham, Rusty John Lloyd Mina, Dias Issa, Chang D. Yoo
- **Comment**: 5 pages, 4 figures
- **Journal**: None
- **Summary**: In this work, we propose a novel methodology for self-supervised learning for generating global and local attention-aware visual features. Our approach is based on training a model to differentiate between specific image transformations of an input sample and the patched images. Utilizing this approach, the proposed method is able to outperform the previous best competitor by 1.03% on the Tiny-ImageNet dataset and by 2.32% on the STL-10 dataset. Furthermore, our approach outperforms the fully-supervised learning method on the STL-10 dataset. Experimental results and visualizations show the capability of successfully learning global and local attention-aware visual representations.



### CERL: A Unified Optimization Framework for Light Enhancement with Realistic Noise
- **Arxiv ID**: http://arxiv.org/abs/2108.00478v2
- **DOI**: 10.1109/TIP.2022.3180213
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2108.00478v2)
- **Published**: 2021-08-01 15:31:15+00:00
- **Updated**: 2022-05-22 13:42:54+00:00
- **Authors**: Zeyuan Chen, Yifan Jiang, Dong Liu, Zhangyang Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Low-light images captured in the real world are inevitably corrupted by sensor noise. Such noise is spatially variant and highly dependent on the underlying pixel intensity, deviating from the oversimplified assumptions in conventional denoising. Existing light enhancement methods either overlook the important impact of real-world noise during enhancement, or treat noise removal as a separate pre- or post-processing step. We present \underline{C}oordinated \underline{E}nhancement for \underline{R}eal-world \underline{L}ow-light Noisy Images (CERL), that seamlessly integrates light enhancement and noise suppression parts into a unified and physics-grounded optimization framework. For the real low-light noise removal part, we customize a self-supervised denoising model that can easily be adapted without referring to clean ground-truth images. For the light enhancement part, we also improve the design of a state-of-the-art backbone. The two parts are then joint formulated into one principled plug-and-play optimization. Our approach is compared against state-of-the-art low-light enhancement methods both qualitatively and quantitatively. Besides standard benchmarks, we further collect and test on a new realistic low-light mobile photography dataset (RLMP), whose mobile-captured photos display heavier realistic noise than those taken by high-quality cameras. CERL consistently produces the most visually pleasing and artifact-free results across all experiments. Our RLMP dataset and codes are available at: https://github.com/VITA-Group/CERL.



### BundleTrack: 6D Pose Tracking for Novel Objects without Instance or Category-Level 3D Models
- **Arxiv ID**: http://arxiv.org/abs/2108.00516v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.GR, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2108.00516v1)
- **Published**: 2021-08-01 18:14:46+00:00
- **Updated**: 2021-08-01 18:14:46+00:00
- **Authors**: Bowen Wen, Kostas Bekris
- **Comment**: None
- **Journal**: None
- **Summary**: Tracking the 6D pose of objects in video sequences is important for robot manipulation. Most prior efforts, however, often assume that the target object's CAD model, at least at a category-level, is available for offline training or during online template matching. This work proposes BundleTrack, a general framework for 6D pose tracking of novel objects, which does not depend upon 3D models, either at the instance or category-level. It leverages the complementary attributes of recent advances in deep learning for segmentation and robust feature extraction, as well as memory-augmented pose graph optimization for spatiotemporal consistency. This enables long-term, low-drift tracking under various challenging scenarios, including significant occlusions and object motions. Comprehensive experiments given two public benchmarks demonstrate that the proposed approach significantly outperforms state-of-art, category-level 6D tracking or dynamic SLAM methods. When compared against state-of-art methods that rely on an object instance CAD model, comparable performance is achieved, despite the proposed method's reduced information requirements. An efficient implementation in CUDA provides a real-time performance of 10Hz for the entire framework. Code is available at: https://github.com/wenbowen123/BundleTrack



### PSE-Match: A Viewpoint-free Place Recognition Method with Parallel Semantic Embedding
- **Arxiv ID**: http://arxiv.org/abs/2108.00552v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2108.00552v2)
- **Published**: 2021-08-01 22:16:40+00:00
- **Updated**: 2021-08-27 23:02:08+00:00
- **Authors**: Peng Yin, Lingyun Xu, Ziyue Feng, Anton Egorov, Bing Li
- **Comment**: 12 pages, 12 figures, accepted by IEEE Transactions on Intelligent
  Transportation Systems
- **Journal**: None
- **Summary**: Accurate localization on autonomous driving cars is essential for autonomy and driving safety, especially for complex urban streets and search-and-rescue subterranean environments where high-accurate GPS is not available. However current odometry estimation may introduce the drifting problems in long-term navigation without robust global localization. The main challenges involve scene divergence under the interference of dynamic environments and effective perception of observation and object layout variance from different viewpoints. To tackle these challenges, we present PSE-Match, a viewpoint-free place recognition method based on parallel semantic analysis of isolated semantic attributes from 3D point-cloud models. Compared with the original point cloud, the observed variance of semantic attributes is smaller. PSE-Match incorporates a divergence place learning network to capture different semantic attributes parallelly through the spherical harmonics domain. Using both existing benchmark datasets and two in-field collected datasets, our experiments show that the proposed method achieves above 70% average recall with top one retrieval and above 95% average recall with top ten retrieval cases. And PSE-Match has also demonstrated an obvious generalization ability with a limited training dataset.



### Learning Maritime Obstacle Detection from Weak Annotations by Scaffolding
- **Arxiv ID**: http://arxiv.org/abs/2108.00564v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2108.00564v1)
- **Published**: 2021-08-01 23:37:57+00:00
- **Updated**: 2021-08-01 23:37:57+00:00
- **Authors**: Lojze Å½ust, Matej Kristan
- **Comment**: Accepted to WACV 2022
- **Journal**: None
- **Summary**: Coastal water autonomous boats rely on robust perception methods for obstacle detection and timely collision avoidance. The current state-of-the-art is based on deep segmentation networks trained on large datasets. Per-pixel ground truth labeling of such datasets, however, is labor-intensive and expensive. We observe that far less information is required for practical obstacle avoidance - the location of water edge on static obstacles like shore and approximate location and bounds of dynamic obstacles in the water is sufficient to plan a reaction. We propose a new scaffolding learning regime (SLR) that allows training obstacle detection segmentation networks only from such weak annotations, thus significantly reducing the cost of ground-truth labeling. Experiments show that maritime obstacle segmentation networks trained using SLR substantially outperform the same networks trained with dense ground truth labels. Thus accuracy is not sacrificed for labelling simplicity but is in fact improved, which is a remarkable result.



### FLASH: Fast Neural Architecture Search with Hardware Optimization
- **Arxiv ID**: http://arxiv.org/abs/2108.00568v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2108.00568v1)
- **Published**: 2021-08-01 23:46:48+00:00
- **Updated**: 2021-08-01 23:46:48+00:00
- **Authors**: Guihong Li, Sumit K. Mandal, Umit Y. Ogras, Radu Marculescu
- **Comment**: Published at ACM CODES+ISSS 2021
- **Journal**: None
- **Summary**: Neural architecture search (NAS) is a promising technique to design efficient and high-performance deep neural networks (DNNs). As the performance requirements of ML applications grow continuously, the hardware accelerators start playing a central role in DNN design. This trend makes NAS even more complicated and time-consuming for most real applications. This paper proposes FLASH, a very fast NAS methodology that co-optimizes the DNN accuracy and performance on a real hardware platform. As the main theoretical contribution, we first propose the NN-Degree, an analytical metric to quantify the topological characteristics of DNNs with skip connections (e.g., DenseNets, ResNets, Wide-ResNets, and MobileNets). The newly proposed NN-Degree allows us to do training-free NAS within one second and build an accuracy predictor by training as few as 25 samples out of a vast search space with more than 63 billion configurations. Second, by performing inference on the target hardware, we fine-tune and validate our analytical models to estimate the latency, area, and energy consumption of various DNN architectures while executing standard ML datasets. Third, we construct a hierarchical algorithm based on simplicial homology global optimization (SHGO) to optimize the model-architecture co-design process, while considering the area, latency, and energy consumption of the target hardware. We demonstrate that, compared to the state-of-the-art NAS approaches, our proposed hierarchical SHGO-based algorithm enables more than four orders of magnitude speedup (specifically, the execution time of the proposed algorithm is about 0.1 seconds). Finally, our experimental evaluations show that FLASH is easily transferable to different hardware architectures, thus enabling us to do NAS on a Raspberry Pi-3B processor in less than 3 seconds.



