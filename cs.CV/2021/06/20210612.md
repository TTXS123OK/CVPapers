# Arxiv Papers in cs.CV on 2021-06-12
### 1st Place Solution for YouTubeVOS Challenge 2021:Video Instance Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2106.06649v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.06649v2)
- **Published**: 2021-06-12 00:20:38+00:00
- **Updated**: 2021-07-09 02:29:17+00:00
- **Authors**: Thuy C. Nguyen, Tuan N. Tang, Nam LH. Phan, Chuong H. Nguyen, Masayuki Yamazaki, Masao Yamanaka
- **Comment**: Accepted to CPVR 2021 Workshop
- **Journal**: None
- **Summary**: Video Instance Segmentation (VIS) is a multi-task problem performing detection, segmentation, and tracking simultaneously. Extended from image set applications, video data additionally induces the temporal information, which, if handled appropriately, is very useful to identify and predict object motions. In this work, we design a unified model to mutually learn these tasks. Specifically, we propose two modules, named Temporally Correlated Instance Segmentation (TCIS) and Bidirectional Tracking (BiTrack), to take the benefit of the temporal correlation between the object's instance masks across adjacent frames. On the other hand, video data is often redundant due to the frame's overlap. Our analysis shows that this problem is particularly severe for the YoutubeVOS-VIS2021 data. Therefore, we propose a Multi-Source Data (MSD) training mechanism to compensate for the data deficiency. By combining these techniques with a bag of tricks, the network performance is significantly boosted compared to the baseline, and outperforms other methods by a considerable margin on the YoutubeVOS-VIS 2019 and 2021 datasets.



### Large-Scale Unsupervised Object Discovery
- **Arxiv ID**: http://arxiv.org/abs/2106.06650v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.06650v2)
- **Published**: 2021-06-12 00:29:49+00:00
- **Updated**: 2021-11-16 22:43:27+00:00
- **Authors**: Huy V. Vo, Elena Sizikova, Cordelia Schmid, Patrick Pérez, Jean Ponce
- **Comment**: Accepted to NeurIPS 2021, 19 pages with supplemental materials
- **Journal**: None
- **Summary**: Existing approaches to unsupervised object discovery (UOD) do not scale up to large datasets without approximations that compromise their performance. We propose a novel formulation of UOD as a ranking problem, amenable to the arsenal of distributed methods available for eigenvalue problems and link analysis. Through the use of self-supervised features, we also demonstrate the first effective fully unsupervised pipeline for UOD. Extensive experiments on COCO and OpenImages show that, in the single-object discovery setting where a single prominent object is sought in each image, the proposed LOD (Large-scale Object Discovery) approach is on par with, or better than the state of the art for medium-scale datasets (up to 120K images), and over 37% better than the only other algorithms capable of scaling up to 1.7M images. In the multi-object discovery setting where multiple objects are sought in each image, the proposed LOD is over 14% better in average precision (AP) than all other methods for datasets ranging from 20K to 1.7M images. Using self-supervised features, we also show that the proposed method obtains state-of-the-art UOD performance on OpenImages. Our code is publicly available at https://github.com/huyvvo/LOD.



### Disrupting Model Training with Adversarial Shortcuts
- **Arxiv ID**: http://arxiv.org/abs/2106.06654v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.CR, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2106.06654v2)
- **Published**: 2021-06-12 01:04:41+00:00
- **Updated**: 2021-06-30 21:48:44+00:00
- **Authors**: Ivan Evtimov, Ian Covert, Aditya Kusupati, Tadayoshi Kohno
- **Comment**: None
- **Journal**: None
- **Summary**: When data is publicly released for human consumption, it is unclear how to prevent its unauthorized usage for machine learning purposes. Successful model training may be preventable with carefully designed dataset modifications, and we present a proof-of-concept approach for the image classification setting. We propose methods based on the notion of adversarial shortcuts, which encourage models to rely on non-robust signals rather than semantic features, and our experiments demonstrate that these measures successfully prevent deep learning models from achieving high accuracy on real, unmodified data examples.



### Rapid COVID-19 Risk Screening by Eye-region Manifestations
- **Arxiv ID**: http://arxiv.org/abs/2106.06664v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.06664v1)
- **Published**: 2021-06-12 01:56:10+00:00
- **Updated**: 2021-06-12 01:56:10+00:00
- **Authors**: Yanwei Fu, Lei Zhao, Haojie Zheng, Qiang Sun, Li Yang, Hong Li, Jiao Xie, Xiangyang Xue, Feng Li, Yuan Li, Wei Wang, Yantao Pei, Jianmin Wang, Xiuqi Wu, Yanhua Zheng, Hongxia Tian Mengwei Gu1
- **Comment**: None
- **Journal**: None
- **Summary**: It is still nontrivial to develop a new fast COVID-19 screening method with the easier access and lower cost, due to the technical and cost limitations of the current testing methods in the medical resource-poor districts. On the other hand, there are more and more ocular manifestations that have been reported in the COVID-19 patients as growing clinical evidence[1]. This inspired this project. We have conducted the joint clinical research since January 2021 at the ShiJiaZhuang City, Heibei province, China, which approved by the ethics committee of The fifth hospital of ShiJiaZhuang of Hebei Medical University. We undertake several blind tests of COVID-19 patients by Union Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China. Meantime as an important part of the ongoing globally COVID-19 eye test program by AIMOMICS since February 2020, we propose a new fast screening method of analyzing the eye-region images, captured by common CCD and CMOS cameras. This could reliably make a rapid risk screening of COVID-19 with the sustainable stable high performance in different countries and races. Our model for COVID-19 rapid prescreening have the merits of the lower cost, fully self-performed, non-invasive, importantly real-time, and thus enables the continuous health surveillance. We further implement it as the open accessible APIs, and provide public service to the world. Our pilot experiments show that our model is ready to be usable to all kinds of surveillance scenarios, such as infrared temperature measurement device at airports and stations, or directly pushing to the target people groups smartphones as a packaged application.



### Structure-Regularized Attention for Deformable Object Representation
- **Arxiv ID**: http://arxiv.org/abs/2106.06672v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.06672v1)
- **Published**: 2021-06-12 03:10:17+00:00
- **Updated**: 2021-06-12 03:10:17+00:00
- **Authors**: Shenao Zhang, Li Shen, Zhifeng Li, Wei Liu
- **Comment**: Published at NeurIPS 2020 Workshop on Object Representations for
  Learning and Reasoning; code is available at
  https://github.com/shenao-zhang/StRA
- **Journal**: None
- **Summary**: Capturing contextual dependencies has proven useful to improve the representational power of deep neural networks. Recent approaches that focus on modeling global context, such as self-attention and non-local operation, achieve this goal by enabling unconstrained pairwise interactions between elements. In this work, we consider learning representations for deformable objects which can benefit from context exploitation by modeling the structural dependencies that the data intrinsically possesses. To this end, we provide a novel structure-regularized attention mechanism, which formalizes feature interaction as structural factorization through the use of a pair of light-weight operations. The instantiated building blocks can be directly incorporated into modern convolutional neural networks, to boost the representational power in an efficient manner. Comprehensive studies on multiple tasks and empirical comparisons with modern attention mechanisms demonstrate the gains brought by our method in terms of both performance and model complexity. We further investigate its effect on feature representations, showing that our trained models can capture diversified representations characterizing object parts without resorting to extra supervision.



### Multistream ValidNet: Improving 6D Object Pose Estimation by Automatic Multistream Validation
- **Arxiv ID**: http://arxiv.org/abs/2106.06684v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.06684v1)
- **Published**: 2021-06-12 04:11:28+00:00
- **Updated**: 2021-06-12 04:11:28+00:00
- **Authors**: Joy Mazumder, Mohsen Zand, Michael Greenspan
- **Comment**: 6 pages, 2 figures, 2 tables. To appear in the proceedings of the
  28th IEEE International Conference on Image Processing (IEEE - ICIP),
  September 19-22, 2021, Anchorage, Alaska, USA
- **Journal**: None
- **Summary**: This work presents a novel approach to improve the results of pose estimation by detecting and distinguishing between the occurrence of True and False Positive results. It achieves this by training a binary classifier on the output of an arbitrary pose estimation algorithm, and returns a binary label indicating the validity of the result. We demonstrate that our approach improves upon a state-of-the-art pose estimation result on the Sil\'eane dataset, outperforming a variation of the alternative CullNet method by 4.15% in average class accuracy and 0.73% in overall accuracy at validation. Applying our method can also improve the pose estimation average precision results of Op-Net by 6.06% on average.



### Adversarial Robustness via Fisher-Rao Regularization
- **Arxiv ID**: http://arxiv.org/abs/2106.06685v3
- **DOI**: 10.1109/TPAMI.2022.3174724
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.06685v3)
- **Published**: 2021-06-12 04:12:58+00:00
- **Updated**: 2022-06-13 21:54:21+00:00
- **Authors**: Marine Picot, Francisco Messina, Malik Boudiaf, Fabrice Labeau, Ismail Ben Ayed, Pablo Piantanida
- **Comment**: IEEE Transactions on Pattern Analysis and Machine Intelligence (Early
  Access)
- **Journal**: None
- **Summary**: Adversarial robustness has become a topic of growing interest in machine learning since it was observed that neural networks tend to be brittle. We propose an information-geometric formulation of adversarial defense and introduce FIRE, a new Fisher-Rao regularization for the categorical cross-entropy loss, which is based on the geodesic distance between the softmax outputs corresponding to natural and perturbed input features. Based on the information-geometric properties of the class of softmax distributions, we derive an explicit characterization of the Fisher-Rao Distance (FRD) for the binary and multiclass cases, and draw some interesting properties as well as connections with standard regularization metrics. Furthermore, for a simple linear and Gaussian model, we show that all Pareto-optimal points in the accuracy-robustness region can be reached by FIRE while other state-of-the-art methods fail. Empirically, we evaluate the performance of various classifiers trained with the proposed loss on standard datasets, showing up to a simultaneous 1\% of improvement in terms of clean and robust performances while reducing the training time by 20\% over the best-performing methods.



### Reverse-engineer the Distributional Structure of Infant Egocentric Views for Training Generalizable Image Classifiers
- **Arxiv ID**: http://arxiv.org/abs/2106.06694v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.06694v1)
- **Published**: 2021-06-12 06:02:40+00:00
- **Updated**: 2021-06-12 06:02:40+00:00
- **Authors**: Satoshi Tsutsui, David Crandall, Chen Yu
- **Comment**: Accepted to 2021 CVPR Workshop on Egocentric Perception, Interaction
  and Computing (EPIC)
- **Journal**: None
- **Summary**: We analyze egocentric views of attended objects from infants. This paper shows 1) empirical evidence that children's egocentric views have more diverse distributions compared to adults' views, 2) we can computationally simulate the infants' distribution, and 3) the distribution is beneficial for training more generalized image classifiers not only for infant egocentric vision but for third-person computer vision.



### Unsupervised Place Recognition with Deep Embedding Learning over Radar Videos
- **Arxiv ID**: http://arxiv.org/abs/2106.06703v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2106.06703v1)
- **Published**: 2021-06-12 07:14:15+00:00
- **Updated**: 2021-06-12 07:14:15+00:00
- **Authors**: Matthew Gadd, Daniele De Martini, Paul Newman
- **Comment**: to be presented at the Workshop on Radar Perception for All-Weather
  Autonomy at the IEEE International Conference on Robotics and Automation
  (ICRA) 2021
- **Journal**: None
- **Summary**: We learn, in an unsupervised way, an embedding from sequences of radar images that is suitable for solving place recognition problem using complex radar data. We experiment on 280 km of data and show performance exceeding state-of-the-art supervised approaches, localising correctly 98.38% of the time when using just the nearest database candidate.



### DS-TransUNet:Dual Swin Transformer U-Net for Medical Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2106.06716v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.06716v1)
- **Published**: 2021-06-12 08:37:17+00:00
- **Updated**: 2021-06-12 08:37:17+00:00
- **Authors**: Ailiang Lin, Bingzhi Chen, Jiayu Xu, Zheng Zhang, Guangming Lu
- **Comment**: None
- **Journal**: None
- **Summary**: Automatic medical image segmentation has made great progress benefit from the development of deep learning. However, most existing methods are based on convolutional neural networks (CNNs), which fail to build long-range dependencies and global context connections due to the limitation of receptive field in convolution operation. Inspired by the success of Transformer in modeling the long-range contextual information, some researchers have expended considerable efforts in designing the robust variants of Transformer-based U-Net. Moreover, the patch division used in vision transformers usually ignores the pixel-level intrinsic structural features inside each patch. To alleviate these problems, we propose a novel deep medical image segmentation framework called Dual Swin Transformer U-Net (DS-TransUNet), which might be the first attempt to concurrently incorporate the advantages of hierarchical Swin Transformer into both encoder and decoder of the standard U-shaped architecture to enhance the semantic segmentation quality of varying medical images. Unlike many prior Transformer-based solutions, the proposed DS-TransUNet first adopts dual-scale encoder subnetworks based on Swin Transformer to extract the coarse and fine-grained feature representations of different semantic scales. As the core component for our DS-TransUNet, a well-designed Transformer Interactive Fusion (TIF) module is proposed to effectively establish global dependencies between features of different scales through the self-attention mechanism. Furthermore, we also introduce the Swin Transformer block into decoder to further explore the long-range contextual information during the up-sampling process. Extensive experiments across four typical tasks for medical image segmentation demonstrate the effectiveness of DS-TransUNet, and show that our approach significantly outperforms the state-of-the-art methods.



### Using Convolutional Neural Networks for the Helicity Classification of Magnetic Fields
- **Arxiv ID**: http://arxiv.org/abs/2106.06718v1
- **DOI**: None
- **Categories**: **astro-ph.HE**, cs.AI, cs.CV, cs.LG, hep-ph
- **Links**: [PDF](http://arxiv.org/pdf/2106.06718v1)
- **Published**: 2021-06-12 08:48:25+00:00
- **Updated**: 2021-06-12 08:48:25+00:00
- **Authors**: Nicolò Oreste Pinciroli Vago, Ibrahim A. Hameed, Michael Kachelriess
- **Comment**: 14 pages, extended version of a contribution to the proceedings of
  the 37.th ICRC 2021
- **Journal**: None
- **Summary**: The presence of non-zero helicity in intergalactic magnetic fields is a smoking gun for their primordial origin since they have to be generated by processes that break CP invariance. As an experimental signature for the presence of helical magnetic fields, an estimator $Q$ based on the triple scalar product of the wave-vectors of photons generated in electromagnetic cascades from, e.g., TeV blazars, has been suggested previously. We propose to apply deep learning to helicity classification employing Convolutional Neural Networks and show that this method outperforms the $Q$ estimator.



### Go Small and Similar: A Simple Output Decay Brings Better Performance
- **Arxiv ID**: http://arxiv.org/abs/2106.06726v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.06726v1)
- **Published**: 2021-06-12 09:36:06+00:00
- **Updated**: 2021-06-12 09:36:06+00:00
- **Authors**: Xuan Cheng, Tianshu Xie, Xiaomin Wang, Jiali Deng, Minghui Liu, Ming Liu
- **Comment**: None
- **Journal**: None
- **Summary**: Regularization and data augmentation methods have been widely used and become increasingly indispensable in deep learning training. Researchers who devote themselves to this have considered various possibilities. But so far, there has been little discussion about regularizing outputs of the model. This paper begins with empirical observations that better performances are significantly associated with output distributions, that have smaller average values and variances. By audaciously assuming there is causality involved, we propose a novel regularization term, called Output Decay, that enforces the model to assign smaller and similar output values on each class. Though being counter-intuitive, such a small modification result in a remarkable improvement on performance. Extensive experiments demonstrate the wide applicability, versatility, and compatibility of Output Decay.



### LENAS: Learning-based Neural Architecture Search and Ensemble for 3D Radiotherapy Dose Prediction
- **Arxiv ID**: http://arxiv.org/abs/2106.06733v3
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2106.06733v3)
- **Published**: 2021-06-12 10:08:52+00:00
- **Updated**: 2022-02-09 12:22:29+00:00
- **Authors**: Yi Lin, Yanfei Liu, Hao Chen, Xin Yang, Kai Ma, Yefeng Zheng, Kwang-Ting Cheng
- **Comment**: None
- **Journal**: None
- **Summary**: Radiation therapy treatment planning is a complex process, as the target dose prescription and normal tissue sparing are conflicting objectives. In order to reduce human planning time efforts and improve the quality of treatment planning, knowledge-based planning (KBP) is in high demand. In this study, we propose a novel learning-based ensemble approach, named LENAS, which integrates neural architecture search (NAS) with knowledge distillation for 3D radiotherapy dose prediction. Specifically, the prediction network first exhaustively searches each block from an enormous architecture space. Then, multiple architectures with promising performance and a large diversity are selected. To reduce the inference time, we adopt the teacher-student paradigm by treating the combination of diverse outputs from multiple learned networks as supervisions to guide the student network training. In addition, we apply adversarial learning to optimize the student network to recover the knowledge in teacher networks. To the best of our knowledge, this is the first attempt to investigate NAS and knowledge distillation in ensemble learning, especially in the field of medical image analysis. The proposed method has been evaluated on two public datasets, i.e., the OpenKBP and AIMIS dataset. Extensive experimental results demonstrate the effectiveness of our method and its superior performance to the state-of-the-art methods. In addition, several in-depth analysis and empirical guidelines are derived for ensemble learning.



### Predicting Depth from Semantic Segmentation using Game Engine Dataset
- **Arxiv ID**: http://arxiv.org/abs/2106.15257v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.RO, 68T45, I.4.6; I.4.8
- **Links**: [PDF](http://arxiv.org/pdf/2106.15257v1)
- **Published**: 2021-06-12 10:15:40+00:00
- **Updated**: 2021-06-12 10:15:40+00:00
- **Authors**: Mohammad Amin Kashi
- **Comment**: 79 pages, Master's thesis at K. N. Toosi University of Technology,
  supervised by Professor Hamid D. Taghirad
- **Journal**: None
- **Summary**: Depth perception is fundamental for robots to understand the surrounding environment. As the view of cognitive neuroscience, visual depth perception methods are divided into three categories, namely binocular, active, and pictorial. The first two categories have been studied for decades in detail. However, research for the exploration of the third category is still in its infancy and has got momentum by the advent of deep learning methods in recent years. In cognitive neuroscience, it is known that pictorial depth perception mechanisms are dependent on the perception of seen objects. Inspired by this fact, in this thesis, we investigated the relation of perception of objects and depth estimation convolutional neural networks. For this purpose, we developed new network structures based on a simple depth estimation network that only used a single image at its input. Our proposed structures use both an image and a semantic label of the image as their input. We used semantic labels as the output of object perception. The obtained results of performance comparison between the developed network and original network showed that our novel structures can improve the performance of depth estimation by 52\% of relative error of distance in the examined cases. Most of the experimental studies were carried out on synthetic datasets that were generated by game engines to isolate the performance comparison from the effect of inaccurate depth and semantic labels of non-synthetic datasets. It is shown that particular synthetic datasets may be used for training of depth networks in cases that an appropriate dataset is not available. Furthermore, we showed that in these cases, usage of semantic labels improves the robustness of the network against domain shift from synthetic training data to non-synthetic test data.



### Multi-level Attention Fusion Network for Audio-visual Event Recognition
- **Arxiv ID**: http://arxiv.org/abs/2106.06736v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2106.06736v1)
- **Published**: 2021-06-12 10:24:52+00:00
- **Updated**: 2021-06-12 10:24:52+00:00
- **Authors**: Mathilde Brousmiche, Jean Rouat, Stéphane Dupont
- **Comment**: Preprint submitted to the Information Fusion journal in August 2020
- **Journal**: None
- **Summary**: Event classification is inherently sequential and multimodal. Therefore, deep neural models need to dynamically focus on the most relevant time window and/or modality of a video. In this study, we propose the Multi-level Attention Fusion network (MAFnet), an architecture that can dynamically fuse visual and audio information for event recognition. Inspired by prior studies in neuroscience, we couple both modalities at different levels of visual and audio paths. Furthermore, the network dynamically highlights a modality at a given time window relevant to classify events. Experimental results in AVE (Audio-Visual Event), UCF51, and Kinetics-Sounds datasets show that the approach can effectively improve the accuracy in audio-visual event classification. Code is available at: https://github.com/numediart/MAFnet



### Task Transformer Network for Joint MRI Reconstruction and Super-Resolution
- **Arxiv ID**: http://arxiv.org/abs/2106.06742v3
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.06742v3)
- **Published**: 2021-06-12 10:59:46+00:00
- **Updated**: 2021-12-15 18:27:48+00:00
- **Authors**: Chun-Mei Feng, Yunlu Yan, Huazhu Fu, Li Chen, Yong Xu
- **Comment**: None
- **Journal**: International Conference on Medical Image Computing and Computer
  Assisted Intervention (MICCAI2021)
- **Summary**: The core problem of Magnetic Resonance Imaging (MRI) is the trade off between acceleration and image quality. Image reconstruction and super-resolution are two crucial techniques in Magnetic Resonance Imaging (MRI). Current methods are designed to perform these tasks separately, ignoring the correlations between them. In this work, we propose an end-to-end task transformer network (T$^2$Net) for joint MRI reconstruction and super-resolution, which allows representations and feature transmission to be shared between multiple task to achieve higher-quality, super-resolved and motion-artifacts-free images from highly undersampled and degenerated MRI data. Our framework combines both reconstruction and super-resolution, divided into two sub-branches, whose features are expressed as queries and keys. Specifically, we encourage joint feature learning between the two tasks, thereby transferring accurate task information. We first use two separate CNN branches to extract task-specific features. Then, a task transformer module is designed to embed and synthesize the relevance between the two tasks. Experimental results show that our multi-task model significantly outperforms advanced sequential methods, both quantitatively and qualitatively.



### Hippocampus segmentation in magnetic resonance images of Alzheimer's patients using Deep machine learning
- **Arxiv ID**: http://arxiv.org/abs/2106.06743v2
- **DOI**: 10.13140/RG.2.2.17986.91843
- **Categories**: **eess.IV**, cs.CV, cs.LG, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/2106.06743v2)
- **Published**: 2021-06-12 11:00:29+00:00
- **Updated**: 2021-06-16 06:07:08+00:00
- **Authors**: Hossein Yousefi-Banaem, Saber Malekzadeh
- **Comment**: None
- **Journal**: None
- **Summary**: Background: Alzheimers disease is a progressive neurodegenerative disorder and the main cause of dementia in aging. Hippocampus is prone to changes in the early stages of Alzheimers disease. Detection and observation of the hippocampus changes using magnetic resonance imaging (MRI) before the onset of Alzheimers disease leads to the faster preventive and therapeutic measures. Objective: The aim of this study was the segmentation of the hippocampus in magnetic resonance (MR) images of Alzheimers patients using deep machine learning method. Methods: U-Net architecture of convolutional neural network was proposed to segment the hippocampus in the real MRI data. The MR images of the 100 and 35 patients available in Alzheimers disease Neuroimaging Initiative (ADNI) dataset, was used for the train and test of the model, respectively. The performance of the proposed method was compared with manual segmentation by measuring the similarity metrics. Results: The desired segmentation achieved after 10 iterations. A Dice similarity coefficient (DSC) = 92.3%, sensitivity = 96.5%, positive predicted value (PPV) = 90.4%, and Intersection over Union (IoU) value for the train 92.94 and test 92.93 sets were obtained which are acceptable. Conclusion: The proposed approach is promising and can be extended in the prognosis of Alzheimers disease by the prediction of the hippocampus volume changes in the early stage of the disease.



### DeepMMSA: A Novel Multimodal Deep Learning Method for Non-small Cell Lung Cancer Survival Analysis
- **Arxiv ID**: http://arxiv.org/abs/2106.06744v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.06744v1)
- **Published**: 2021-06-12 11:02:14+00:00
- **Updated**: 2021-06-12 11:02:14+00:00
- **Authors**: Yujiao Wu, Jie Ma, Xiaoshui Huang, Sai Ho Ling, Steven Weidong Su
- **Comment**: 7 Submitted to IEEE TBME
- **Journal**: None
- **Summary**: Lung cancer is the leading cause of cancer death worldwide. The critical reason for the deaths is delayed diagnosis and poor prognosis. With the accelerated development of deep learning techniques, it has been successfully applied extensively in many real-world applications, including health sectors such as medical image interpretation and disease diagnosis. By combining more modalities that being engaged in the processing of information, multimodal learning can extract better features and improve predictive ability. The conventional methods for lung cancer survival analysis normally utilize clinical data and only provide a statistical probability. To improve the survival prediction accuracy and help prognostic decision-making in clinical practice for medical experts, we for the first time propose a multimodal deep learning method for non-small cell lung cancer (NSCLC) survival analysis, named DeepMMSA. This method leverages CT images in combination with clinical data, enabling the abundant information hold within medical images to be associate with lung cancer survival information. We validate our method on the data of 422 NSCLC patients from The Cancer Imaging Archive (TCIA). Experimental results support our hypothesis that there is an underlying relationship between prognostic information and radiomic images. Besides, quantitative results showing that the established multimodal model can be applied to traditional method and has the potential to break bottleneck of existing methods and increase the the percentage of concordant pairs(right predicted pairs) in overall population by 4%.



### Cross-Subject Domain Adaptation for Classifying Working Memory Load with Multi-Frame EEG Images
- **Arxiv ID**: http://arxiv.org/abs/2106.06769v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2106.06769v4)
- **Published**: 2021-06-12 13:04:46+00:00
- **Updated**: 2022-09-09 11:25:38+00:00
- **Authors**: Junfu Chen, Dechang Pi, Xiaoyi Jiang, Yang Chen
- **Comment**: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible
- **Journal**: None
- **Summary**: Working memory (WM), denoting the information temporally stored in the mind, is a fundamental research topic in the field of human cognition. Electroencephalograph (EEG), which can monitor the electrical activity of the brain, has been widely used in measuring the level of WM. However, one of the critical challenges is that individual differences may cause ineffective results, especially when the established model meets an unfamiliar subject. In this work, we propose a cross-subject deep adaptation model with spatial attention (CS-DASA) to generalize the workload classifications across subjects. First, we transform EEG time series into multi-frame EEG images incorporating spatial, spectral, and temporal information. First, the Subject-Shared module in CS-DASA receives multi-frame EEG image data from both source and target subjects and learns the common feature representations. Then, in the subject-specific module, the maximum mean discrepancy is implemented to measure the domain distribution divergence in a reproducing kernel Hilbert space, which can add an effective penalty loss for domain adaptation. Additionally, the subject-to-subject spatial attention mechanism is employed to focus on the discriminative spatial features from the target image data. Experiments conducted on a public WM EEG dataset containing 13 subjects show that the proposed model is capable of achieving better performance than existing state-of-the-art methods.



### Dynamic Clone Transformer for Efficient Convolutional Neural Netwoks
- **Arxiv ID**: http://arxiv.org/abs/2106.06778v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2106.06778v1)
- **Published**: 2021-06-12 13:42:28+00:00
- **Updated**: 2021-06-12 13:42:28+00:00
- **Authors**: Longqing Ye
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional networks (ConvNets) have shown impressive capability to solve various vision tasks. Nevertheless, the trade-off between performance and efficiency is still a challenge for a feasible model deployment on resource-constrained platforms. In this paper, we introduce a novel concept termed multi-path fully connected pattern (MPFC) to rethink the interdependencies of topology pattern, accuracy and efficiency for ConvNets. Inspired by MPFC, we further propose a dual-branch module named dynamic clone transformer (DCT) where one branch generates multiple replicas from inputs and another branch reforms those clones through a series of difference vectors conditional on inputs itself to produce more variants. This operation allows the self-expansion of channel-wise information in a data-driven way with little computational cost while providing sufficient learning capacity, which is a potential unit to replace computationally expensive pointwise convolution as an expansion layer in the bottleneck structure.



### A One-Shot Texture-Perceiving Generative Adversarial Network for Unsupervised Surface Inspection
- **Arxiv ID**: http://arxiv.org/abs/2106.06792v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.06792v1)
- **Published**: 2021-06-12 15:05:17+00:00
- **Updated**: 2021-06-12 15:05:17+00:00
- **Authors**: Lingyun Gu, Lin Zhang, Zhaokui Wang
- **Comment**: Accepted by ICIP 2021
- **Journal**: None
- **Summary**: Visual surface inspection is a challenging task owing to the highly diverse appearance of target surfaces and defective regions. Previous attempts heavily rely on vast quantities of training examples with manual annotation. However, in some practical cases, it is difficult to obtain a large number of samples for inspection. To combat it, we propose a hierarchical texture-perceiving generative adversarial network (HTP-GAN) that is learned from the one-shot normal image in an unsupervised scheme. Specifically, the HTP-GAN contains a pyramid of convolutional GANs that can capture the global structure and fine-grained representation of an image simultaneously. This innovation helps distinguishing defective surface regions from normal ones. In addition, in the discriminator, a texture-perceiving module is devised to capture the spatially invariant representation of normal image via directional convolutions, making it more sensitive to defective areas. Experiments on a variety of datasets consistently demonstrate the effectiveness of our method.



### Knowledge Consolidation based Class Incremental Online Learning with Limited Data
- **Arxiv ID**: http://arxiv.org/abs/2106.06795v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.06795v1)
- **Published**: 2021-06-12 15:18:29+00:00
- **Updated**: 2021-06-12 15:18:29+00:00
- **Authors**: Mohammed Asad Karim, Vinay Kumar Verma, Pravendra Singh, Vinay Namboodiri, Piyush Rai
- **Comment**: International Joint Conference on Artificial Intelligence
  (IJCAI-2021)
- **Journal**: None
- **Summary**: We propose a novel approach for class incremental online learning in a limited data setting. This problem setting is challenging because of the following constraints: (1) Classes are given incrementally, which necessitates a class incremental learning approach; (2) Data for each class is given in an online fashion, i.e., each training example is seen only once during training; (3) Each class has very few training examples; and (4) We do not use or assume access to any replay/memory to store data from previous classes. Therefore, in this setting, we have to handle twofold problems of catastrophic forgetting and overfitting. In our approach, we learn robust representations that are generalizable across tasks without suffering from the problems of catastrophic forgetting and overfitting to accommodate future classes with limited samples. Our proposed method leverages the meta-learning framework with knowledge consolidation. The meta-learning framework helps the model for rapid learning when samples appear in an online fashion. Simultaneously, knowledge consolidation helps to learn a robust representation against forgetting under online updates to facilitate future learning. Our approach significantly outperforms other methods on several benchmarks.



### Contrastive Semi-Supervised Learning for 2D Medical Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2106.06801v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.06801v3)
- **Published**: 2021-06-12 15:43:24+00:00
- **Updated**: 2021-08-06 16:33:11+00:00
- **Authors**: Prashant Pandey, Ajey Pai, Nisarg Bhatt, Prasenjit Das, Govind Makharia, Prathosh AP, Mausam
- **Comment**: The paper is withdrawn due to a bug in experimental protocol that
  renders its experimental results and observations invalid. All expts were
  conducted by the student authors. The roles of senior authors (Prasenjit Das,
  Govind Makharia, Prathosh, and Mausam) were in defining the problem
  statement, discussions of potential solutions and framing of the paper and
  not in performing experiments
- **Journal**: None
- **Summary**: Contrastive Learning (CL) is a recent representation learning approach, which encourages inter-class separability and intra-class compactness in learned image representations. Since medical images often contain multiple semantic classes in an image, using CL to learn representations of local features (as opposed to global) is important. In this work, we present a novel semi-supervised 2D medical segmentation solution that applies CL on image patches, instead of full images. These patches are meaningfully constructed using the semantic information of different classes obtained via pseudo labeling. We also propose a novel consistency regularization (CR) scheme, which works in synergy with CL. It addresses the problem of confirmation bias, and encourages better clustering in the feature space. We evaluate our method on four public medical segmentation datasets and a novel histopathology dataset that we introduce. Our method obtains consistent improvements over state-of-the-art semi-supervised segmentation approaches for all datasets.



### Entropy-based Logic Explanations of Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2106.06804v4
- **DOI**: 10.1609/aaai.v36i6.20551
- **Categories**: **cs.AI**, cs.CV, cs.LG, cs.LO
- **Links**: [PDF](http://arxiv.org/pdf/2106.06804v4)
- **Published**: 2021-06-12 15:50:47+00:00
- **Updated**: 2022-01-31 16:56:43+00:00
- **Authors**: Pietro Barbiero, Gabriele Ciravegna, Francesco Giannini, Pietro Lió, Marco Gori, Stefano Melacci
- **Comment**: None
- **Journal**: In Proceedings of the AAAI Conference on Artificial Intelligence,
  Vol. 36, No. 6, pp. 6046-6054, 2022
- **Summary**: Explainable artificial intelligence has rapidly emerged since lawmakers have started requiring interpretable models for safety-critical domains. Concept-based neural networks have arisen as explainable-by-design methods as they leverage human-understandable symbols (i.e. concepts) to predict class memberships. However, most of these approaches focus on the identification of the most relevant concepts but do not provide concise, formal explanations of how such concepts are leveraged by the classifier to make predictions. In this paper, we propose a novel end-to-end differentiable approach enabling the extraction of logic explanations from neural networks using the formalism of First-Order Logic. The method relies on an entropy-based criterion which automatically identifies the most relevant concepts. We consider four different case studies to demonstrate that: (i) this entropy-based criterion enables the distillation of concise logic explanations in safety-critical domains from clinical data to computer vision; (ii) the proposed approach outperforms state-of-the-art white-box models in terms of classification accuracy and matches black box performances.



### Evaluating Foveated Video Quality Using Entropic Differencing
- **Arxiv ID**: http://arxiv.org/abs/2106.06817v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.06817v1)
- **Published**: 2021-06-12 16:29:13+00:00
- **Updated**: 2021-06-12 16:29:13+00:00
- **Authors**: Yize Jin, Anjul Patney, Alan Bovik
- **Comment**: None
- **Journal**: None
- **Summary**: Virtual Reality is regaining attention due to recent advancements in hardware technology. Immersive images / videos are becoming widely adopted to carry omnidirectional visual information. However, due to the requirements for higher spatial and temporal resolution of real video data, immersive videos require significantly larger bandwidth consumption. To reduce stresses on bandwidth, foveated video compression is regaining popularity, whereby the space-variant spatial resolution of the retina is exploited. Towards advancing the progress of foveated video compression, we propose a full reference (FR) foveated image quality assessment algorithm, which we call foveated entropic differencing (FED), which employs the natural scene statistics of bandpass responses by applying differences of local entropies weighted by a foveation-based error sensitivity function. We evaluate the proposed algorithm by measuring the correlations of the predictions that FED makes against human judgements on the newly created 2D and 3D LIVE-FBT-FCVR databases for Virtual Reality (VR). The performance of the proposed algorithm yields state-of-the-art as compared with other existing full reference algorithms. Software for FED has been made available at: http://live.ece.utexas.edu/research/Quality/FED.zip



### D2C: Diffusion-Denoising Models for Few-shot Conditional Generation
- **Arxiv ID**: http://arxiv.org/abs/2106.06819v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.06819v1)
- **Published**: 2021-06-12 16:32:30+00:00
- **Updated**: 2021-06-12 16:32:30+00:00
- **Authors**: Abhishek Sinha, Jiaming Song, Chenlin Meng, Stefano Ermon
- **Comment**: None
- **Journal**: None
- **Summary**: Conditional generative models of high-dimensional images have many applications, but supervision signals from conditions to images can be expensive to acquire. This paper describes Diffusion-Decoding models with Contrastive representations (D2C), a paradigm for training unconditional variational autoencoders (VAEs) for few-shot conditional image generation. D2C uses a learned diffusion-based prior over the latent representations to improve generation and contrastive self-supervised learning to improve representation quality. D2C can adapt to novel generation tasks conditioned on labels or manipulation constraints, by learning from as few as 100 labeled examples. On conditional generation from new labels, D2C achieves superior performance over state-of-the-art VAEs and diffusion models. On conditional image manipulation, D2C generations are two orders of magnitude faster to produce over StyleGAN2 ones and are preferred by 50% - 60% of the human evaluators in a double-blind study.



### Video Super-Resolution Transformer
- **Arxiv ID**: http://arxiv.org/abs/2106.06847v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.06847v3)
- **Published**: 2021-06-12 20:00:32+00:00
- **Updated**: 2023-07-04 15:30:58+00:00
- **Authors**: Jiezhang Cao, Yawei Li, Kai Zhang, Luc Van Gool
- **Comment**: None
- **Journal**: None
- **Summary**: Video super-resolution (VSR), with the aim to restore a high-resolution video from its corresponding low-resolution version, is a spatial-temporal sequence prediction problem. Recently, Transformer has been gaining popularity due to its parallel computing ability for sequence-to-sequence modeling. Thus, it seems to be straightforward to apply the vision Transformer to solve VSR. However, the typical block design of Transformer with a fully connected self-attention layer and a token-wise feed-forward layer does not fit well for VSR due to the following two reasons. First, the fully connected self-attention layer neglects to exploit the data locality because this layer relies on linear layers to compute attention maps. Second, the token-wise feed-forward layer lacks the feature alignment which is important for VSR since this layer independently processes each of the input token embeddings without any interaction among them. In this paper, we make the first attempt to adapt Transformer for VSR. Specifically, to tackle the first issue, we present a spatial-temporal convolutional self-attention layer with a theoretical understanding to exploit the locality information. For the second issue, we design a bidirectional optical flow-based feed-forward layer to discover the correlations across different video frames and also align features. Extensive experiments on several benchmark datasets demonstrate the effectiveness of our proposed method. The code will be available at https://github.com/caojiezhang/VSR-Transformer.



### DyGLIP: A Dynamic Graph Model with Link Prediction for Accurate Multi-Camera Multiple Object Tracking
- **Arxiv ID**: http://arxiv.org/abs/2106.06856v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.06856v1)
- **Published**: 2021-06-12 20:22:30+00:00
- **Updated**: 2021-06-12 20:22:30+00:00
- **Authors**: Kha Gia Quach, Pha Nguyen, Huu Le, Thanh-Dat Truong, Chi Nhan Duong, Minh-Triet Tran, Khoa Luu
- **Comment**: accepted at CVPR 2021
- **Journal**: None
- **Summary**: Multi-Camera Multiple Object Tracking (MC-MOT) is a significant computer vision problem due to its emerging applicability in several real-world applications. Despite a large number of existing works, solving the data association problem in any MC-MOT pipeline is arguably one of the most challenging tasks. Developing a robust MC-MOT system, however, is still highly challenging due to many practical issues such as inconsistent lighting conditions, varying object movement patterns, or the trajectory occlusions of the objects between the cameras. To address these problems, this work, therefore, proposes a new Dynamic Graph Model with Link Prediction (DyGLIP) approach to solve the data association task. Compared to existing methods, our new model offers several advantages, including better feature representations and the ability to recover from lost tracks during camera transitions. Moreover, our model works gracefully regardless of the overlapping ratios between the cameras. Experimental results show that we outperform existing MC-MOT algorithms by a large margin on several practical datasets. Notably, our model works favorably on online settings but can be extended to an incremental approach for large-scale datasets.



### A Multi-Implicit Neural Representation for Fonts
- **Arxiv ID**: http://arxiv.org/abs/2106.06866v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/2106.06866v2)
- **Published**: 2021-06-12 21:40:11+00:00
- **Updated**: 2022-01-09 16:44:14+00:00
- **Authors**: Pradyumna Reddy, Zhifei Zhang, Matthew Fisher, Hailin Jin, Zhaowen Wang, Niloy J. Mitra
- **Comment**: None
- **Journal**: None
- **Summary**: Fonts are ubiquitous across documents and come in a variety of styles. They are either represented in a native vector format or rasterized to produce fixed resolution images. In the first case, the non-standard representation prevents benefiting from latest network architectures for neural representations; while, in the latter case, the rasterized representation, when encoded via networks, results in loss of data fidelity, as font-specific discontinuities like edges and corners are difficult to represent using neural networks. Based on the observation that complex fonts can be represented by a superposition of a set of simpler occupancy functions, we introduce \textit{multi-implicits} to represent fonts as a permutation-invariant set of learned implict functions, without losing features (e.g., edges and corners). However, while multi-implicits locally preserve font features, obtaining supervision in the form of ground truth multi-channel signals is a problem in itself. Instead, we propose how to train such a representation with only local supervision, while the proposed neural architecture directly finds globally consistent multi-implicits for font families. We extensively evaluate the proposed representation for various tasks including reconstruction, interpolation, and synthesis to demonstrate clear advantages with existing alternatives. Additionally, the representation naturally enables glyph completion, wherein a single characteristic font is used to synthesize a whole font family in the target style.



### Sparse PointPillars: Maintaining and Exploiting Input Sparsity to Improve Runtime on Embedded Systems
- **Arxiv ID**: http://arxiv.org/abs/2106.06882v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2106.06882v3)
- **Published**: 2021-06-12 23:15:32+00:00
- **Updated**: 2022-03-01 22:15:23+00:00
- **Authors**: Kyle Vedder, Eric Eaton
- **Comment**: 7 pages, 5 figures. Submitted to IROS 2022. All models, weights,
  experimental configurations, and datasets used are publicly available at
  http://vedder.io/sparse_point_pillars
- **Journal**: International Conference on Intelligent Robots and Systems (IROS)
  2022
- **Summary**: Bird's Eye View (BEV) is a popular representation for processing 3D point clouds, and by its nature is fundamentally sparse. Motivated by the computational limitations of mobile robot platforms, we create a fast, high-performance BEV 3D object detector that maintains and exploits this input sparsity to decrease runtimes over non-sparse baselines and avoids the tradeoff between pseudoimage area and runtime. We present results on KITTI, a canonical 3D detection dataset, and Matterport-Chair, a novel Matterport3D-derived chair detection dataset from scenes in real furnished homes. We evaluate runtime characteristics using a desktop GPU, an embedded ML accelerator, and a robot CPU, demonstrating that our method results in significant detection speedups (2X or more) for embedded systems with only a modest decrease in detection quality. Our work represents a new approach for practitioners to optimize models for embedded systems by maintaining and exploiting input sparsity throughout their entire pipeline to reduce runtime and resource usage while preserving detection performance.



