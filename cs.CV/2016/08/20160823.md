# Arxiv Papers in cs.CV on 2016-08-23
### Deep Double Sparsity Encoder: Learning to Sparsify Not Only Features But Also Parameters
- **Arxiv ID**: http://arxiv.org/abs/1608.06374v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1608.06374v2)
- **Published**: 2016-08-23 03:50:01+00:00
- **Updated**: 2016-10-02 03:01:51+00:00
- **Authors**: Zhangyang Wang, Thomas S. Huang
- **Comment**: None
- **Journal**: None
- **Summary**: This paper emphasizes the significance to jointly exploit the problem structure and the parameter structure, in the context of deep modeling. As a specific and interesting example, we describe the deep double sparsity encoder (DDSE), which is inspired by the double sparsity model for dictionary learning. DDSE simultaneously sparsities the output features and the learned model parameters, under one unified framework. In addition to its intuitive model interpretation, DDSE also possesses compact model size and low complexity. Extensive simulations compare DDSE with several carefully-designed baselines, and verify the consistently superior performance of DDSE. We further apply DDSE to the novel application domain of brain encoding, with promising preliminary results achieved.



### Artificial Neural Networks for Detection of Malaria in RBCs
- **Arxiv ID**: http://arxiv.org/abs/1608.06627v1
- **DOI**: None
- **Categories**: **physics.med-ph**, cs.CV, cs.NE, 62M45
- **Links**: [PDF](http://arxiv.org/pdf/1608.06627v1)
- **Published**: 2016-08-23 06:01:19+00:00
- **Updated**: 2016-08-23 06:01:19+00:00
- **Authors**: Purnima Pandit, A. Anand
- **Comment**: None
- **Journal**: None
- **Summary**: Malaria is one of the most common diseases caused by mosquitoes and is a great public health problem worldwide. Currently, for malaria diagnosis the standard technique is microscopic examination of a stained blood film. We propose use of Artificial Neural Networks (ANN) for the diagnosis of the disease in the red blood cell. For this purpose features / parameters are computed from the data obtained by the digital holographic images of the blood cells and is given as input to ANN which classifies the cell as the infected one or otherwise.



### Convolutional Network for Attribute-driven and Identity-preserving Human Face Generation
- **Arxiv ID**: http://arxiv.org/abs/1608.06434v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.06434v1)
- **Published**: 2016-08-23 09:32:47+00:00
- **Updated**: 2016-08-23 09:32:47+00:00
- **Authors**: Mu Li, Wangmeng Zuo, David Zhang
- **Comment**: 9 pages, 7 figures
- **Journal**: None
- **Summary**: This paper focuses on the problem of generating human face pictures from specific attributes. The existing CNN-based face generation models, however, either ignore the identity of the generated face or fail to preserve the identity of the reference face image. Here we address this problem from the view of optimization, and suggest an optimization model to generate human face with the given attributes while keeping the identity of the reference image. The attributes can be obtained from the attribute-guided image or by tuning the attribute features of the reference image. With the deep convolutional network "VGG-Face", the loss is defined on the convolutional feature maps. We then apply the gradient decent algorithm to solve this optimization problem. The results validate the effectiveness of our method for attribute driven and identity-preserving face generation.



### A Delay-Tolerant Potential-Field-Based Network Implementation of an Integrated Navigation System
- **Arxiv ID**: http://arxiv.org/abs/1608.06440v1
- **DOI**: 10.1109/TIE.2009.2026764
- **Categories**: **cs.RO**, cs.CV, cs.SY
- **Links**: [PDF](http://arxiv.org/pdf/1608.06440v1)
- **Published**: 2016-08-23 09:49:10+00:00
- **Updated**: 2016-08-23 09:49:10+00:00
- **Authors**: Rachana Ashok Gupta, Ahmad A. Masoud, Mo-Yuen Chow
- **Comment**: None
- **Journal**: The IEEE Transactions On Industrial Electronics, Vol. 57, No.2,
  February 2010, PP. 769-783
- **Summary**: Network controllers (NCs) are devices that are capable of converting dynamic, spatially extended, and functionally specialized modules into a taskable goal-oriented group called networked control system. This paper examines the practical aspects of designing and building an NC that uses the Internet as a communication medium. It focuses on finding compatible controller components that can be integrated via a host structure in a manner that makes it possible to network, in real-time, a webcam, an unmanned ground vehicle (UGV), and a remote computer server along with the necessary operator software interface. The aim is to deskill the UGV navigation process and yet maintain a robust performance. The structure of the suggested controller, its components, and the manner in which they are interfaced are described. Thorough experimental results along with performance assessment and comparisons to a previously implemented NC are provided.



### Failure Detection for Facial Landmark Detectors
- **Arxiv ID**: http://arxiv.org/abs/1608.06451v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.06451v1)
- **Published**: 2016-08-23 10:28:41+00:00
- **Updated**: 2016-08-23 10:28:41+00:00
- **Authors**: Andreas Steger, Radu Timofte, Luc Van Gool
- **Comment**: None
- **Journal**: None
- **Summary**: Most face applications depend heavily on the accuracy of the face and facial landmarks detectors employed. Prediction of attributes such as gender, age, and identity usually completely fail when the faces are badly aligned due to inaccurate facial landmark detection. Despite the impressive recent advances in face and facial landmark detection, little study is on the recovery from and detection of failures or inaccurate predictions. In this work we study two top recent facial landmark detectors and devise confidence models for their outputs. We validate our failure detection approaches on standard benchmarks (AFLW, HELEN) and correctly identify more than 40% of the failures in the outputs of the landmark detectors. Moreover, with our failure detection we can achieve a 12% error reduction on a gender estimation application at the cost of a small increase in computation.



### Searching Action Proposals via Spatial Actionness Estimation and Temporal Path Inference and Tracking
- **Arxiv ID**: http://arxiv.org/abs/1608.06495v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.06495v1)
- **Published**: 2016-08-23 13:08:30+00:00
- **Updated**: 2016-08-23 13:08:30+00:00
- **Authors**: Nannan Li, Dan Xu, Zhenqiang Ying, Zhihao Li, Ge Li
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we address the problem of searching action proposals in unconstrained video clips. Our approach starts from actionness estimation on frame-level bounding boxes, and then aggregates the bounding boxes belonging to the same actor across frames via linking, associating, tracking to generate spatial-temporal continuous action paths. To achieve the target, a novel actionness estimation method is firstly proposed by utilizing both human appearance and motion cues. Then, the association of the action paths is formulated as a maximum set coverage problem with the results of actionness estimation as a priori. To further promote the performance, we design an improved optimization objective for the problem and provide a greedy search algorithm to solve it. Finally, a tracking-by-detection scheme is designed to further refine the searched action paths. Extensive experiments on two challenging datasets, UCF-Sports and UCF-101, show that the proposed approach advances state-of-the-art proposal generation performance in terms of both accuracy and proposal quantity.



### Does V-NIR based Image Enhancement Come with Better Features?
- **Arxiv ID**: http://arxiv.org/abs/1608.06521v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.06521v2)
- **Published**: 2016-08-23 14:27:14+00:00
- **Updated**: 2016-08-24 09:20:59+00:00
- **Authors**: Vivek Sharma, Luc Van Gool
- **Comment**: None
- **Journal**: None
- **Summary**: Image enhancement using the visible (V) and near-infrared (NIR) usually enhances useful image details. The enhanced images are evaluated by observers perception, instead of quantitative feature evaluation. Thus, can we say that these enhanced images using NIR information has better features in comparison to the computed features in the Red, Green, and Blue color channels directly? In this work, we present a new method to enhance the visible images using NIR information via edge-preserving filters, and also investigate which method performs best from a image features standpoint. We then show that our proposed enhancement method produces more stable features than the existing state-of-the-art methods.



### Neural Networks with Smooth Adaptive Activation Functions for Regression
- **Arxiv ID**: http://arxiv.org/abs/1608.06557v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.06557v1)
- **Published**: 2016-08-23 15:56:08+00:00
- **Updated**: 2016-08-23 15:56:08+00:00
- **Authors**: Le Hou, Dimitris Samaras, Tahsin M. Kurc, Yi Gao, Joel H. Saltz
- **Comment**: None
- **Journal**: None
- **Summary**: In Neural Networks (NN), Adaptive Activation Functions (AAF) have parameters that control the shapes of activation functions. These parameters are trained along with other parameters in the NN. AAFs have improved performance of Neural Networks (NN) in multiple classification tasks. In this paper, we propose and apply AAFs on feedforward NNs for regression tasks. We argue that applying AAFs in the regression (second-to-last) layer of a NN can significantly decrease the bias of the regression NN. However, using existing AAFs may lead to overfitting. To address this problem, we propose a Smooth Adaptive Activation Function (SAAF) with piecewise polynomial form which can approximate any continuous function to arbitrary degree of error. NNs with SAAFs can avoid overfitting by simply regularizing the parameters. In particular, an NN with SAAFs is Lipschitz continuous given a bounded magnitude of the NN parameters. We prove an upper-bound for model complexity in terms of fat-shattering dimension for any Lipschitz continuous regression model. Thus, regularizing the parameters in NNs with SAAFs avoids overfitting. We empirically evaluated NNs with SAAFs and achieved state-of-the-art results on multiple regression datasets.



### A Non-Local Conventional Approach for Noise Removal in 3D MRI
- **Arxiv ID**: http://arxiv.org/abs/1608.06558v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.06558v1)
- **Published**: 2016-08-23 15:58:29+00:00
- **Updated**: 2016-08-23 15:58:29+00:00
- **Authors**: Sona Morajab, Mehregan Mahdavi
- **Comment**: 1st International Conference on New Perspective in Electrical &
  Computer Engineering
- **Journal**: None
- **Summary**: In this paper, a filtering approach for the 3D magnetic resonance imaging (MRI) assuming a Rician model for noise is addressed. Our denoising method is based on the Conventional Approach (CA) proposed to deal with the noise issue in the squared domain of the acquired magnitude MRI, where the noise distribution follows a Chi-square model rather than the Rician one. In the CA filtering method, the local samples around each voxel is used to estimate the unknown signal value. Intrinsically, such a method fails to achieve the best results where the underlying signal values have different statistical properties. On the contrary, our proposal takes advantage of the data redundancy and self-similarity properties of real MR images to improve the noise removal performance. In other words, in our approach, the statistical momentums of the given 3D MR volume are first calculated to explore the similar patches inside a defined search volume. Then, these patches are put together to obtain the noise-free value for each voxel under processing. The experimental results on the synthetic as well as the clinical MR data show our proposed method outperforms the other compared denoising filters.



### Computerized Tomography with Total Variation and with Shearlets
- **Arxiv ID**: http://arxiv.org/abs/1608.06668v1
- **DOI**: 10.1088/1361-6420/33/4/044011
- **Categories**: **physics.med-ph**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1608.06668v1)
- **Published**: 2016-08-23 23:38:43+00:00
- **Updated**: 2016-08-23 23:38:43+00:00
- **Authors**: Edgar Gardu√±o, Gabor T. Herman
- **Comment**: 25 pages, 7 figures, Special Issue on Superiorization, Inverse
  Problems 2016
- **Journal**: None
- **Summary**: To reduce the x-ray dose in computerized tomography (CT), many constrained optimization approaches have been proposed aiming at minimizing a regularizing function that measures lack of consistency with some prior knowledge about the object that is being imaged, subject to a (predetermined) level of consistency with the detected attenuation of x-rays. Proponents of the shearlet transform in the regularizing function claim that the reconstructions so obtained are better than those produced using TV for texture preservation (but may be worse for noise reduction). In this paper we report results related to this claim. In our reported experiments using simulated CT data collection of the head, reconstructions whose shearlet transform has a small $\ell_1$-norm are not more efficacious than reconstructions that have a small TV value. Our experiments for making such comparisons use the recently-developed superiorization methodology for both regularizing functions. Superiorization is an automated procedure for turning an iterative algorithm for producing images that satisfy a primary criterion (such as consistency with the observed measurements) into its superiorized version that will produce results that, according to the primary criterion are as good as those produced by the original algorithm, but in addition are superior to them according to a secondary (regularizing) criterion. The method presented for superiorization involving the $\ell_1$-norm of the shearlet transform is novel and is quite general: It can be used for any regularizing function that is defined as the $\ell_1$-norm of a transform specified by the application of a matrix. Because in the previous literature the split Bregman algorithm is used for similar purposes, a section is included comparing the results of the superiorization algorithm with the split Bregman algorithm.



### On Clustering and Embedding Mixture Manifolds using a Low Rank Neighborhood Approach
- **Arxiv ID**: http://arxiv.org/abs/1608.06669v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.06669v3)
- **Published**: 2016-08-23 23:40:14+00:00
- **Updated**: 2017-08-12 19:28:38+00:00
- **Authors**: Arun M. Saranathan, Mario Parente
- **Comment**: 11 Pages
- **Journal**: None
- **Summary**: Samples from intimate (non-linear) mixtures are generally modeled as being drawn from a smooth manifold. Scenarios where the data contains multiple intimate mixtures with some constituent materials in common can be thought of as manifolds which share a boundary. Two important steps in the processing of such data are (i) to identify (cluster) the different mixture-manifolds present in the data and (ii) to eliminate the non-linearities present the data by mapping each mixture-manifold into some low-dimensional euclidean space (embedding). Manifold clustering and embedding techniques appear to be an ideal tool for this task, but the present state-of-the-art algorithms perform poorly for hyperspectral data, particularly in the embedding task. We propose a novel reconstruction-based algorithm for improved clustering and embedding of mixture-manifolds. The algorithms attempts to reconstruct each target-point as an affine combination of its nearest neighbors with an additional rank penalty on the neighborhood to ensure that only neighbors on the same manifold as the target-point are used in the reconstruction. The reconstruction matrix generated by using this technique is block-diagonal and can be used for clustering (using spectral clustering) and embedding. The improved performance of the algorithms vis-a-vis its competitors is exhibited on a variety of simulated and real mixture datasets.



