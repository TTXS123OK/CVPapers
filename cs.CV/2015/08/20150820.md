# Arxiv Papers in cs.CV on 2015-08-20
### Recursive Training of 2D-3D Convolutional Networks for Neuronal Boundary Detection
- **Arxiv ID**: http://arxiv.org/abs/1508.04843v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.04843v1)
- **Published**: 2015-08-20 00:46:38+00:00
- **Updated**: 2015-08-20 00:46:38+00:00
- **Authors**: Kisuk Lee, Aleksandar Zlateski, Ashwin Vishwanathan, H. Sebastian Seung
- **Comment**: None
- **Journal**: None
- **Summary**: Efforts to automate the reconstruction of neural circuits from 3D electron microscopic (EM) brain images are critical for the field of connectomics. An important computation for reconstruction is the detection of neuronal boundaries. Images acquired by serial section EM, a leading 3D EM technique, are highly anisotropic, with inferior quality along the third dimension. For such images, the 2D max-pooling convolutional network has set the standard for performance at boundary detection. Here we achieve a substantial gain in accuracy through three innovations. Following the trend towards deeper networks for object recognition, we use a much deeper network than previously employed for boundary detection. Second, we incorporate 3D as well as 2D filters, to enable computations that use 3D context. Finally, we adopt a recursively trained architecture in which a first network generates a preliminary boundary map that is provided as input along with the original image to a second network that generates a final boundary map. Backpropagation training is accelerated by ZNN, a new implementation of 3D convolutional networks that uses multicore CPU parallelism for speed. Our hybrid 2D-3D architecture could be more generally applicable to other types of anisotropic 3D images, including video, and our recursive framework for any image labeling problem.



### Multi-criteria Similarity-based Anomaly Detection using Pareto Depth Analysis
- **Arxiv ID**: http://arxiv.org/abs/1508.04887v1
- **DOI**: 10.1109/TNNLS.2015.2466686
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1508.04887v1)
- **Published**: 2015-08-20 06:25:52+00:00
- **Updated**: 2015-08-20 06:25:52+00:00
- **Authors**: Ko-Jen Hsiao, Kevin S. Xu, Jeff Calder, Alfred O. Hero III
- **Comment**: The work is submitted to IEEE TNNLS Special Issue on Learning in
  Non-(geo)metric Spaces for review on October 28, 2013, revised on July 26,
  2015 and accepted on July 30, 2015. A preliminary version of this work is
  reported in the conference Advances in Neural Information Processing Systems
  (NIPS) 2012
- **Journal**: IEEE Transactions on Neural Networks and Learning Systems 27
  (2016) 1307-1321
- **Summary**: We consider the problem of identifying patterns in a data set that exhibit anomalous behavior, often referred to as anomaly detection. Similarity-based anomaly detection algorithms detect abnormally large amounts of similarity or dissimilarity, e.g.~as measured by nearest neighbor Euclidean distances between a test sample and the training samples. In many application domains there may not exist a single dissimilarity measure that captures all possible anomalous patterns. In such cases, multiple dissimilarity measures can be defined, including non-metric measures, and one can test for anomalies by scalarizing using a non-negative linear combination of them. If the relative importance of the different dissimilarity measures are not known in advance, as in many anomaly detection applications, the anomaly detection algorithm may need to be executed multiple times with different choices of weights in the linear combination. In this paper, we propose a method for similarity-based anomaly detection using a novel multi-criteria dissimilarity measure, the Pareto depth. The proposed Pareto depth analysis (PDA) anomaly detection algorithm uses the concept of Pareto optimality to detect anomalies under multiple criteria without having to run an algorithm multiple times with different choices of weights. The proposed PDA approach is provably better than using linear combinations of the criteria and shows superior performance on experiments with synthetic and real data sets.



### Distributed Compressive Sensing: A Deep Learning Approach
- **Arxiv ID**: http://arxiv.org/abs/1508.04924v3
- **DOI**: 10.1109/TSP.2016.2557301
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1508.04924v3)
- **Published**: 2015-08-20 08:57:29+00:00
- **Updated**: 2016-05-11 22:18:13+00:00
- **Authors**: Hamid Palangi, Rabab Ward, Li Deng
- **Comment**: To appear in IEEE Transactions on Signal Processing
- **Journal**: IEEE Transactions on Signal Processing, Volume: 64, Issue: 17, pp.
  4504-4518, 2016
- **Summary**: Various studies that address the compressed sensing problem with Multiple Measurement Vectors (MMVs) have been recently carried. These studies assume the vectors of the different channels to be jointly sparse. In this paper, we relax this condition. Instead we assume that these sparse vectors depend on each other but that this dependency is unknown. We capture this dependency by computing the conditional probability of each entry in each vector being non-zero, given the "residuals" of all previous vectors. To estimate these probabilities, we propose the use of the Long Short-Term Memory (LSTM)[1], a data driven model for sequence modelling that is deep in time. To calculate the model parameters, we minimize a cross entropy cost function. To reconstruct the sparse vectors at the decoder, we propose a greedy solver that uses the above model to estimate the conditional probabilities. By performing extensive experiments on two real world datasets, we show that the proposed method significantly outperforms the general MMV solver (the Simultaneous Orthogonal Matching Pursuit (SOMP)) and a number of the model-based Bayesian methods. The proposed method does not add any complexity to the general compressive sensing encoder. The trained model is used just at the decoder. As the proposed method is a data driven method, it is only applicable when training data is available. In many applications however, training data is indeed available, e.g. in recorded images and videos.



### DeepWriterID: An End-to-end Online Text-independent Writer Identification System
- **Arxiv ID**: http://arxiv.org/abs/1508.04945v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1508.04945v2)
- **Published**: 2015-08-20 10:39:19+00:00
- **Updated**: 2015-12-22 14:05:48+00:00
- **Authors**: Weixin Yang, Lianwen Jin, Manfei Liu
- **Comment**: 7 pages5 6 figures
- **Journal**: None
- **Summary**: Owing to the rapid growth of touchscreen mobile terminals and pen-based interfaces, handwriting-based writer identification systems are attracting increasing attention for personal authentication, digital forensics, and other applications. However, most studies on writer identification have not been satisfying because of the insufficiency of data and difficulty of designing good features under various conditions of handwritings. Hence, we introduce an end-to-end system, namely DeepWriterID, employed a deep convolutional neural network (CNN) to address these problems. A key feature of DeepWriterID is a new method we are proposing, called DropSegment. It designs to achieve data augmentation and improve the generalized applicability of CNN. For sufficient feature representation, we further introduce path signature feature maps to improve performance. Experiments were conducted on the NLPR handwriting database. Even though we only use pen-position information in the pen-down state of the given handwriting samples, we achieved new state-of-the-art identification rates of 95.72% for Chinese text and 98.51% for English text.



### Introducing Geometry in Active Learning for Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1508.04955v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.04955v1)
- **Published**: 2015-08-20 11:03:44+00:00
- **Updated**: 2015-08-20 11:03:44+00:00
- **Authors**: Ksenia Konyushkova, Raphael Sznitman, Pascal Fua
- **Comment**: None
- **Journal**: None
- **Summary**: We propose an Active Learning approach to training a segmentation classifier that exploits geometric priors to streamline the annotation process in 3D image volumes. To this end, we use these priors not only to select voxels most in need of annotation but to guarantee that they lie on 2D planar patch, which makes it much easier to annotate than if they were randomly distributed in the volume. A simplified version of this approach is effective in natural 2D images. We evaluated our approach on Electron Microscopy and Magnetic Resonance image volumes, as well as on natural images. Comparing our approach against several accepted baselines demonstrates a marked performance increase.



### High-Contrast Color-Stripe Pattern for Rapid Structured-Light Range Imaging
- **Arxiv ID**: http://arxiv.org/abs/1508.04981v1
- **DOI**: 10.1007/978-3-540-24670-1_8
- **Categories**: **cs.CV**, cs.GR, physics.optics, I.2.10; I.4.8
- **Links**: [PDF](http://arxiv.org/pdf/1508.04981v1)
- **Published**: 2015-08-20 13:43:46+00:00
- **Updated**: 2015-08-20 13:43:46+00:00
- **Authors**: Changsoo Je, Sang Wook Lee, Rae-Hong Park
- **Comment**: 13 pages, 12 figures, 8th European Conference on Computer Vision
  (ECCV), Prague, Czech Republic, May 2004, Proceedings, Part I
- **Journal**: Computer Vision - ECCV 2004, LNCS 3021, pp. 95-107,
  Springer-Verlag Berlin Heidelberg, May 10, 2004
- **Summary**: For structured-light range imaging, color stripes can be used for increasing the number of distinguishable light patterns compared to binary BW stripes. Therefore, an appropriate use of color patterns can reduce the number of light projections and range imaging is achievable in single video frame or in "one shot". On the other hand, the reliability and range resolution attainable from color stripes is generally lower than those from multiply projected binary BW patterns since color contrast is affected by object color reflectance and ambient light. This paper presents new methods for selecting stripe colors and designing multiple-stripe patterns for "one-shot" and "two-shot" imaging. We show that maximizing color contrast between the stripes in one-shot imaging reduces the ambiguities resulting from colored object surfaces and limitations in sensor/projector resolution. Two-shot imaging adds an extra video frame and maximizes the color contrast between the first and second video frames to diminish the ambiguities even further. Experimental results demonstrate the effectiveness of the presented one-shot and two-shot color-stripe imaging schemes.



### Using User Generated Online Photos to Estimate and Monitor Air Pollution in Major Cities
- **Arxiv ID**: http://arxiv.org/abs/1508.05028v1
- **DOI**: 10.1145/2808492.2808564
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.05028v1)
- **Published**: 2015-08-20 16:20:35+00:00
- **Updated**: 2015-08-20 16:20:35+00:00
- **Authors**: Yuncheng Li, Jifei Huang, Jiebo Luo
- **Comment**: ICIMCS '15
- **Journal**: None
- **Summary**: With the rapid development of economy in China over the past decade, air pollution has become an increasingly serious problem in major cities and caused grave public health concerns in China. Recently, a number of studies have dealt with air quality and air pollution. Among them, some attempt to predict and monitor the air quality from different sources of information, ranging from deployed physical sensors to social media. These methods are either too expensive or unreliable, prompting us to search for a novel and effective way to sense the air quality. In this study, we propose to employ the state of the art in computer vision techniques to analyze photos that can be easily acquired from online social media. Next, we establish the correlation between the haze level computed directly from photos with the official PM 2.5 record of the taken city at the taken time. Our experiments based on both synthetic and real photos have shown the promise of this image-based approach to estimating and monitoring air pollution.



### Seeing Behind the Camera: Identifying the Authorship of a Photograph
- **Arxiv ID**: http://arxiv.org/abs/1508.05038v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.05038v3)
- **Published**: 2015-08-20 16:45:17+00:00
- **Updated**: 2016-06-01 01:09:08+00:00
- **Authors**: Christopher Thomas, Adriana Kovashka
- **Comment**: Dataset downloadable at http://www.cs.pitt.edu/~chris/photographer To
  Appear in CVPR 2016
- **Journal**: None
- **Summary**: We introduce the novel problem of identifying the photographer behind a photograph. To explore the feasibility of current computer vision techniques to address this problem, we created a new dataset of over 180,000 images taken by 41 well-known photographers. Using this dataset, we examined the effectiveness of a variety of features (low and high-level, including CNN features) at identifying the photographer. We also trained a new deep convolutional neural network for this task. Our results show that high-level features greatly outperform low-level features. We provide qualitative results using these learned models that give insight into our method's ability to distinguish between photographers, and allow us to draw interesting conclusions about what specific photographers shoot. We also demonstrate two applications of our method.



### Improving Image Restoration with Soft-Rounding
- **Arxiv ID**: http://arxiv.org/abs/1508.05046v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.05046v1)
- **Published**: 2015-08-20 17:04:34+00:00
- **Updated**: 2015-08-20 17:04:34+00:00
- **Authors**: Xing Mei, Honggang Qi, Bao-Gang Hu, Siwei Lyu
- **Comment**: 9 pages, 6 figures
- **Journal**: None
- **Summary**: Several important classes of images such as text, barcode and pattern images have the property that pixels can only take a distinct subset of values. This knowledge can benefit the restoration of such images, but it has not been widely considered in current restoration methods. In this work, we describe an effective and efficient approach to incorporate the knowledge of distinct pixel values of the pristine images into the general regularized least squares restoration framework. We introduce a new regularizer that attains zero at the designated pixel values and becomes a quadratic penalty function in the intervals between them. When incorporated into the regularized least squares restoration framework, this regularizer leads to a simple and efficient step that resembles and extends the rounding operation, which we term as soft-rounding. We apply the soft-rounding enhanced solution to the restoration of binary text/barcode images and pattern images with multiple distinct pixel values. Experimental results show that soft-rounding enhanced restoration methods achieve significant improvement in both visual quality and quantitative measures (PSNR and SSIM). Furthermore, we show that this regularizer can also benefit the restoration of general natural images.



### Diving Deep into Sentiment: Understanding Fine-tuned CNNs for Visual Sentiment Prediction
- **Arxiv ID**: http://arxiv.org/abs/1508.05056v2
- **DOI**: 10.1145/2813524.2813530
- **Categories**: **cs.MM**, cs.CV, I.2.10; H.1.2
- **Links**: [PDF](http://arxiv.org/pdf/1508.05056v2)
- **Published**: 2015-08-20 17:36:48+00:00
- **Updated**: 2015-08-24 09:43:18+00:00
- **Authors**: Victor Campos, Amaia Salvador, Brendan Jou, Xavier Gir√≥-i-Nieto
- **Comment**: Preprint of the paper accepted at the 1st Workshop on Affect and
  Sentiment in Multimedia (ASM), in ACM MultiMedia 2015. Brisbane, Australia
- **Journal**: None
- **Summary**: Visual media are powerful means of expressing emotions and sentiments. The constant generation of new content in social networks highlights the need of automated visual sentiment analysis tools. While Convolutional Neural Networks (CNNs) have established a new state-of-the-art in several vision problems, their application to the task of sentiment analysis is mostly unexplored and there are few studies regarding how to design CNNs for this purpose. In this work, we study the suitability of fine-tuning a CNN for visual sentiment prediction as well as explore performance boosting techniques within this deep learning setting. Finally, we provide a deep-dive analysis into a benchmark, state-of-the-art network architecture to gain insight about how to design patterns for CNNs on the task of visual sentiment prediction.



