# Arxiv Papers in cs.CV on 2015-05-26
### An Empirical Evaluation of Current Convolutional Architectures' Ability to Manage Nuisance Location and Scale Variability
- **Arxiv ID**: http://arxiv.org/abs/1505.06795v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1505.06795v2)
- **Published**: 2015-05-26 03:11:11+00:00
- **Updated**: 2016-04-28 05:20:40+00:00
- **Authors**: Nikolaos Karianakis, Jingming Dong, Stefano Soatto
- **Comment**: 10 pages, 5 figures, 3 tables -- CVPR 2016, camera-ready version
- **Journal**: None
- **Summary**: We conduct an empirical study to test the ability of Convolutional Neural Networks (CNNs) to reduce the effects of nuisance transformations of the input data, such as location, scale and aspect ratio. We isolate factors by adopting a common convolutional architecture either deployed globally on the image to compute class posterior distributions, or restricted locally to compute class conditional distributions given location, scale and aspect ratios of bounding boxes determined by proposal heuristics. In theory, averaging the latter should yield inferior performance compared to proper marginalization. Yet empirical evidence suggests the converse, leading us to conclude that - at the current level of complexity of convolutional architectures and scale of the data sets used to train them - CNNs are not very effective at marginalizing nuisance variability. We also quantify the effects of context on the overall classification task and its impact on the performance of CNNs, and propose improved sampling techniques for heuristic proposal schemes that improve end-to-end performance to state-of-the-art levels. We test our hypothesis on a classification task using the ImageNet Challenge benchmark and on a wide-baseline matching task using the Oxford and Fischer's datasets.



### Accelerating Very Deep Convolutional Networks for Classification and Detection
- **Arxiv ID**: http://arxiv.org/abs/1505.06798v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1505.06798v2)
- **Published**: 2015-05-26 03:30:59+00:00
- **Updated**: 2015-11-18 06:16:59+00:00
- **Authors**: Xiangyu Zhang, Jianhua Zou, Kaiming He, Jian Sun
- **Comment**: TPAMI, accepted. arXiv admin note: substantial text overlap with
  arXiv:1411.4229
- **Journal**: None
- **Summary**: This paper aims to accelerate the test-time computation of convolutional neural networks (CNNs), especially very deep CNNs that have substantially impacted the computer vision community. Unlike previous methods that are designed for approximating linear filters or linear responses, our method takes the nonlinear units into account. We develop an effective solution to the resulting nonlinear optimization problem without the need of stochastic gradient descent (SGD). More importantly, while previous methods mainly focus on optimizing one or two layers, our nonlinear method enables an asymmetric reconstruction that reduces the rapidly accumulated error when multiple (e.g., >=10) layers are approximated. For the widely used very deep VGG-16 model, our method achieves a whole-model speedup of 4x with merely a 0.3% increase of top-5 error in ImageNet classification. Our 4x accelerated VGG-16 model also shows a graceful accuracy degradation for object detection when plugged into the Fast R-CNN detector.



### Boosting-like Deep Learning For Pedestrian Detection
- **Arxiv ID**: http://arxiv.org/abs/1505.06800v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1505.06800v1)
- **Published**: 2015-05-26 03:52:52+00:00
- **Updated**: 2015-05-26 03:52:52+00:00
- **Authors**: Lei Wang, Baochang Zhang
- **Comment**: 9 pages,7 figures
- **Journal**: None
- **Summary**: This paper proposes boosting-like deep learning (BDL) framework for pedestrian detection. Due to overtraining on the limited training samples, overfitting is a major problem of deep learning. We incorporate a boosting-like technique into deep learning to weigh the training samples, and thus prevent overtraining in the iterative process. We theoretically give the details of derivation of our algorithm, and report the experimental results on open data sets showing that BDL achieves a better stable performance than the state-of-the-arts. Our approach achieves 15.85% and 3.81% reduction in the average miss rate compared with ACF and JointDeep on the largest Caltech benchmark dataset, respectively.



### Discrete Independent Component Analysis (DICA) with Belief Propagation
- **Arxiv ID**: http://arxiv.org/abs/1505.06814v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1505.06814v1)
- **Published**: 2015-05-26 06:02:05+00:00
- **Updated**: 2015-05-26 06:02:05+00:00
- **Authors**: Francesco A. N. Palmieri, Amedeo Buonanno
- **Comment**: Sumbitted for publication (May 2015)
- **Journal**: None
- **Summary**: We apply belief propagation to a Bayesian bipartite graph composed of discrete independent hidden variables and discrete visible variables. The network is the Discrete counterpart of Independent Component Analysis (DICA) and it is manipulated in a factor graph form for inference and learning. A full set of simulations is reported for character images from the MNIST dataset. The results show that the factorial code implemented by the sources contributes to build a good generative model for the data that can be used in various inference modes.



### Deep Ranking for Person Re-identification via Joint Representation Learning
- **Arxiv ID**: http://arxiv.org/abs/1505.06821v2
- **DOI**: 10.1109/TIP.2016.2545929
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.06821v2)
- **Published**: 2015-05-26 06:35:46+00:00
- **Updated**: 2016-03-23 03:37:36+00:00
- **Authors**: Shi-Zhe Chen, Chun-Chao Guo, Jian-Huang Lai
- **Comment**: 15 pages, 15 figures, IEEE Transactions on Image Processing (TIP),
  2016
- **Journal**: None
- **Summary**: This paper proposes a novel approach to person re-identification, a fundamental task in distributed multi-camera surveillance systems. Although a variety of powerful algorithms have been presented in the past few years, most of them usually focus on designing hand-crafted features and learning metrics either individually or sequentially. Different from previous works, we formulate a unified deep ranking framework that jointly tackles both of these key components to maximize their strengths. We start from the principle that the correct match of the probe image should be positioned in the top rank within the whole gallery set. An effective learning-to-rank algorithm is proposed to minimize the cost corresponding to the ranking disorders of the gallery. The ranking model is solved with a deep convolutional neural network (CNN) that builds the relation between input image pairs and their similarity scores through joint representation learning directly from raw image pixels. The proposed framework allows us to get rid of feature engineering and does not rely on any assumption. An extensive comparative evaluation is given, demonstrating that our approach significantly outperforms all state-of-the-art approaches, including both traditional and CNN-based methods on the challenging VIPeR, CUHK-01 and CAVIAR4REID datasets. Additionally, our approach has better ability to generalize across datasets without fine-tuning.



### Using Dimension Reduction to Improve the Classification of High-dimensional Data
- **Arxiv ID**: http://arxiv.org/abs/1505.06907v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1505.06907v1)
- **Published**: 2015-05-26 11:33:04+00:00
- **Updated**: 2015-05-26 11:33:04+00:00
- **Authors**: Andreas Grünauer, Markus Vincze
- **Comment**: Presented at OAGM Workshop, 2015 (arXiv:1505.01065)
- **Journal**: None
- **Summary**: In this work we show that the classification performance of high-dimensional structural MRI data with only a small set of training examples is improved by the usage of dimension reduction methods. We assessed two different dimension reduction variants: feature selection by ANOVA F-test and feature transformation by PCA. On the reduced datasets, we applied common learning algorithms using 5-fold cross-validation. Training, tuning of the hyperparameters, as well as the performance evaluation of the classifiers was conducted using two different performance measures: Accuracy, and Receiver Operating Characteristic curve (AUC). Our hypothesis is supported by experimental results.



### Sequential Dimensionality Reduction for Extracting Localized Features
- **Arxiv ID**: http://arxiv.org/abs/1505.06957v2
- **DOI**: 10.1016/j.patcog.2016.09.006
- **Categories**: **cs.CV**, cs.LG, cs.NA, math.NA, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1505.06957v2)
- **Published**: 2015-05-26 14:06:16+00:00
- **Updated**: 2016-07-05 06:44:58+00:00
- **Authors**: Gabriella Casalino, Nicolas Gillis
- **Comment**: 24 pages, 12 figures. New numerical experiments on synthetic data
  sets, discussion about the convergence
- **Journal**: Pattern Recoginition 63, pp. 15-29, 2017
- **Summary**: Linear dimensionality reduction techniques are powerful tools for image analysis as they allow the identification of important features in a data set. In particular, nonnegative matrix factorization (NMF) has become very popular as it is able to extract sparse, localized and easily interpretable features by imposing an additive combination of nonnegative basis elements. Nonnegative matrix underapproximation (NMU) is a closely related technique that has the advantage to identify features sequentially. In this paper, we propose a variant of NMU that is particularly well suited for image analysis as it incorporates the spatial information, that is, it takes into account the fact that neighboring pixels are more likely to be contained in the same features, and favors the extraction of localized features by looking for sparse basis elements. We show that our new approach competes favorably with comparable state-of-the-art techniques on synthetic, facial and hyperspectral image data sets.



### Efficient Decomposition of Image and Mesh Graphs by Lifted Multicuts
- **Arxiv ID**: http://arxiv.org/abs/1505.06973v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.06973v2)
- **Published**: 2015-05-26 14:46:27+00:00
- **Updated**: 2015-09-11 14:16:25+00:00
- **Authors**: Margret Keuper, Evgeny Levinkov, Nicolas Bonneel, Guillaume Lavoué, Thomas Brox, Bjoern Andres
- **Comment**: None
- **Journal**: None
- **Summary**: Formulations of the Image Decomposition Problem as a Multicut Problem (MP) w.r.t. a superpixel graph have received considerable attention. In contrast, instances of the MP w.r.t. a pixel grid graph have received little attention, firstly, because the MP is NP-hard and instances w.r.t. a pixel grid graph are hard to solve in practice, and, secondly, due to the lack of long-range terms in the objective function of the MP. We propose a generalization of the MP with long-range terms (LMP). We design and implement two efficient algorithms (primal feasible heuristics) for the MP and LMP which allow us to study instances of both problems w.r.t. the pixel grid graphs of the images in the BSDS-500 benchmark. The decompositions we obtain do not differ significantly from the state of the art, suggesting that the LMP is a competitive formulation of the Image Decomposition Problem. To demonstrate the generality of the LMP, we apply it also to the Mesh Decomposition Problem posed by the Princeton benchmark, obtaining state-of-the-art decompositions.



