# Arxiv Papers in cs.CV on 2019-02-08
### Mobile Artificial Intelligence Technology for Detecting Macula Edema and Subretinal Fluid on OCT Scans: Initial Results from the DATUM alpha Study
- **Arxiv ID**: http://arxiv.org/abs/1902.02905v2
- **DOI**: None
- **Categories**: **physics.med-ph**, cs.AI, cs.CV, cs.LG, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/1902.02905v2)
- **Published**: 2019-02-08 01:15:23+00:00
- **Updated**: 2019-02-12 23:50:23+00:00
- **Authors**: Stephen G. Odaibo, Mikelson MomPremier, Richard Y. Hwang, Salman J. Yousuf, Steven L. Williams, Joshua Grant
- **Comment**: Initial results of the DATUM alpha Study were initially presented on
  August 13th 2018 in the Keynote Address at the 116th National Medical
  Association Annual Meeting & Scientific Assembly's New Innovations in
  Ophthalmology Session. The results were also presented on September 21st 2018
  in a Podium Lecture during Alumni Day at the University of Michigan--Ann
  Arbor Kellogg Eye Center
- **Journal**: None
- **Summary**: Artificial Intelligence (AI) is necessary to address the large and growing deficit in retina and healthcare access globally. And mobile AI diagnostic platforms running in the Cloud may effectively and efficiently distribute such AI capability. Here we sought to evaluate the feasibility of Cloud-based mobile artificial intelligence for detection of retinal disease. And to evaluate the accuracy of a particular such system for detection of subretinal fluid (SRF) and macula edema (ME) on OCT scans. A multicenter retrospective image analysis was conducted in which board-certified ophthalmologists with fellowship training in retina evaluated OCT images of the macula. They noted the presence or absence of ME or SRF, then compared their assessment to that obtained from Fluid Intelligence, a mobile AI app that detects SRF and ME on OCT scans. Investigators consecutively selected retinal OCTs, while making effort to balance the number of scans with retinal fluid and scans without. Exclusion criteria included poor scan quality, ambiguous features, macula holes, retinoschisis, and dense epiretinal membranes. Accuracy in the form of sensitivity and specificity of the AI mobile App was determined by comparing its assessments to those of the retina specialists. At the time of this submission, five centers have completed their initial studies. This consists of a total of 283 OCT scans of which 155 had either ME or SRF ("wet") and 128 did not ("dry"). The sensitivity ranged from 82.5% to 97% with a weighted average of 89.3%. The specificity ranged from 52% to 100% with a weighted average of 81.23%. CONCLUSION: Cloud-based Mobile AI technology is feasible for the detection retinal disease. In particular, Fluid Intelligence (alpha version), is sufficiently accurate as a screening tool for SRF and ME, especially in underserved areas. Further studies and technology development is needed.



### AdaScale: Towards Real-time Video Object Detection Using Adaptive Scaling
- **Arxiv ID**: http://arxiv.org/abs/1902.02910v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1902.02910v1)
- **Published**: 2019-02-08 01:31:02+00:00
- **Updated**: 2019-02-08 01:31:02+00:00
- **Authors**: Ting-Wu Chin, Ruizhou Ding, Diana Marculescu
- **Comment**: Accepted to SysML 2019 (http://www.sysml.cc/) as oral contribution
- **Journal**: None
- **Summary**: In vision-enabled autonomous systems such as robots and autonomous cars, video object detection plays a crucial role, and both its speed and accuracy are important factors to provide reliable operation. The key insight we show in this paper is that speed and accuracy are not necessarily a trade-off when it comes to image scaling. Our results show that re-scaling the image to a lower resolution will sometimes produce better accuracy. Based on this observation, we propose a novel approach, dubbed AdaScale, which adaptively selects the input image scale that improves both accuracy and speed for video object detection. To this end, our results on ImageNet VID and mini YouTube-BoundingBoxes datasets demonstrate 1.3 points and 2.7 points mAP improvement with 1.6x and 1.8x speedup, respectively. Additionally, we improve state-of-the-art video acceleration work by an extra 1.25x speedup with slightly better mAP on ImageNet VID dataset.



### A Comprehensive Overview of Biometric Fusion
- **Arxiv ID**: http://arxiv.org/abs/1902.02919v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1902.02919v1)
- **Published**: 2019-02-08 02:15:15+00:00
- **Updated**: 2019-02-08 02:15:15+00:00
- **Authors**: Maneet Singh, Richa Singh, Arun Ross
- **Comment**: Accepted for publication in Information Fusion
- **Journal**: None
- **Summary**: The performance of a biometric system that relies on a single biometric modality (e.g., fingerprints only) is often stymied by various factors such as poor data quality or limited scalability. Multibiometric systems utilize the principle of fusion to combine information from multiple sources in order to improve recognition accuracy whilst addressing some of the limitations of single-biometric systems. The past two decades have witnessed the development of a large number of biometric fusion schemes. This paper presents an overview of biometric fusion with specific focus on three questions: what to fuse, when to fuse, and how to fuse. A comprehensive review of techniques incorporating ancillary information in the biometric recognition pipeline is also presented. In this regard, the following topics are discussed: (i) incorporating data quality in the biometric recognition pipeline; (ii) combining soft biometric attributes with primary biometric identifiers; (iii) utilizing contextual information to improve biometric recognition accuracy; and (iv) performing continuous authentication using ancillary information. In addition, the use of information fusion principles for presentation attack detection and multibiometric cryptosystems is also discussed. Finally, some of the research challenges in biometric fusion are enumerated. The purpose of this article is to provide readers a comprehensive overview of the role of information fusion in biometrics.



### Informing Computer Vision with Optical Illusions
- **Arxiv ID**: http://arxiv.org/abs/1902.02922v1
- **DOI**: None
- **Categories**: **cs.CV**, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/1902.02922v1)
- **Published**: 2019-02-08 03:06:29+00:00
- **Updated**: 2019-02-08 03:06:29+00:00
- **Authors**: Nasim Nematzadeh, David M. W. Powers, Trent Lewis
- **Comment**: 8 pages, 4 figures. Submitted to IJCNN2019 conference
- **Journal**: None
- **Summary**: Illusions are fascinating and immediately catch people's attention and interest, but they are also valuable in terms of giving us insights into human cognition and perception. A good theory of human perception should be able to explain the illusion, and a correct theory will actually give quantifiable results. We investigate here the efficiency of a computational filtering model utilised for modelling the lateral inhibition of retinal ganglion cells and their responses to a range of Geometric Illusions using isotropic Differences of Gaussian filters. This study explores the way in which illusions have been explained and shows how a simple standard model of vision based on classical receptive fields can predict the existence of these illusions as well as the degree of effect. A fundamental contribution of this work is to link bottom-up processes to higher level perception and cognition consistent with Marr's theory of vision and edge map representation.



### A Single-shot Object Detector with Feature Aggragation and Enhancement
- **Arxiv ID**: http://arxiv.org/abs/1902.02923v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1902.02923v2)
- **Published**: 2019-02-08 03:08:12+00:00
- **Updated**: 2019-09-09 11:07:12+00:00
- **Authors**: Weiqiang Li, Guizhong Liu
- **Comment**: None
- **Journal**: None
- **Summary**: For many real applications, it is equally important to detect objects accurately and quickly. In this paper, we propose an accurate and efficient single shot object detector with feature aggregation and enhancement (FAENet). Our motivation is to enhance and exploit the shallow and deep feature maps of the whole network simultaneously. To achieve it we introduce a pair of novel feature aggregation modules and two feature enhancement blocks, and integrate them into the original structure of SSD. Extensive experiments on both the PASCAL VOC and MS COCO datasets demonstrate that the proposed method achieves much higher accuracy than SSD. In addition, our method performs better than the state-of-the-art one-stage detector RefineDet on small objects and can run at a faster speed.



### Prediction of Dashed Café Wall illusion by the Classical Receptive Field Model
- **Arxiv ID**: http://arxiv.org/abs/1902.03739v2
- **DOI**: None
- **Categories**: **q-bio.NC**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1902.03739v2)
- **Published**: 2019-02-08 03:23:22+00:00
- **Updated**: 2020-05-11 07:59:53+00:00
- **Authors**: Nasim Nematzadeh, David M. W. Powers
- **Comment**: 6 pages, 6 figures. Accepted in ICECCE2020 conference
- **Journal**: None
- **Summary**: The Caf\'e Wall illusion is one of a class of tilt illusions where lines that are parallel appear to be tilted. We demonstrate that a simple Differences of Gaussian model provides an explanatory mechanism for the illusory tilt perceived in a family of Caf\'e Wall illusion generalizes to the dashed versions of Caf\'e Wall. Our explanation models the visual mechanisms in low level stages and the lateral inhibition of simple cells that can reveal tilt cues in Geometrical distortion illusions such as Tile illusions particularly Caf\'e Wall illusions. For this, we simulate the activations of the retinal/cortical simple cells in responses to these patterns based on a Classical Receptive Field (CRF) model (referred to as Vis-CRF) to explain tilt effects in these illusions. Previously, it was assumed that all these visual experiences of tilt arise from the orientation selectivity properties described for more complex cortical cells. An estimation of an overall tilt angle perceived in these illusions is based on the integration of the local tilts detected by simple cells which is presumed to be a key mechanism utilized by the complex cells to create our final perception of tilt.



### Robust Encoder-Decoder Learning Framework towards Offline Handwritten Mathematical Expression Recognition Based on Multi-Scale Deep Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1902.05376v3
- **DOI**: 10.1007/s11432-018-9824-9
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1902.05376v3)
- **Published**: 2019-02-08 03:29:49+00:00
- **Updated**: 2020-05-28 11:06:38+00:00
- **Authors**: Guangcun Shan, Hongyu Wang, Wei Liang
- **Comment**: 11 pages, 16 figures
- **Journal**: Sci China Inf Sci, 2021, 64(3): 139101, doi:
  10.1007/s11432-018-9824-9
- **Summary**: Offline handwritten mathematical expression recognition is a challenging task, because handwritten mathematical expressions mainly have two problems in the process of recognition. On one hand, it is how to correctly recognize different mathematical symbols. On the other hand, it is how to correctly recognize the two-dimensional structure existing in mathematical expressions. Inspired by recent work in deep learning, a new neural network model that combines a Multi-Scale convolutional neural network (CNN) with an Attention recurrent neural network (RNN) is proposed to identify two-dimensional handwritten mathematical expressions as one-dimensional LaTeX sequences. As a result, the model proposed in the present work has achieved a WER error of 25.715% and ExpRate of 28.216%.



### Understanding the One-Pixel Attack: Propagation Maps and Locality Analysis
- **Arxiv ID**: http://arxiv.org/abs/1902.02947v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CR, cs.CV, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1902.02947v1)
- **Published**: 2019-02-08 06:06:01+00:00
- **Updated**: 2019-02-08 06:06:01+00:00
- **Authors**: Danilo Vasconcellos Vargas, Jiawei Su
- **Comment**: None
- **Journal**: None
- **Summary**: Deep neural networks were shown to be vulnerable to single pixel modifications. However, the reason behind such phenomena has never been elucidated. Here, we propose Propagation Maps which show the influence of the perturbation in each layer of the network. Propagation Maps reveal that even in extremely deep networks such as Resnet, modification in one pixel easily propagates until the last layer. In fact, this initial local perturbation is also shown to spread becoming a global one and reaching absolute difference values that are close to the maximum value of the original feature maps in a given layer. Moreover, we do a locality analysis in which we demonstrate that nearby pixels of the perturbed one in the one-pixel attack tend to share the same vulnerability, revealing that the main vulnerability lies in neither neurons nor pixels but receptive fields. Hopefully, the analysis conducted in this work together with a new technique called propagation maps shall shed light into the inner workings of other adversarial samples and be the basis of new defense systems to come.



### Reducing Uncertainty in Undersampled MRI Reconstruction with Active Acquisition
- **Arxiv ID**: http://arxiv.org/abs/1902.03051v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1902.03051v1)
- **Published**: 2019-02-08 12:24:57+00:00
- **Updated**: 2019-02-08 12:24:57+00:00
- **Authors**: Zizhao Zhang, Adriana Romero, Matthew J. Muckley, Pascal Vincent, Lin Yang, Michal Drozdzal
- **Comment**: None
- **Journal**: None
- **Summary**: The goal of MRI reconstruction is to restore a high fidelity image from partially observed measurements. This partial view naturally induces reconstruction uncertainty that can only be reduced by acquiring additional measurements. In this paper, we present a novel method for MRI reconstruction that, at inference time, dynamically selects the measurements to take and iteratively refines the prediction in order to best reduce the reconstruction error and, thus, its uncertainty. We validate our method on a large scale knee MRI dataset, as well as on ImageNet. Results show that (1) our system successfully outperforms active acquisition baselines; (2) our uncertainty estimates correlate with error maps; and (3) our ResNet-based architecture surpasses standard pixel-to-pixel models in the task of MRI reconstruction. The proposed method not only shows high-quality reconstructions but also paves the road towards more applicable solutions for accelerating MRI.



### OrthographicNet: A Deep Transfer Learning Approach for 3D Object Recognition in Open-Ended Domains
- **Arxiv ID**: http://arxiv.org/abs/1902.03057v3
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1902.03057v3)
- **Published**: 2019-02-08 12:39:00+00:00
- **Updated**: 2020-12-31 17:37:11+00:00
- **Authors**: Hamidreza Kasaei
- **Comment**: None
- **Journal**: None
- **Summary**: Nowadays, service robots are appearing more and more in our daily life. For this type of robot, open-ended object category learning and recognition is necessary since no matter how extensive the training data used for batch learning, the robot might be faced with a new object when operating in a real-world environment. In this work, we present OrthographicNet, a Convolutional Neural Network (CNN)-based model, for 3D object recognition in open-ended domains. In particular, OrthographicNet generates a global rotation- and scale-invariant representation for a given 3D object, enabling robots to recognize the same or similar objects seen from different perspectives. Experimental results show that our approach yields significant improvements over the previous state-of-the-art approaches concerning object recognition performance and scalability in open-ended scenarios. Moreover, OrthographicNet demonstrates the capability of learning new categories from very few examples on-site. Regarding real-time performance, three real-world demonstrations validate the promising performance of the proposed architecture.



### A Fast Algorithm for Cosine Transform Based Tensor Singular Value Decomposition
- **Arxiv ID**: http://arxiv.org/abs/1902.03070v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1902.03070v1)
- **Published**: 2019-02-08 13:21:37+00:00
- **Updated**: 2019-02-08 13:21:37+00:00
- **Authors**: Wen-Hao Xu, Xi-Le Zhao, Michael Ng
- **Comment**: None
- **Journal**: None
- **Summary**: Recently, there has been a lot of research into tensor singular value decomposition (t-SVD) by using discrete Fourier transform (DFT) matrix. The main aims of this paper are to propose and study tensor singular value decomposition based on the discrete cosine transform (DCT) matrix. The advantages of using DCT are that (i) the complex arithmetic is not involved in the cosine transform based tensor singular value decomposition, so the computational cost required can be saved; (ii) the intrinsic reflexive boundary condition along the tubes in the third dimension of tensors is employed, so its performance would be better than that by using the periodic boundary condition in DFT. We demonstrate that the tensor product between two tensors by using DCT can be equivalent to the multiplication between a block Toeplitz-plus-Hankel matrix and a block vector. Numerical examples of low-rank tensor completion are further given to illustrate that the efficiency by using DCT is two times faster than that by using DFT and also the errors of video and multispectral image completion by using DCT are smaller than those by using DFT.



### Spectral-Spatial Diffusion Geometry for Hyperspectral Image Clustering
- **Arxiv ID**: http://arxiv.org/abs/1902.05402v1
- **DOI**: 10.1109/LGRS.2019.2943001
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1902.05402v1)
- **Published**: 2019-02-08 13:28:30+00:00
- **Updated**: 2019-02-08 13:28:30+00:00
- **Authors**: James M. Murphy, Mauro Maggioni
- **Comment**: None
- **Journal**: None
- **Summary**: An unsupervised learning algorithm to cluster hyperspectral image (HSI) data is proposed that exploits spatially-regularized random walks. Markov diffusions are defined on the space of HSI spectra with transitions constrained to near spatial neighbors. The explicit incorporation of spatial regularity into the diffusion construction leads to smoother random processes that are more adapted for unsupervised machine learning than those based on spectra alone. The regularized diffusion process is subsequently used to embed the high-dimensional HSI into a lower dimensional space through diffusion distances. Cluster modes are computed using density estimation and diffusion distances, and all other points are labeled according to these modes. The proposed method has low computational complexity and performs competitively against state-of-the-art HSI clustering algorithms on real data. In particular, the proposed spatial regularization confers an empirical advantage over non-regularized methods.



### Skeleton-Based Online Action Prediction Using Scale Selection Network
- **Arxiv ID**: http://arxiv.org/abs/1902.03084v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1902.03084v2)
- **Published**: 2019-02-08 14:04:25+00:00
- **Updated**: 2019-04-03 10:46:28+00:00
- **Authors**: Jun Liu, Amir Shahroudy, Gang Wang, Ling-Yu Duan, Alex C. Kot
- **Comment**: This paper has been accepted by T-PAMI. DOI:
  10.1109/TPAMI.2019.2898954
- **Journal**: None
- **Summary**: Action prediction is to recognize the class label of an ongoing activity when only a part of it is observed. In this paper, we focus on online action prediction in streaming 3D skeleton sequences. A dilated convolutional network is introduced to model the motion dynamics in temporal dimension via a sliding window over the temporal axis. Since there are significant temporal scale variations in the observed part of the ongoing action at different time steps, a novel window scale selection method is proposed to make our network focus on the performed part of the ongoing action and try to suppress the possible incoming interference from the previous actions at each step. An activation sharing scheme is also proposed to handle the overlapping computations among the adjacent time steps, which enables our framework to run more efficiently. Moreover, to enhance the performance of our framework for action prediction with the skeletal input data, a hierarchy of dilated tree convolutions are also designed to learn the multi-level structured semantic representations over the skeleton joints at each frame. Our proposed approach is evaluated on four challenging datasets. The extensive experiments demonstrate the effectiveness of our method for skeleton-based online action prediction.



### Addressing Overfitting on Pointcloud Classification using Atrous XCRF
- **Arxiv ID**: http://arxiv.org/abs/1902.03088v1
- **DOI**: 10.1016/j.isprsjprs.2019.07.002
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1902.03088v1)
- **Published**: 2019-02-08 14:20:42+00:00
- **Updated**: 2019-02-08 14:20:42+00:00
- **Authors**: Hasan Asyari Arief, Ulf Geir Indahl, Geir-Harald Strand, Håvard Tveite
- **Comment**: None
- **Journal**: ISPRS Journal of Photogrammetry and Remote Sensing Volume 155,
  September 2019, Pages 90-101
- **Summary**: Advances in techniques for automated classification of pointcloud data introduce great opportunities for many new and existing applications. However, with a limited number of labeled points, automated classification by a machine learning model is prone to overfitting and poor generalization. The present paper addresses this problem by inducing controlled noise (on a trained model) generated by invoking conditional random field similarity penalties using nearby features. The method is called Atrous XCRF and works by forcing a trained model to respect the similarity penalties provided by unlabeled data. In a benchmark study carried out using the ISPRS 3D labeling dataset, our technique achieves 84.97% in term of overall accuracy, and 71.05% in term of F1 score. The result is on par with the current best model for the benchmark dataset and has the highest value in term of F1 score.



### FocusNet: An attention-based Fully Convolutional Network for Medical Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1902.03091v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1902.03091v1)
- **Published**: 2019-02-08 14:24:36+00:00
- **Updated**: 2019-02-08 14:24:36+00:00
- **Authors**: Chaitanya Kaul, Suresh Manandhar, Nick Pears
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a novel technique to incorporate attention within convolutional neural networks using feature maps generated by a separate convolutional autoencoder. Our attention architecture is well suited for incorporation with deep convolutional networks. We evaluate our model on benchmark segmentation datasets in skin cancer segmentation and lung lesion segmentation. Results show highly competitive performance when compared with U-Net and it's residual variant.



### Discretization based Solutions for Secure Machine Learning against Adversarial Attacks
- **Arxiv ID**: http://arxiv.org/abs/1902.03151v2
- **DOI**: 10.1109/ACCESS.2019.2919463
- **Categories**: **cs.LG**, cs.CR, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1902.03151v2)
- **Published**: 2019-02-08 15:38:24+00:00
- **Updated**: 2019-02-11 18:15:55+00:00
- **Authors**: Priyadarshini Panda, Indranil Chakraborty, Kaushik Roy
- **Comment**: 8 pages, 8 Figures, 6 Tables
- **Journal**: IEEE Access, 2019
- **Summary**: Adversarial examples are perturbed inputs that are designed (from a deep learning network's (DLN) parameter gradients) to mislead the DLN during test time. Intuitively, constraining the dimensionality of inputs or parameters of a network reduces the 'space' in which adversarial examples exist. Guided by this intuition, we demonstrate that discretization greatly improves the robustness of DLNs against adversarial attacks. Specifically, discretizing the input space (or allowed pixel levels from 256 values or 8-bit to 4 values or 2-bit) extensively improves the adversarial robustness of DLNs for a substantial range of perturbations for minimal loss in test accuracy. Furthermore, we find that Binary Neural Networks (BNNs) and related variants are intrinsically more robust than their full precision counterparts in adversarial scenarios. Combining input discretization with BNNs furthers the robustness even waiving the need for adversarial training for certain magnitude of perturbation values. We evaluate the effect of discretization on MNIST, CIFAR10, CIFAR100 and Imagenet datasets. Across all datasets, we observe maximal adversarial resistance with 2-bit input discretization that incurs an adversarial accuracy loss of just ~1-2% as compared to clean test accuracy.



### Software-Defined FPGA Accelerator Design for Mobile Deep Learning Applications
- **Arxiv ID**: http://arxiv.org/abs/1902.03192v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1902.03192v2)
- **Published**: 2019-02-08 17:08:39+00:00
- **Updated**: 2019-03-24 17:23:57+00:00
- **Authors**: Panagiotis G. Mousouliotis, Loukas P. Petrou
- **Comment**: Accepted to be presented in the 15th International Symposium on
  Applied Reconfigurable Computing
- **Journal**: None
- **Summary**: Recently, the field of deep learning has received great attention by the scientific community and it is used to provide improved solutions to many computer vision problems. Convolutional neural networks (CNNs) have been successfully used to attack problems such as object recognition, object detection, semantic segmentation, and scene understanding. The rapid development of deep learning goes hand by hand with the adaptation of GPUs for accelerating its processes, such as network training and inference. Even though FPGA design exists long before the use of GPUs for accelerating computations and despite the fact that high-level synthesis (HLS) tools are getting more attractive, the adaptation of FPGAs for deep learning research and application development is poor due to the requirement of hardware design related expertise. This work presents a workflow for deep learning mobile application acceleration on small low-cost low-power FPGA devices using HLS tools. This workflow eases the design of an improved version of the SqueezeJet accelerator used for the speedup of mobile-friendly low-parameter ImageNet class CNNs, such as the SqueezeNet v1.1 and the ZynqNet. Additionally, the workflow includes the development of an HLS-driven analytical model which is used for performance estimation of the accelerator. This model can be also used to direct the design process and lead to future design improvements and optimizations.



### Object tracking in video signals using Compressive Sensing
- **Arxiv ID**: http://arxiv.org/abs/1903.06253v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1903.06253v1)
- **Published**: 2019-02-08 17:41:02+00:00
- **Updated**: 2019-02-08 17:41:02+00:00
- **Authors**: Marijana Kracunov, Milica Bastica, Jovana Tesovic
- **Comment**: Student paper submitted to "The 8th Mediterranean Conference on
  Embedded Computing" - MECO'2019
- **Journal**: None
- **Summary**: Reducing the number of pixels in video signals while maintaining quality needed for recovering the trace of an object using Compressive Sensing is main subject of this work. Quality of frames, from video that contains moving object, are gradually reduced by keeping different number of pixels in each iteration, going from 45% all the way to 1%. Using algorithm for tracing object, results were satisfactory and showed mere changes in trajectory graphs, obtained from original and reconstructed videos.



### Minimal Images in Deep Neural Networks: Fragile Object Recognition in Natural Images
- **Arxiv ID**: http://arxiv.org/abs/1902.03227v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1902.03227v1)
- **Published**: 2019-02-08 18:36:49+00:00
- **Updated**: 2019-02-08 18:36:49+00:00
- **Authors**: Sanjana Srivastava, Guy Ben-Yosef, Xavier Boix
- **Comment**: International Conference on Learning Representations (ICLR) 2019
- **Journal**: None
- **Summary**: The human ability to recognize objects is impaired when the object is not shown in full. "Minimal images" are the smallest regions of an image that remain recognizable for humans. Ullman et al. 2016 show that a slight modification of the location and size of the visible region of the minimal image produces a sharp drop in human recognition accuracy. In this paper, we demonstrate that such drops in accuracy due to changes of the visible region are a common phenomenon between humans and existing state-of-the-art deep neural networks (DNNs), and are much more prominent in DNNs. We found many cases where DNNs classified one region correctly and the other incorrectly, though they only differed by one row or column of pixels, and were often bigger than the average human minimal image size. We show that this phenomenon is independent from previous works that have reported lack of invariance to minor modifications in object location in DNNs. Our results thus reveal a new failure mode of DNNs that also affects humans to a much lesser degree. They expose how fragile DNN recognition ability is for natural images even without adversarial patterns being introduced. Bringing the robustness of DNNs in natural images to the human level remains an open challenge for the community.



### A 3D Probabilistic Deep Learning System for Detection and Diagnosis of Lung Cancer Using Low-Dose CT Scans
- **Arxiv ID**: http://arxiv.org/abs/1902.03233v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1902.03233v3)
- **Published**: 2019-02-08 18:53:27+00:00
- **Updated**: 2020-01-21 02:27:50+00:00
- **Authors**: Onur Ozdemir, Rebecca L. Russell, Andrew A. Berlin
- **Comment**: None
- **Journal**: None
- **Summary**: We introduce a new computer aided detection and diagnosis system for lung cancer screening with low-dose CT scans that produces meaningful probability assessments. Our system is based entirely on 3D convolutional neural networks and achieves state-of-the-art performance for both lung nodule detection and malignancy classification tasks on the publicly available LUNA16 and Kaggle Data Science Bowl challenges. While nodule detection systems are typically designed and optimized on their own, we find that it is important to consider the coupling between detection and diagnosis components. Exploiting this coupling allows us to develop an end-to-end system that has higher and more robust performance and eliminates the need for a nodule detection false positive reduction stage. Furthermore, we characterize model uncertainty in our deep learning systems, a first for lung CT analysis, and show that we can use this to provide well-calibrated classification probabilities for both nodule detection and patient malignancy diagnosis. These calibrated probabilities informed by model uncertainty can be used for subsequent risk-based decision making towards diagnostic interventions or disease treatments, as we demonstrate using a probability-based patient referral strategy to further improve our results.



### Skin Lesion Synthesis with Generative Adversarial Networks
- **Arxiv ID**: http://arxiv.org/abs/1902.03253v1
- **DOI**: 10.1007/978-3-030-01201-4_32
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1902.03253v1)
- **Published**: 2019-02-08 19:03:41+00:00
- **Updated**: 2019-02-08 19:03:41+00:00
- **Authors**: Alceu Bissoto, Fábio Perez, Eduardo Valle, Sandra Avila
- **Comment**: Conference: ISIC Skin Image Analysis Workshop and Challenge @ MICCAI
  2018
- **Journal**: None
- **Summary**: Skin cancer is by far the most common type of cancer. Early detection is the key to increase the chances for successful treatment significantly. Currently, Deep Neural Networks are the state-of-the-art results on automated skin cancer classification. To push the results further, we need to address the lack of annotated data, which is expensive and require much effort from specialists. To bypass this problem, we propose using Generative Adversarial Networks for generating realistic synthetic skin lesion images. To the best of our knowledge, our results are the first to show visually-appealing synthetic images that comprise clinically-meaningful information.



### FERAtt: Facial Expression Recognition with Attention Net
- **Arxiv ID**: http://arxiv.org/abs/1902.03284v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1902.03284v1)
- **Published**: 2019-02-08 20:39:53+00:00
- **Updated**: 2019-02-08 20:39:53+00:00
- **Authors**: Pedro D. Marrero Fernandez, Fidel A. Guerrero Peña, Tsang Ing Ren, Alexandre Cunha
- **Comment**: None
- **Journal**: None
- **Summary**: We present a new end-to-end network architecture for facial expression recognition with an attention model. It focuses attention in the human face and uses a Gaussian space representation for expression recognition. We devise this architecture based on two fundamental complementary components: (1) facial image correction and attention and (2) facial expression representation and classification. The first component uses an encoder-decoder style network and a convolutional feature extractor that are pixel-wise multiplied to obtain a feature attention map. The second component is responsible for obtaining an embedded representation and classification of the facial expression. We propose a loss function that creates a Gaussian structure on the representation space. To demonstrate the proposed method, we create two larger and more comprehensive synthetic datasets using the traditional BU3DFE and CK+ facial datasets. We compared results with the PreActResNet18 baseline. Our experiments on these datasets have shown the superiority of our approach in recognizing facial expressions.



### Architecture Compression
- **Arxiv ID**: http://arxiv.org/abs/1902.03326v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1902.03326v3)
- **Published**: 2019-02-08 23:26:12+00:00
- **Updated**: 2019-03-12 09:10:49+00:00
- **Authors**: Anubhav Ashok
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper we propose a novel approach to model compression termed Architecture Compression. Instead of operating on the weight or filter space of the network like classical model compression methods, our approach operates on the architecture space. A 1-D CNN encoder-decoder is trained to learn a mapping from discrete architecture space to a continuous embedding and back. Additionally, this embedding is jointly trained to regress accuracy and parameter count in order to incorporate information about the architecture's effectiveness on the dataset. During the compression phase, we first encode the network and then perform gradient descent in continuous space to optimize a compression objective function that maximizes accuracy and minimizes parameter count. The final continuous feature is then mapped to a discrete architecture using the decoder. We demonstrate the merits of this approach on visual recognition tasks such as CIFAR-10, CIFAR-100, Fashion-MNIST and SVHN and achieve a greater than 20x compression on CIFAR-10.



