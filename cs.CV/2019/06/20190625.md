# Arxiv Papers in cs.CV on 2019-06-25
### Appearance and Shape from Water Reflection
- **Arxiv ID**: http://arxiv.org/abs/1906.10284v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.10284v2)
- **Published**: 2019-06-25 00:52:37+00:00
- **Updated**: 2020-01-07 12:06:01+00:00
- **Authors**: Ryo Kawahara, Meng-Yu Jennifer Kuo, Shohei Nobuhara, Ko Nishino
- **Comment**: WACV 2020
- **Journal**: None
- **Summary**: This paper introduces single-image geometric and appearance reconstruction from water reflection photography, i.e., images capturing direct and water-reflected real-world scenes. Water reflection offers an additional viewpoint to the direct sight, collectively forming a stereo pair. The water-reflected scene, however, includes internally scattered and reflected environmental illumination in addition to the scene radiance, which precludes direct stereo matching. We derive a principled iterative method that disentangles this scene radiometry and geometry for reconstructing 3D scene structure as well as its high-dynamic range appearance. In the presence of waves, we simultaneously recover the wave geometry as surface normal perturbations of the water surface. Most important, we show that the water reflection enables calibration of the camera. In other words, for the first time, we show that capturing a direct and water-reflected scene in a single exposure forms a self-calibrating HDR catadioptric stereo camera. We demonstrate our method on a number of images taken in the wild. The results demonstrate a new means for leveraging this accidental catadioptric camera.



### 3DBGrowth: volumetric vertebrae segmentation and reconstruction in magnetic resonance imaging
- **Arxiv ID**: http://arxiv.org/abs/1906.10288v2
- **DOI**: 10.1109/CBMS.2019.00091
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1906.10288v2)
- **Published**: 2019-06-25 01:28:20+00:00
- **Updated**: 2019-07-08 21:44:44+00:00
- **Authors**: Jonathan S. Ramos, Mirela T. Cazzolato, Bruno S. Faiçal, Marcello H. Nogueira-Barbosa, Caetano Traina Jr., Agma J. M. Traina
- **Comment**: This is a pre-print of an article published in Computer-Based Medical
  Systems. The final authenticated version is available online at:
  https://doi.org/10.1109/CBMS.2019.00091
- **Journal**: Computer-Based Medical Systems, 2019
- **Summary**: Segmentation of medical images is critical for making several processes of analysis and classification more reliable. With the growing number of people presenting back pain and related problems, the semi-automatic segmentation and 3D reconstruction of vertebral bodies became even more important to support decision making. A 3D reconstruction allows a fast and objective analysis of each vertebrae condition, which may play a major role in surgical planning and evaluation of suitable treatments. In this paper, we propose 3DBGrowth, which develops a 3D reconstruction over the efficient Balanced Growth method for 2D images. We also take advantage of the slope coefficient from the annotation time to reduce the total number of annotated slices, reducing the time spent on manual annotation. We show experimental results on a representative dataset with 17 MRI exams demonstrating that our approach significantly outperforms the competitors and, on average, only 37% of the total slices with vertebral body content must be annotated without losing performance/accuracy. Compared to the state-of-the-art methods, we have achieved a Dice Score gain of over 5% with comparable processing time. Moreover, 3DBGrowth works well with imprecise seed points, which reduces the time spent on manual annotation by the specialist.



### Road-network-based Rapid Geolocalization
- **Arxiv ID**: http://arxiv.org/abs/1906.12174v1
- **DOI**: 10.1109/TGRS.2020.3011034
- **Categories**: **cs.CV**, cs.AI, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1906.12174v1)
- **Published**: 2019-06-25 01:54:21+00:00
- **Updated**: 2019-06-25 01:54:21+00:00
- **Authors**: Yongfei Li, Dongfang Yang, Shicheng Wang, Hao He
- **Comment**: 19pages, 10 figures, 3 tables. in IEEE Transactions on Geoscience and
  Remote Sensing
- **Journal**: None
- **Summary**: It has always been a research hotspot to use geographic information to assist the navigation of unmanned aerial vehicles. In this paper, a road-network-based localization method is proposed. We match roads in the measurement images to the reference road vector map, and realize successful localization on areas as large as a whole city. The road network matching problem is treated as a point cloud registration problem under two-dimensional projective transformation, and solved under a hypothesise-and-test framework. To deal with the projective point cloud registration problem, a global projective invariant feature is proposed, which consists of two road intersections augmented with the information of their tangents. We call it two road intersections tuple. We deduce the closed-form solution for determining the alignment transformation from a pair of matching two road intersections tuples. In addition, we propose the necessary conditions for the tuples to match. This can reduce the candidate matching tuples, thus accelerating the search to a great extent. We test all the candidate matching tuples under a hypothesise-and-test framework to search for the best match. The experiments show that our method can localize the target area over an area of 400 within 1 second on a single cpu.



### Method of diagnosing heart disease based on deep learning ECG signal
- **Arxiv ID**: http://arxiv.org/abs/1907.01514v2
- **DOI**: None
- **Categories**: **eess.SP**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1907.01514v2)
- **Published**: 2019-06-25 05:30:29+00:00
- **Updated**: 2019-10-27 04:07:14+00:00
- **Authors**: Jie Zhang, Bohao Li, Kexin Xiang, Xuegang Shi
- **Comment**: 9 pages,5 figures
- **Journal**: None
- **Summary**: The traditional method of diagnosing heart disease on ECG signal is artificial observation. Some have tried to combine expertise and signal processing to classify ECG signal by heart disease type. However, the currency is not so sufficient that it can be used in medical applications. We develop an algorithm that combines signal processing and deep learning to classify ECG signals into Normal AF other rhythm and noise, which help us solve this problem. It is demonstrated that we can obtain the time-frequency diagram of ECG signal by wavelet transform, and use DNN to classify the time-frequency diagram to find out the heart disease that the signal collector may have. Overall, an accuracy of 94 percent is achieved on the validation set. According to the evaluation criteria of PhysioNet/Computing in Cardiology (CinC) in 2017, the F1 score of this method is 0.957, which is higher than the first place in the competition in 2017.



### EKFPnP: Extended Kalman Filter for Camera Pose Estimation in a Sequence of Images
- **Arxiv ID**: http://arxiv.org/abs/1906.10324v2
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1906.10324v2)
- **Published**: 2019-06-25 05:33:48+00:00
- **Updated**: 2020-04-22 12:25:27+00:00
- **Authors**: Mohammad Amin Mehralian, Mohsen Soryani
- **Comment**: None
- **Journal**: None
- **Summary**: In real-world applications the Perspective-n-Point (PnP) problem should generally be applied in a sequence of images which a set of drift-prone features are tracked over time. In this paper, we consider both the temporal dependency of camera poses and the uncertainty of features for the sequential camera pose estimation. Using the Extended Kalman Filter (EKF), a priori estimate of the camera pose is calculated from the camera motion model and then corrected by minimizing the reprojection error of the reference points. Experimental results, using both simulated and real data, demonstrate that the proposed method improves the robustness of the camera pose estimation, in the presence of noise, compared to the state-of-the-art.



### SkyNet: A Champion Model for DAC-SDC on Low Power Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1906.10327v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.10327v2)
- **Published**: 2019-06-25 05:41:01+00:00
- **Updated**: 2019-07-09 05:51:07+00:00
- **Authors**: Xiaofan Zhang, Cong Hao, Haoming Lu, Jiachen Li, Yuhong Li, Yuchen Fan, Kyle Rupnow, Jinjun Xiong, Thomas Huang, Honghui Shi, Wen-mei Hwu, Deming Chen
- **Comment**: None
- **Journal**: None
- **Summary**: Developing artificial intelligence (AI) at the edge is always challenging, since edge devices have limited computation capability and memory resources but need to meet demanding requirements, such as real-time processing, high throughput performance, and high inference accuracy. To overcome these challenges, we propose SkyNet, an extremely lightweight DNN with 12 convolutional (Conv) layers and only 1.82 megabyte (MB) of parameters following a bottom-up DNN design approach. SkyNet is demonstrated in the 56th IEEE/ACM Design Automation Conference System Design Contest (DAC-SDC), a low power object detection challenge in images captured by unmanned aerial vehicles (UAVs). SkyNet won the first place award for both the GPU and FPGA tracks of the contest: we deliver 0.731 Intersection over Union (IoU) and 67.33 frames per second (FPS) on a TX2 GPU and deliver 0.716 IoU and 25.05 FPS on an Ultra96 FPGA.



### COP: Customized Deep Model Compression via Regularized Correlation-Based Filter-Level Pruning
- **Arxiv ID**: http://arxiv.org/abs/1906.10337v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1906.10337v1)
- **Published**: 2019-06-25 06:15:42+00:00
- **Updated**: 2019-06-25 06:15:42+00:00
- **Authors**: Wenxiao Wang, Cong Fu, Jishun Guo, Deng Cai, Xiaofei He
- **Comment**: 7 pages, 4 figures, has been accepted by IJCAI2019
- **Journal**: None
- **Summary**: Neural network compression empowers the effective yet unwieldy deep convolutional neural networks (CNN) to be deployed in resource-constrained scenarios. Most state-of-the-art approaches prune the model in filter-level according to the "importance" of filters. Despite their success, we notice they suffer from at least two of the following problems: 1) The redundancy among filters is not considered because the importance is evaluated independently. 2) Cross-layer filter comparison is unachievable since the importance is defined locally within each layer. Consequently, we must manually specify layer-wise pruning ratios. 3) They are prone to generate sub-optimal solutions because they neglect the inequality between reducing parameters and reducing computational cost. Reducing the same number of parameters in different positions in the network may reduce different computational cost. To address the above problems, we develop a novel algorithm named as COP (correlation-based pruning), which can detect the redundant filters efficiently. We enable the cross-layer filter comparison through global normalization. We add parameter-quantity and computational-cost regularization terms to the importance, which enables the users to customize the compression according to their preference (smaller or faster). Extensive experiments have shown COP outperforms the others significantly. The code is released at https://github.com/ZJULearning/COP.



### Learning a sparse database for patch-based medical image segmentation
- **Arxiv ID**: http://arxiv.org/abs/1906.10338v1
- **DOI**: 10.1007/978-3-319-67434-6_6
- **Categories**: **eess.IV**, cs.CV, cs.LG, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/1906.10338v1)
- **Published**: 2019-06-25 06:16:05+00:00
- **Updated**: 2019-06-25 06:16:05+00:00
- **Authors**: Moti Freiman, Hannes Nickisch, Holger Schmitt, Pal Maurovich-Horvat, Patrick Donnelly, Mani Vembar, Liran Goshen
- **Comment**: None
- **Journal**: Wu G., Munsell B., Zhan Y., Bai W., Sanroma G., Coup\'e P. (eds)
  Patch-Based Techniques in Medical Imaging. Patch-MI 2017. Lecture Notes in
  Computer Science, vol 10530. Springer, Cham
- **Summary**: We introduce a functional for the learning of an optimal database for patch-based image segmentation with application to coronary lumen segmentation from coronary computed tomography angiography (CCTA) data. The proposed functional consists of fidelity, sparseness and robustness to small-variations terms and their associated weights. Existing work address database optimization by prototype selection aiming to optimize the database by either adding or removing prototypes according to a set of predefined rules. In contrast, we formulate the database optimization task as an energy minimization problem that can be solved using standard numerical tools. We apply the proposed database optimization functional to the task of optimizing a database for patch-base coronary lumen segmentation. Our experiments using the publicly available MICCAI 2012 coronary lumen segmentation challenge data show that optimizing the database using the proposed approach reduced database size by 96% while maintaining the same level of lumen segmentation accuracy. Moreover, we show that the optimized database yields an improved specificity of CCTA based fractional flow reserve (0.73 vs 0.7 for all lesions and 0.68 vs 0.65 for obstructive lesions) using a training set of 132 (76 obstructive) coronary lesions with invasively measured FFR as the reference.



### Exploring Self-Supervised Regularization for Supervised and Semi-Supervised Learning
- **Arxiv ID**: http://arxiv.org/abs/1906.10343v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1906.10343v2)
- **Published**: 2019-06-25 06:42:05+00:00
- **Updated**: 2019-11-21 08:30:43+00:00
- **Authors**: Phi Vu Tran
- **Comment**: NeurIPS'19 Workshop on Learning with Rich Experience: Integration of
  Learning Paradigms
- **Journal**: None
- **Summary**: Recent advances in semi-supervised learning have shown tremendous potential in overcoming a major barrier to the success of modern machine learning algorithms: access to vast amounts of human-labeled training data. Previous algorithms based on consistency regularization can harness the abundance of unlabeled data to produce impressive results on a number of semi-supervised benchmarks, approaching the performance of strong supervised baselines using only a fraction of the available labeled data. In this work, we challenge the long-standing success of consistency regularization by introducing self-supervised regularization as the basis for combining semantic feature representations from unlabeled data. We perform extensive comparative experiments to demonstrate the effectiveness of self-supervised regularization for supervised and semi-supervised image classification on SVHN, CIFAR-10, and CIFAR-100 benchmark datasets. We present two main results: (1) models augmented with self-supervised regularization significantly improve upon traditional supervised classifiers without the need for unlabeled data; (2) together with unlabeled data, our models yield semi-supervised performance competitive with, and in many cases exceeding, prior state-of-the-art consistency baselines. Lastly, our models have the practical utility of being efficiently trained end-to-end and require no additional hyper-parameters to tune for optimal performance beyond the standard set for training neural networks. Reference code and data are available at https://github.com/vuptran/sesemi



### End-to-End Learning of Multi-scale Convolutional Neural Network for Stereo Matching
- **Arxiv ID**: http://arxiv.org/abs/1906.10399v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.10399v1)
- **Published**: 2019-06-25 09:15:22+00:00
- **Updated**: 2019-06-25 09:15:22+00:00
- **Authors**: Li Zhang, Quanhong Wang, Haihua Lu, Yong Zhao
- **Comment**: 16 pages, 4 figures,Asian Conference on Machine Learning(ACML)2018
- **Journal**: None
- **Summary**: Deep neural networks have shown excellent performance in stereo matching task. Recently CNN-based methods have shown that stereo matching can be formulated as a supervised learning task. However, less attention is paid on the fusion of contextual semantic information and details. To tackle this problem, we propose a network for disparity estimation based on abundant contextual details and semantic information, called Multi-scale Features Network (MSFNet). First, we design a new structure to encode rich semantic information and fine-grained details by fusing multi-scale features. And we combine the advantages of element-wise addition and concatenation, which is conducive to merge semantic information with details. Second, a guidance mechanism is introduced to guide the network to automatically focus more on the unreliable regions. Third, we formulate the consistency check as an error map, obtained by the low stage features with fine-grained details. Finally, we adopt the consistency checking between the left feature and the synthetic left feature to refine the initial disparity. Experiments on Scene Flow and KITTI 2015 benchmark demonstrated that the proposed method can achieve the state-of-the-art performance.



### Brain MR Image Segmentation in Small Dataset with Adversarial Defense and Task Reorganization
- **Arxiv ID**: http://arxiv.org/abs/1906.10400v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1906.10400v1)
- **Published**: 2019-06-25 09:15:24+00:00
- **Updated**: 2019-06-25 09:15:24+00:00
- **Authors**: Xuhua Ren, Lichi Zhang, Qian Wang, Dinggang Shen
- **Comment**: None
- **Journal**: None
- **Summary**: Medical image segmentation is challenging especially in dealing with small dataset of 3D MR images. Encoding the variation of brain anatomical struc-tures from individual subjects cannot be easily achieved, which is further chal-lenged by only a limited number of well labeled subjects for training. In this study, we aim to address the issue of brain MR image segmentation in small da-taset. First, concerning the limited number of training images, we adopt adver-sarial defense to augment the training data and therefore increase the robustness of the network. Second, inspired by the prior knowledge of neural anatomies, we reorganize the segmentation tasks of different regions into several groups in a hierarchical way. Third, the task reorganization extends to the semantic level, as we incorporate an additional object-level classification task to contribute high-order visual features toward the pixel-level segmentation task. In experiments we validate our method by segmenting gray matter, white matter, and several major regions on a challenge dataset. The proposed method with only seven subjects for training can achieve 84.46% of Dice score in the onsite test set.



### Graph-Based Offline Signature Verification
- **Arxiv ID**: http://arxiv.org/abs/1906.10401v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.10401v1)
- **Published**: 2019-06-25 09:15:35+00:00
- **Updated**: 2019-06-25 09:15:35+00:00
- **Authors**: Paul Maergner, Nicholas R. Howe, Kaspar Riesen, Rolf Ingold, Andreas Fischer
- **Comment**: None
- **Journal**: None
- **Summary**: Graphs provide a powerful representation formalism that offers great promise to benefit tasks like handwritten signature verification. While most state-of-the-art approaches to signature verification rely on fixed-size representations, graphs are flexible in size and allow modeling local features as well as the global structure of the handwriting. In this article, we present two recent graph-based approaches to offline signature verification: keypoint graphs with approximated graph edit distance and inkball models. We provide a comprehensive description of the methods, propose improvements both in terms of computational time and accuracy, and report experimental results for four benchmark datasets. The proposed methods achieve top results for several benchmarks, highlighting the potential of graph-based signature verification.



### Deep Learning of Compressed Sensing Operators with Structural Similarity Loss
- **Arxiv ID**: http://arxiv.org/abs/1906.10411v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1906.10411v1)
- **Published**: 2019-06-25 09:33:30+00:00
- **Updated**: 2019-06-25 09:33:30+00:00
- **Authors**: Yochai Zur, Amir Adler
- **Comment**: None
- **Journal**: None
- **Summary**: Compressed sensing (CS) is a signal processing framework for efficiently reconstructing a signal from a small number of measurements, obtained by linear projections of the signal. In this paper we present an end-to-end deep learning approach for CS, in which a fully-connected network performs both the linear sensing and non-linear reconstruction stages. During the training phase, the sensing matrix and the non-linear reconstruction operator are jointly optimized using Structural similarity index (SSIM) as loss rather than the standard Mean Squared Error (MSE) loss. We compare the proposed approach with state-of-the-art in terms of reconstruction quality under both losses, i.e. SSIM score and MSE score.



### A CNN-Based Super-Resolution Technique for Active Fire Detection on Sentinel-2 Data
- **Arxiv ID**: http://arxiv.org/abs/1906.10413v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1906.10413v1)
- **Published**: 2019-06-25 09:34:38+00:00
- **Updated**: 2019-06-25 09:34:38+00:00
- **Authors**: Massimiliano Gargiulo, Domenico Antonio Giuseppe Dell'Aglio, Antonio Iodice, Daniele Riccio, Giuseppe Ruello
- **Comment**: 8 pages, 6 figures
- **Journal**: None
- **Summary**: Remote Sensing applications can benefit from a relatively fine spatial resolution multispectral (MS) images and a high revisit frequency ensured by the twin satellites Sentinel-2. Unfortunately, only four out of thirteen bands are provided at the highest resolution of 10 meters, and the others at 20 or 60 meters. For instance the Short-Wave Infrared (SWIR) bands, provided at 20 meters, are very useful to detect active fires. Aiming to a more detailed Active Fire Detection (AFD) maps, we propose a super-resolution data fusion method based on Convolutional Neural Network (CNN) to move towards the 10-m spatial resolution the SWIR bands. The proposed CNN-based solution achieves better results than alternative methods in terms of some accuracy metrics. Moreover we test the super-resolved bands from an application point of view by monitoring active fire through classic indices. Advantages and limits of our proposed approach are validated on specific geographical area (the mount Vesuvius, close to Naples) that was damaged by widespread fires during the summer of 2017.



### Learning Feature Embeddings for Discriminant Model based Tracking
- **Arxiv ID**: http://arxiv.org/abs/1906.10414v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.10414v2)
- **Published**: 2019-06-25 09:40:37+00:00
- **Updated**: 2020-09-06 09:23:13+00:00
- **Authors**: Linyu Zheng, Ming Tang, Yingying Chen, Jinqiao Wang, Hanqing Lu
- **Comment**: 15 pages, 5 figures, accepted by ECCV2020
- **Journal**: None
- **Summary**: After observing that the features used in most online discriminatively trained trackers are not optimal, in this paper, we propose a novel and effective architecture to learn optimal feature embeddings for online discriminative tracking. Our method, called DCFST, integrates the solver of a discriminant model that is differentiable and has a closed-form solution into convolutional neural networks. Then, the resulting network can be trained in an end-to-end way, obtaining optimal feature embeddings for the discriminant model-based tracker. As an instance, we apply the popular ridge regression model in this work to demonstrate the power of DCFST. Extensive experiments on six public benchmarks, OTB2015, NFS, GOT10k, TrackingNet, VOT2018, and VOT2019, show that our approach is efficient and generalizes well to class-agnostic target objects in online tracking, thus achieves state-of-the-art accuracy, while running beyond the real-time speed. Code will be made available.



### New pointwise convolution in Deep Neural Networks through Extremely Fast and Non Parametric Transforms
- **Arxiv ID**: http://arxiv.org/abs/1906.12172v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1906.12172v1)
- **Published**: 2019-06-25 10:47:08+00:00
- **Updated**: 2019-06-25 10:47:08+00:00
- **Authors**: Joonhyun Jeong, Sung-Ho Bae
- **Comment**: 12 pages, 6 figures
- **Journal**: None
- **Summary**: Some conventional transforms such as Discrete Walsh-Hadamard Transform (DWHT) and Discrete Cosine Transform (DCT) have been widely used as feature extractors in image processing but rarely applied in neural networks. However, we found that these conventional transforms have the ability to capture the cross-channel correlations without any learnable parameters in DNNs. This paper firstly proposes to apply conventional transforms to pointwise convolution, showing that such transforms significantly reduce the computational complexity of neural networks without accuracy performance degradation. Especially for DWHT, it requires no floating point multiplications but only additions and subtractions, which can considerably reduce computation overheads. In addition, its fast algorithm further reduces complexity of floating point addition from $\mathcal{O}(n^2)$ to $\mathcal{O}(n\log n)$. These nice properties construct extremely efficient networks in the number parameters and operations, enjoying accuracy gain. Our proposed DWHT-based model gained 1.49\% accuracy increase with 79.1\% reduced parameters and 48.4\% reduced FLOPs compared with its baseline model (MoblieNet-V1) on the CIFAR 100 dataset.



### A Novel Deep Learning Based Approach for Left Ventricle Segmentation in Echocardiography: MFP-Unet
- **Arxiv ID**: http://arxiv.org/abs/1906.10486v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/1906.10486v2)
- **Published**: 2019-06-25 12:56:27+00:00
- **Updated**: 2019-12-22 09:18:39+00:00
- **Authors**: Shakiba Moradi, Mostafa Ghelich-Oghli, Azin Alizadehasl, Isaac Shiri, Niki Oveisi, Mehrdad Oveisi, Majid Maleki, Jan Dhooge
- **Comment**: 32 Pages, 10 Figures, 5 Tables
- **Journal**: https://doi.org/10.1016/j.ejmp.2019.10.001
- **Summary**: Segmentation of the Left ventricle (LV) is a crucial step for quantitative measurements such as area, volume, and ejection fraction. However, the automatic LV segmentation in 2D echocardiographic images is a challenging task due to ill-defined borders, and operator dependence issues (insufficient reproducibility). U-net, which is a well-known architecture in medical image segmentation, addressed this problem through an encoder-decoder path. Despite outstanding overall performance, U-net ignores the contribution of all semantic strengths in the segmentation procedure. In the present study, we have proposed a novel architecture to tackle this drawback. Feature maps in all levels of the decoder path of U-net are concatenated, their depths are equalized, and up-sampled to a fixed dimension. This stack of feature maps would be the input of the semantic segmentation layer. The proposed network yielded state-of-the-art results when comparing with results from U-net, dilated U-net, and deeplabv3, using the same dataset. An average Dice Metric (DM) of 0.945, Hausdorff Distance (HD) of 1.62, Jaccard Coefficient (JC) of 0.97, and Mean Absolute Distance (MAD) of 1.32 are achieved. The correlation graph, bland-altman analysis, and box plot showed a great agreement between automatic and manually calculated volume, area, and length.



### Age and gender bias in pedestrian detection algorithms
- **Arxiv ID**: http://arxiv.org/abs/1906.10490v1
- **DOI**: None
- **Categories**: **cs.CY**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1906.10490v1)
- **Published**: 2019-06-25 13:01:29+00:00
- **Updated**: 2019-06-25 13:01:29+00:00
- **Authors**: Martim Brandao
- **Comment**: Appeared at the Workshop on Fairness Accountability Transparency and
  Ethics in Computer Vision (FATE CV) at CVPR 2019
- **Journal**: None
- **Summary**: Pedestrian detection algorithms are important components of mobile robots, such as autonomous vehicles, which directly relate to human safety. Performance disparities in these algorithms could translate into disparate impact in the form of biased accident outcomes. To evaluate the need for such concerns, we characterize the age and gender bias in the performance of state-of-the-art pedestrian detection algorithms. Our analysis is based on the INRIA Person Dataset extended with child, adult, male and female labels. We show that all of the 24 top-performing methods of the Caltech Pedestrian Detection Benchmark have higher miss rates on children. The difference is significant and we analyse how it varies with the classifier, features and training data used by the methods. Algorithms were also gender-biased on average but the performance differences were not significant. We discuss the source of the bias, the ethical implications, possible technical solutions and barriers.



### Discrete Optimization of Ray Potentials for Semantic 3D Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/1906.10491v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.10491v1)
- **Published**: 2019-06-25 13:04:56+00:00
- **Updated**: 2019-06-25 13:04:56+00:00
- **Authors**: Nikolay Savinov, Lubor Ladicky, Christian Haene, Marc Pollefeys
- **Comment**: Published at CVPR 2015
- **Journal**: None
- **Summary**: Dense semantic 3D reconstruction is typically formulated as a discrete or continuous problem over label assignments in a voxel grid, combining semantic and depth likelihoods in a Markov Random Field framework. The depth and semantic information is incorporated as a unary potential, smoothed by a pairwise regularizer. However, modelling likelihoods as a unary potential does not model the problem correctly leading to various undesirable visibility artifacts.   We propose to formulate an optimization problem that directly optimizes the reprojection error of the 3D model with respect to the image estimates, which corresponds to the optimization over rays, where the cost function depends on the semantic class and depth of the first occupied voxel along the ray. The 2-label formulation is made feasible by transforming it into a graph-representable form under QPBO relaxation, solvable using graph cut. The multi-label problem is solved by applying alpha-expansion using the same relaxation in each expansion move. Our method was indeed shown to be feasible in practice, running comparably fast to the competing methods, while not suffering from ray potential approximation artifacts.



### 3D Surface Reconstruction from Voxel-based Lidar Data
- **Arxiv ID**: http://arxiv.org/abs/1906.10515v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1906.10515v1)
- **Published**: 2019-06-25 13:37:26+00:00
- **Updated**: 2019-06-25 13:37:26+00:00
- **Authors**: Luis Roldão, Raoul de Charette, Anne Verroust-Blondet
- **Comment**: IEEE Intelligent Transportation Systems Conference (ITSC) 2019
- **Journal**: None
- **Summary**: To achieve fully autonomous navigation, vehicles need to compute an accurate model of their direct surrounding. In this paper, a 3D surface reconstruction algorithm from heterogeneous density 3D data is presented. The proposed method is based on a TSDF voxel-based representation, where an adaptive neighborhood kernel sourced on a Gaussian confidence evaluation is introduced. This enables to keep a good trade-off between the density of the reconstructed mesh and its accuracy. Experimental evaluations carried on both synthetic (CARLA) and real (KITTI) 3D data show a good performance compared to a state of the art method used for surface reconstruction.



### Naver at ActivityNet Challenge 2019 -- Task B Active Speaker Detection (AVA)
- **Arxiv ID**: http://arxiv.org/abs/1906.10555v1
- **DOI**: None
- **Categories**: **cs.SD**, cs.CV, eess.AS
- **Links**: [PDF](http://arxiv.org/pdf/1906.10555v1)
- **Published**: 2019-06-25 14:11:14+00:00
- **Updated**: 2019-06-25 14:11:14+00:00
- **Authors**: Joon Son Chung
- **Comment**: None
- **Journal**: None
- **Summary**: This report describes our submission to the ActivityNet Challenge at CVPR 2019. We use a 3D convolutional neural network (CNN) based front-end and an ensemble of temporal convolution and LSTM classifiers to predict whether a visible person is speaking or not. Our results show significant improvements over the baseline on the AVA-ActiveSpeaker dataset.



### Gesture Recognition in RGB Videos UsingHuman Body Keypoints and Dynamic Time Warping
- **Arxiv ID**: http://arxiv.org/abs/1906.12171v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1906.12171v1)
- **Published**: 2019-06-25 14:30:38+00:00
- **Updated**: 2019-06-25 14:30:38+00:00
- **Authors**: Pascal Schneider, Raphael Memmesheimer, Ivanna Kramer, Dietrich Paulus
- **Comment**: 13 pages, 4 figures, 2 tables, RoboCup 2019 Symposium
- **Journal**: None
- **Summary**: Gesture recognition opens up new ways for humans to intuitively interact with machines. Especially for service robots, gestures can be a valuable addition to the means of communication to, for example, draw the robot's attention to someone or something. Extracting a gesture from video data and classifying it is a challenging task and a variety of approaches have been proposed throughout the years. This paper presents a method for gesture recognition in RGB videos using OpenPose to extract the pose of a person and Dynamic Time Warping (DTW) in conjunction with One-Nearest-Neighbor (1NN) for time-series classification. The main features of this approach are the independence of any specific hardware and high flexibility, because new gestures can be added to the classifier by adding only a few examples of it. We utilize the robustness of the Deep Learning-based OpenPose framework while avoiding the data-intensive task of training a neural network ourselves. We demonstrate the classification performance of our method using a public dataset.



### LipReading with 3D-2D-CNN BLSTM-HMM and word-CTC models
- **Arxiv ID**: http://arxiv.org/abs/1906.12170v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.SD, eess.AS, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1906.12170v1)
- **Published**: 2019-06-25 14:52:54+00:00
- **Updated**: 2019-06-25 14:52:54+00:00
- **Authors**: Dilip Kumar Margam, Rohith Aralikatti, Tanay Sharma, Abhinav Thanda, Pujitha A K, Sharad Roy, Shankar M Venkatesan
- **Comment**: Submitted to Interspeech 2019
- **Journal**: None
- **Summary**: In recent years, deep learning based machine lipreading has gained prominence. To this end, several architectures such as LipNet, LCANet and others have been proposed which perform extremely well compared to traditional lipreading DNN-HMM hybrid systems trained on DCT features. In this work, we propose a simpler architecture of 3D-2D-CNN-BLSTM network with a bottleneck layer. We also present analysis of two different approaches for lipreading on this architecture. In the first approach, 3D-2D-CNN-BLSTM network is trained with CTC loss on characters (ch-CTC). Then BLSTM-HMM model is trained on bottleneck lip features (extracted from 3D-2D-CNN-BLSTM ch-CTC network) in a traditional ASR training pipeline. In the second approach, same 3D-2D-CNN-BLSTM network is trained with CTC loss on word labels (w-CTC). The first approach shows that bottleneck features perform better compared to DCT features. Using the second approach on Grid corpus' seen speaker test set, we report $1.3\%$ WER - a $55\%$ improvement relative to LCANet. On unseen speaker test set we report $8.6\%$ WER which is $24.5\%$ improvement relative to LipNet. We also verify the method on a second dataset of $81$ speakers which we collected. Finally, we also discuss the effect of feature duplication on BLSTM-HMM model performance.



### Interpretable Image Recognition with Hierarchical Prototypes
- **Arxiv ID**: http://arxiv.org/abs/1906.10651v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1906.10651v2)
- **Published**: 2019-06-25 16:45:34+00:00
- **Updated**: 2019-08-25 00:35:55+00:00
- **Authors**: Peter Hase, Chaofan Chen, Oscar Li, Cynthia Rudin
- **Comment**: Published as a full paper at HCOMP 2019
- **Journal**: None
- **Summary**: Vision models are interpretable when they classify objects on the basis of features that a person can directly understand. Recently, methods relying on visual feature prototypes have been developed for this purpose. However, in contrast to how humans categorize objects, these approaches have not yet made use of any taxonomical organization of class labels. With such an approach, for instance, we may see why a chimpanzee is classified as a chimpanzee, but not why it was considered to be a primate or even an animal. In this work we introduce a model that uses hierarchically organized prototypes to classify objects at every level in a predefined taxonomy. Hence, we may find distinct explanations for the prediction an image receives at each level of the taxonomy. The hierarchical prototypes enable the model to perform another important task: interpretably classifying images from previously unseen classes at the level of the taxonomy to which they correctly relate, e.g. classifying a hand gun as a weapon, when the only weapons in the training data are rifles. With a subset of ImageNet, we test our model against its counterpart black-box model on two tasks: 1) classification of data from familiar classes, and 2) classification of data from previously unseen classes at the appropriate level in the taxonomy. We find that our model performs approximately as well as its counterpart black-box model while allowing for each classification to be interpreted.



### Fast Robot Arm Inverse Kinematics and Path Planning Under Complex Static and Dynamic Obstacle Constraints
- **Arxiv ID**: http://arxiv.org/abs/1906.10678v5
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1906.10678v5)
- **Published**: 2019-06-25 17:34:15+00:00
- **Updated**: 2020-04-14 21:01:00+00:00
- **Authors**: David W. Arathorn
- **Comment**: None
- **Journal**: None
- **Summary**: Described here is a simple, reliable, and quite general method for rapid computation of robot arm inverse kinematic solutions and motion path plans in the presence of complex obstructions. The method derived from the MSC (map-seeking circuit) algorithm, optimized to exploit the characteristics of practical arm configurations. The representation naturally incorporates both arm and obstacle geometries. The consequent performance on modern hardware is suitable for applications requiring real-time response, including smooth continuous avoidance of dynamic obstacles which impinge on the planned path during the traversal of the arm. On high-end GPGPU hardware computation of both final pose for an 8 DOF arm and a smooth obstacle-avoiding motion path to that pose takes approximately 200-300msec depending on the number of waypoints implemented. The mathematics of the method is accessible to high school seniors, making it suitable for broad instruction. [Note: This revision includes a general compute strategy for paths from arbitrary pose to arbitrary pose and a compute strategy for continuous motion mid-course avoidance of dynamic obstacles.]



### CNN-based Survival Model for Pancreatic Ductal Adenocarcinoma in Medical Imaging
- **Arxiv ID**: http://arxiv.org/abs/1906.10729v1
- **DOI**: None
- **Categories**: **q-bio.QM**, cs.CV, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1906.10729v1)
- **Published**: 2019-06-25 19:12:39+00:00
- **Updated**: 2019-06-25 19:12:39+00:00
- **Authors**: Yucheng Zhang, Edrise M. Lobo-Mueller, Paul Karanicolas, Steven Gallinger, Masoom A. Haider, Farzad Khalvati
- **Comment**: None
- **Journal**: None
- **Summary**: Cox proportional hazard model (CPH) is commonly used in clinical research for survival analysis. In quantitative medical imaging (radiomics) studies, CPH plays an important role in feature reduction and modeling. However, the underlying linear assumption of CPH model limits the prognostic performance. In addition, the multicollinearity of radiomic features and multiple testing problem further impedes the CPH models performance. In this work, using transfer learning, a convolutional neural network (CNN) based survival model was built and tested on preoperative CT images of resectable Pancreatic Ductal Adenocarcinoma (PDAC) patients. The proposed CNN-based survival model outperformed the traditional CPH-based radiomics approach in terms of concordance index by 22%, providing a better fit for patients' survival patterns. The proposed CNN-based survival model outperforms CPH-based radiomics pipeline in PDAC prognosis. This approach offers a better fit for survival patterns based on CT images and overcomes the limitations of conventional survival models.



### The Difficulty of Training Sparse Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1906.10732v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1906.10732v3)
- **Published**: 2019-06-25 19:21:15+00:00
- **Updated**: 2020-10-07 17:38:07+00:00
- **Authors**: Utku Evci, Fabian Pedregosa, Aidan Gomez, Erich Elsen
- **Comment**: sparse networks, pruning, energy landscape, sparsity
- **Journal**: None
- **Summary**: We investigate the difficulties of training sparse neural networks and make new observations about optimization dynamics and the energy landscape within the sparse regime. Recent work of \citep{Gale2019, Liu2018} has shown that sparse ResNet-50 architectures trained on ImageNet-2012 dataset converge to solutions that are significantly worse than those found by pruning. We show that, despite the failure of optimizers, there is a linear path with a monotonically decreasing objective from the initialization to the "good" solution. Additionally, our attempts to find a decreasing objective path from "bad" solutions to the "good" ones in the sparse subspace fail. However, if we allow the path to traverse the dense subspace, then we consistently find a path between two solutions. These findings suggest traversing extra dimensions may be needed to escape stationary points found in the sparse subspace.



### Deep Modular Co-Attention Networks for Visual Question Answering
- **Arxiv ID**: http://arxiv.org/abs/1906.10770v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.10770v1)
- **Published**: 2019-06-25 22:16:03+00:00
- **Updated**: 2019-06-25 22:16:03+00:00
- **Authors**: Zhou Yu, Jun Yu, Yuhao Cui, Dacheng Tao, Qi Tian
- **Comment**: Accepted at CVPR 2019
- **Journal**: None
- **Summary**: Visual Question Answering (VQA) requires a fine-grained and simultaneous understanding of both the visual content of images and the textual content of questions. Therefore, designing an effective `co-attention' model to associate key words in questions with key objects in images is central to VQA performance. So far, most successful attempts at co-attention learning have been achieved by using shallow models, and deep co-attention models show little improvement over their shallow counterparts. In this paper, we propose a deep Modular Co-Attention Network (MCAN) that consists of Modular Co-Attention (MCA) layers cascaded in depth. Each MCA layer models the self-attention of questions and images, as well as the guided-attention of images jointly using a modular composition of two basic attention units. We quantitatively and qualitatively evaluate MCAN on the benchmark VQA-v2 dataset and conduct extensive ablation studies to explore the reasons behind MCAN's effectiveness. Experimental results demonstrate that MCAN significantly outperforms the previous state-of-the-art. Our best single model delivers 70.63$\%$ overall accuracy on the test-dev set. Code is available at https://github.com/MILVLG/mcan-vqa.



### Importance Estimation for Neural Network Pruning
- **Arxiv ID**: http://arxiv.org/abs/1906.10771v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1906.10771v1)
- **Published**: 2019-06-25 22:20:16+00:00
- **Updated**: 2019-06-25 22:20:16+00:00
- **Authors**: Pavlo Molchanov, Arun Mallya, Stephen Tyree, Iuri Frosio, Jan Kautz
- **Comment**: None
- **Journal**: None
- **Summary**: Structural pruning of neural network parameters reduces computation, energy, and memory transfer costs during inference. We propose a novel method that estimates the contribution of a neuron (filter) to the final loss and iteratively removes those with smaller scores. We describe two variations of our method using the first and second-order Taylor expansions to approximate a filter's contribution. Both methods scale consistently across any network layer without requiring per-layer sensitivity analysis and can be applied to any kind of layer, including skip connections. For modern networks trained on ImageNet, we measured experimentally a high (>93%) correlation between the contribution computed by our methods and a reliable estimate of the true importance. Pruning with the proposed methods leads to an improvement over state-of-the-art in terms of accuracy, FLOPs, and parameter reduction. On ResNet-101, we achieve a 40% FLOPS reduction by removing 30% of the parameters, with a loss of 0.02% in the top-1 accuracy on ImageNet. Code is available at https://github.com/NVlabs/Taylor_pruning.



