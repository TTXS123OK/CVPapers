# Arxiv Papers in cs.CV on 2009-10-30
### Metric and Kernel Learning using a Linear Transformation
- **Arxiv ID**: http://arxiv.org/abs/0910.5932v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.IR
- **Links**: [PDF](http://arxiv.org/pdf/0910.5932v1)
- **Published**: 2009-10-30 18:19:03+00:00
- **Updated**: 2009-10-30 18:19:03+00:00
- **Authors**: Prateek Jain, Brian Kulis, Jason V. Davis, Inderjit S. Dhillon
- **Comment**: None
- **Journal**: None
- **Summary**: Metric and kernel learning are important in several machine learning applications. However, most existing metric learning algorithms are limited to learning metrics over low-dimensional data, while existing kernel learning algorithms are often limited to the transductive setting and do not generalize to new data points. In this paper, we study metric learning as a problem of learning a linear transformation of the input data. We show that for high-dimensional data, a particular framework for learning a linear transformation of the data based on the LogDet divergence can be efficiently kernelized to learn a metric (or equivalently, a kernel function) over an arbitrarily high dimensional space. We further demonstrate that a wide class of convex loss functions for learning linear transformations can similarly be kernelized, thereby considerably expanding the potential applications of metric learning. We demonstrate our learning approach by applying it to large-scale real world problems in computer vision and text mining.



